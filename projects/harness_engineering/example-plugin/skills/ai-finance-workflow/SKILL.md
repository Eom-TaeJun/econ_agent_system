---
name: ai-finance-workflow
description: |
  AI를 금융 분석에 활용하는 작업 흐름 설계, 도메인 지식을 AI에게 전달하는 방법,
  금융 데이터 전처리 파이프라인, 여러 AI 도구 조합, 분석 결과 해석 및 임플리케이션
  도출 작업 시 활성화된다. AI 코딩 도구 자체 사용법이 아닌 금융 도메인 × AI 접목 시.
version: 1.1.0
updated: 2026-02-20
---

# AI × 금융 도메인 워크플로우

## 핵심 철학: 도메인 지식이 먼저다

> "기본 정의가 아니라 도메인을 사용한 정의, 경제정책을 통한 예시로 AI에게 전달해야 함"

**도메인 지식이란:**
- 사건/이벤트 발생 시 어떤 기업이 유리한지 판단할 수 있는 것
- 물어보는 능력 = 도메인 지식의 표현
- "맥락과 컨텍스트 엔지니어링이 가능해야 함 → 도메인 차이이자 knowledge gap"

**AI가 대체 못하는 사람:**
- 시장 반응을 미국/한국과 연결해 implication을 뽑아내는 사람
- 기사 팩트체크 후 다른 시각을 제시할 수 있는 사람
- 계획하고 방향을 잡는 사람 (AI는 실행 도구)

---

## AI 질문 설계 원칙

```
❌ 잘못된 질문: "포아송 분포란?" (기본 정의)
✅ 올바른 질문: "통상적인 리턴이 노멀이라고 할 때 포아송은?" (도메인 적용)

❌ 잘못된 질문: "factor가 무엇인가?"
✅ 올바른 질문: "factor의 industry는 얼마일까?" (키워드 질문)
```

**프롬프팅 팁:**
- 경로 또는 사용 도구를 지정 → 토큰 절약
- `#`으로 무엇을 하는지, 내가 원하는 게 무엇인지 표시
- 도메인 용어로 새롭게 정의해서 전달

---

## AI 도구 활용 계층

```
1. 검색/요약     → AI (사실 기반, 빠름)
2. 분석/임플리케이션 → 내가 직접 (도메인 판단)
3. 코딩          → AI + 내가 계획 (AI는 실행, 나는 방향)
4. 발표자료       → AI 초안 → 내가 검토
```

**멀티 AI 활용:**
- **Perplexity**: 영어 질문으로 현재 이슈 탐색
- **Claude**: 분석 심화, 코드 생성, 하니스 설계
- **GPT**: 오케스트레이션, 요약
- 터미널 환경 → 복사/붙여넣기 없이 빠르게

---

## 금융 데이터 처리 파이프라인

### 데이터 구조 선택
```
NumPy  : numeric만 (character 불가, 빠름)
Pandas : 유연하지만 메모리 소비 큼
JSON   : 금융 데이터에 가장 편함
         → key-value 구조, loop 없이 처리 가능
```

### 필수 전처리 순서 (반드시 이 순서)
```
1. 다운로드
2. 컬럼명 변환 (표준화)
3. Index 수정 ← 가장 어려운 단계, 주의
4. 이상치/결측치 확인
5. 기초 통계량 확인 (논문 제출 필수)
```

### 금융 이상치 처리 원칙
```
금융 데이터에서 이상치 = 정보일 수 있음
  → 단순 제거 X
  → 이벤트(공시, 계약, 정책 발표)와 연결 확인
  → 제거 vs 이벤트 더미 처리 판단
```

### Time Series 분석 3요소
```
1. Coefficient (계수)   - 변수 간 관계
2. Box interval (박스)  - 신뢰구간
3. Trend (장기 추세)
```

---

## 🔴 2026년 AI×금융 환경 업데이트

### 에이전틱 AI 채택 가속화
```
현황:
  82% 중견기업 / 95% PE 펌 → 에이전틱 AI 도입 시작 또는 계획
  도입 조직의 99% → 운영 효율성·생산성 개선 확인

주요 활용 케이스:
  1. 사이버보안·사기 탐지
  2. FP&A (재무계획 및 분석)
  3. 리서치 자동화 (뉴스·공시·대안데이터 처리)

임플리케이션:
  → AI 에이전트 구축 역량 = 2026년 퀀트 핵심 역량
  → 단순 코드 생성 → 분석 파이프라인 설계로 역할 진화
```

### LLM이 리서치 퍼널을 바꾸다
```
기존: 아이디어 부족 → 아이디어 발굴이 병목
2026: LLM이 아이디어 발굴 자동화
      → 새로운 병목: "어떻게 빠르게 평가하는가?"

Two Sigma의 핵심 통찰:
  LLM = 텍스트 + 구조화 데이터를 통합 표현으로 학습
  → 언어 데이터와 수치 데이터를 함께 처리
  → 리서치 퍼널 확장 (더 많은 아이디어를 더 빠르게 검토)

인간 역할의 진화:
  Before: 아이디어 발굴
  After:  모델 설계·검증 규율, 도메인 해석, 리스크 판단
```

### 대안 데이터(Alternative Data) 폭발
```
2026년 퀀트 전략의 새로운 인풋:
  텍스트: 뉴스, 공시, 실적발표, SNS 감성
  특허: 기술 모멘텀, 혁신 속도
  위성: 공장 가동률, 주차장 수, 농업 생산
  신용카드: 실시간 소비 트렌드
  구인공고: 기업 성장 전략 조기 포착

적용 원칙:
  대안 데이터 단독 < 대안 데이터 + 도메인 해석
  → 숫자를 보는 것보다 왜 그 숫자인지 아는 것이 우위
```

### AI 트레이딩 에이전트 (2026 현황)
```
현재 프로덕션 시스템:
  - 틱 데이터 + 뉴스 + 대안 시그널 실시간 인제스트
  - 엄격한 레이턴시·컴플라이언스 경계 내에서 실행
  - 인간 판단은 여전히 중심 (자율 실행 아님)

주의: AI가 빠르게 분석 → 결정은 사람이 → 실행은 AI
      "AI = 속도와 폭, 자율 의사결정 아님" 원칙 유지
```

---

## Moat(경쟁 우위) 만들기

```
사실/요약 → AI가 함
해석/임플리케이션 → 내가 함

나만의 무기:
  시장 반응을 미국/한국과 연결하는 능력
  질문과 생각의 수준 = 답의 수준
  부서의 문제를 경력직도 못 하는 걸 같이 의논할 수 있는 수준
```

---

## AI Scaffold 설계 원칙

```
1. AI가 해준다고 해도 내가 계획하는 게 중요
2. Search → 분석 → PPT/HTML 순서로 플로우 설계
3. 도메인 지식 → AI 입력 → 결과 검증 순환
4. Local LLM으로 도메인 전문화 가능
```

**LLM 한계 인식:**
- 알고리즘은 본 것만 추천 (학습 데이터 편향)
- 언론 편견이 학습에 반영될 수 있음
- 가장 중요한 정보는 알려주지 않음 → 직접 찾아야 함
- 여러 AI 동시 사용 → 교차 검증 필수
