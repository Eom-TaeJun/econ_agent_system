# Fed Watch ë¶„ì„ ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì„¤ê³„

## ğŸ“Š í˜„ì¬ ìƒí™© ì •ë¦¬

### 1. ë³´ìœ  ë°ì´í„°
âœ… **íšŒì˜ë³„ ë³‘í•© íŒŒì¼** (`meeting_YYYYMMDD_merged.csv`)
- êµ¬ì¡°: `Date, (0-25), (25-50), ..., (1575-1600)`
- ê° í–‰: íŠ¹ì • ë‚ ì§œì˜ í™•ë¥  ë¶„í¬
- ì˜ˆ: meeting_20251210_merged.csv (273ì¼ì¹˜)

âœ… **ì‹œì¥ ë°ì´í„° ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸** (`collect_macro_finance_v2.py`)
- Yahoo Finance: ì£¼ê°€, ì›ìì¬, í™˜ìœ¨ ë“±
- FRED API: ê¸ˆë¦¬, ê±°ì‹œê²½ì œ ì§€í‘œ, ì´ë²¤íŠ¸

âŒ **í•„ìš”í•˜ì§€ë§Œ ì—†ëŠ” ê²ƒ:**
- íŒ¨ë„ í˜•ì‹ ë°ì´í„° (`complete_cme_panel_history.csv`)
- ì‹¤ì œ FOMC ê²°ì • ê¸ˆë¦¬

---

## ğŸ”§ í•´ê²° ë°©ì•ˆ

### Phase 1: í™•ë¥  ë¶„í¬ â†’ ê¸°ëŒ€ê¸ˆë¦¬ ë³€í™˜

#### ë°©ë²• 1: ê°€ì¤‘í‰ê·  (ê¸°ëŒ“ê°’) **[ì¶”ì²œ]**
```python
def calculate_expected_rate(prob_row):
    """
    í™•ë¥  ë¶„í¬ì—ì„œ ê¸°ëŒ€ê¸ˆë¦¬ ê³„ì‚° (ê°€ì¤‘í‰ê· )
    
    Args:
        prob_row: pandas Series, (0-25)=0.1, (25-50)=0.3, ...
    
    Returns:
        expected_rate_bp: float, ê¸°ëŒ“ê°’ (bp ë‹¨ìœ„)
    """
    total_prob = 0
    expected_rate = 0
    
    for col, prob in prob_row.items():
        if pd.isna(prob) or prob == 0:
            continue
        
        # ì»¬ëŸ¼ëª… íŒŒì‹±: "(0-25)" â†’ ì¤‘ê°„ê°’ 12.5
        if col.startswith('(') and ')' in col:
            range_str = col.strip('()')
            low, high = map(int, range_str.split('-'))
            mid_point = (low + high) / 2
            
            expected_rate += mid_point * prob
            total_prob += prob
    
    # ì •ê·œí™” (í˜¹ì‹œ í•©ì´ 1ì´ ì•„ë‹Œ ê²½ìš° ëŒ€ë¹„)
    if total_prob > 0:
        return expected_rate / total_prob
    else:
        return np.nan

# ì‚¬ìš© ì˜ˆì‹œ
df['exp_rate_bp'] = df.apply(
    lambda row: calculate_expected_rate(row.drop('Date')), 
    axis=1
)
```

**ì¥ì :**
- ì´ë¡ ì ìœ¼ë¡œ ê°€ì¥ í•©ë¦¬ì  (í™•ë¥  ê°€ì¤‘ í‰ê· )
- ë¶„í¬ì˜ ëª¨ë“  ì •ë³´ í™œìš©
- ì˜ˆì „ ë¶„ì„ê³¼ ì¼ê´€ì„± ìœ ì§€

**ë‹¨ì :**
- ê·¹ë‹¨ê°’(tail)ì— ë¯¼ê°í•  ìˆ˜ ìˆìŒ

---

#### ë°©ë²• 2: ì¤‘ìœ„ìˆ˜ (Median)
```python
def calculate_median_rate(prob_row):
    """í™•ë¥  ë¶„í¬ì˜ ì¤‘ìœ„ìˆ˜"""
    cumsum = 0
    for col, prob in prob_row.items():
        if pd.isna(prob):
            continue
        cumsum += prob
        if cumsum >= 0.5:
            # ì´ êµ¬ê°„ì´ ì¤‘ìœ„ìˆ˜
            range_str = col.strip('()')
            low, high = map(int, range_str.split('-'))
            return (low + high) / 2
    return np.nan
```

**ì¥ì :**
- ê·¹ë‹¨ê°’ì— ê°•ê±´ (robust)
- ì‹œì¥ì˜ "ì¤‘ì‹¬ ì˜ê²¬" ë°˜ì˜

**ë‹¨ì :**
- tail ì •ë³´ ë¬´ì‹œ

---

#### ë°©ë²• 3: ìµœë¹ˆê°’ (Mode)
```python
def calculate_mode_rate(prob_row):
    """ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ êµ¬ê°„"""
    max_prob = prob_row.max()
    mode_col = prob_row.idxmax()
    
    range_str = mode_col.strip('()')
    low, high = map(int, range_str.split('-'))
    return (low + high) / 2
```

**ì¥ì :**
- ì‹œì¥ì˜ "ì»¨ì„¼ì„œìŠ¤" ë°˜ì˜
- ê³„ì‚° ë¹ ë¦„

**ë‹¨ì :**
- ë¶„í¬ì˜ ëŒ€ë¶€ë¶„ ì •ë³´ ë¬´ì‹œ
- bimodal ë¶„í¬ ì²˜ë¦¬ ì–´ë ¤ì›€

---

### ğŸ’¡ **ì¶”ì²œ: ê°€ì¤‘í‰ê·  + ë¶„ì‚°ë„ í•¨ê»˜ ê³„ì‚°**

```python
def calculate_rate_statistics(prob_row):
    """ê¸°ëŒ“ê°’ + í‘œì¤€í¸ì°¨ ê³„ì‚°"""
    rates = []
    probs = []
    
    for col, prob in prob_row.items():
        if pd.isna(prob) or prob == 0:
            continue
        if col.startswith('(') and ')' in col:
            range_str = col.strip('()')
            low, high = map(int, range_str.split('-'))
            mid_point = (low + high) / 2
            
            rates.append(mid_point)
            probs.append(prob)
    
    if len(rates) == 0:
        return np.nan, np.nan
    
    # ì •ê·œí™”
    probs = np.array(probs)
    probs = probs / probs.sum()
    rates = np.array(rates)
    
    # ê¸°ëŒ“ê°’
    exp_rate = np.sum(rates * probs)
    
    # í‘œì¤€í¸ì°¨ (ë¶ˆí™•ì‹¤ì„± ì§€í‘œ)
    variance = np.sum(((rates - exp_rate) ** 2) * probs)
    std_dev = np.sqrt(variance)
    
    return exp_rate, std_dev

# ì‚¬ìš©
df[['exp_rate_bp', 'rate_uncertainty']] = df.apply(
    lambda row: calculate_rate_statistics(row.drop('Date')),
    axis=1,
    result_type='expand'
)
```

**ì´ì :**
- `rate_uncertainty`ë¥¼ ì¶”ê°€ ë³€ìˆ˜ë¡œ ì‚¬ìš© ê°€ëŠ¥
- "ì‹œì¥ì´ ì–¼ë§ˆë‚˜ í™•ì‹ í•˜ëŠ”ê°€" ì¸¡ì •

---

## ğŸ“‹ Phase 2: íŒ¨ë„ ë°ì´í„° êµ¬ì¡° ìƒì„±

### ëª©í‘œ êµ¬ì¡°
```
meeting_date | asof_date  | exp_rate_bp | rate_uncertainty | days_to_meeting
-------------|------------|-------------|------------------|----------------
2025-07-30   | 2024-09-12 | 327.5       | 45.2             | 321
2025-07-30   | 2024-09-13 | 325.8       | 44.8             | 320
...
2025-12-10   | 2024-11-08 | 387.2       | 52.1             | 397
2025-12-10   | 2024-11-09 | 385.9       | 51.7             | 396
```

### êµ¬í˜„ ìŠ¤í¬ë¦½íŠ¸

```python
def convert_to_panel(meeting_files_dir, output_file):
    """
    íšŒì˜ë³„ ë³‘í•© íŒŒì¼ë“¤ì„ í•˜ë‚˜ì˜ íŒ¨ë„ ë°ì´í„°ë¡œ ë³€í™˜
    
    Args:
        meeting_files_dir: ë³‘í•© íŒŒì¼ë“¤ì´ ìˆëŠ” ë””ë ‰í† ë¦¬
        output_file: ì¶œë ¥ íŒ¨ë„ íŒŒì¼ëª…
    """
    import glob
    from pathlib import Path
    from datetime import datetime
    
    all_panels = []
    
    # ëª¨ë“  meeting_*_merged.csv íŒŒì¼ ì°¾ê¸°
    pattern = f"{meeting_files_dir}/meeting_*_merged.csv"
    files = glob.glob(pattern)
    
    print(f"ë°œê²¬ëœ íšŒì˜ íŒŒì¼: {len(files)}ê°œ\n")
    
    for filepath in sorted(files):
        # íŒŒì¼ëª…ì—ì„œ íšŒì˜ ë‚ ì§œ ì¶”ì¶œ
        filename = Path(filepath).stem
        # meeting_20251210_merged â†’ 20251210
        meeting_date_str = filename.split('_')[1]
        meeting_date = pd.to_datetime(meeting_date_str, format='%Y%m%d')
        
        print(f"ì²˜ë¦¬ ì¤‘: {meeting_date.date()}")
        
        # ë°ì´í„° ë¡œë“œ
        df = pd.read_csv(filepath)
        df['Date'] = pd.to_datetime(df['Date'])
        
        # í™•ë¥  ë¶„í¬ â†’ ê¸°ëŒ€ê¸ˆë¦¬ ê³„ì‚°
        prob_cols = [c for c in df.columns if c != 'Date']
        
        stats = df[prob_cols].apply(
            calculate_rate_statistics,
            axis=1,
            result_type='expand'
        )
        stats.columns = ['exp_rate_bp', 'rate_uncertainty']
        
        # íŒ¨ë„ êµ¬ì¡° ìƒì„±
        panel = pd.DataFrame({
            'meeting_date': meeting_date,
            'asof_date': df['Date'],
            'exp_rate_bp': stats['exp_rate_bp'],
            'rate_uncertainty': stats['rate_uncertainty']
        })
        
        # days_to_meeting ê³„ì‚°
        panel['days_to_meeting'] = (
            panel['meeting_date'] - panel['asof_date']
        ).dt.days
        
        # ìŒìˆ˜ ì œê±° (ê³¼ê±° ë°ì´í„°)
        panel = panel[panel['days_to_meeting'] >= 0]
        
        all_panels.append(panel)
        print(f"  â†’ {len(panel)}ê°œ ê´€ì¸¡ì¹˜")
    
    # ì „ì²´ ë³‘í•©
    full_panel = pd.concat(all_panels, ignore_index=True)
    full_panel.sort_values(['meeting_date', 'asof_date'], inplace=True)
    
    # ì €ì¥
    full_panel.to_csv(output_file, index=False)
    
    print(f"\n[ì™„ë£Œ] íŒ¨ë„ ë°ì´í„° ìƒì„±: {output_file}")
    print(f"  - ì´ ê´€ì¸¡ì¹˜: {len(full_panel):,}ê°œ")
    print(f"  - íšŒì˜ ìˆ˜: {full_panel['meeting_date'].nunique()}ê°œ")
    print(f"  - ê¸°ê°„: {full_panel['asof_date'].min().date()} ~ {full_panel['asof_date'].max().date()}")
    
    return full_panel

# ì‹¤í–‰
panel = convert_to_panel(
    meeting_files_dir='~/projects/forecast/merged',
    output_file='~/projects/forecast/complete_cme_panel_history.csv'
)
```

---

## ğŸ¯ Phase 3: ì‹¤ì œ FOMC ê¸ˆë¦¬ ë°ì´í„°

### ë°©ë²• 1: ìˆ˜ë™ ì…ë ¥ (ê°„ë‹¨í•˜ê³  ì •í™•)

```python
# actual_fed_rates.py

ACTUAL_FOMC_RATES = {
    # meeting_date: (lower_bp, upper_bp, decision_bp_midpoint)
    '2025-05-07': (450, 475, 462.5),
    '2025-06-18': (450, 475, 462.5),  # ë™ê²°
    '2025-07-30': (425, 450, 437.5),  # -25bp
    '2025-09-17': (425, 450, 437.5),  # ë™ê²°
    '2025-10-29': (425, 450, 437.5),  # ë™ê²°
    '2025-12-10': (425, 450, 437.5),  # ë™ê²° (ê°€ì •)
    # ... 26ë…„ íšŒì˜ë“¤
}

def get_actual_rate(meeting_date):
    """
    ì‹¤ì œ FOMC ê²°ì • ê¸ˆë¦¬ ë°˜í™˜
    
    Args:
        meeting_date: str or datetime, 'YYYY-MM-DD' or datetime
    
    Returns:
        float: ì‹¤ì œ ê¸ˆë¦¬ (bp, ì¤‘ê°„ê°’)
    """
    if isinstance(meeting_date, str):
        meeting_date = pd.to_datetime(meeting_date).strftime('%Y-%m-%d')
    else:
        meeting_date = meeting_date.strftime('%Y-%m-%d')
    
    if meeting_date in ACTUAL_FOMC_RATES:
        return ACTUAL_FOMC_RATES[meeting_date][2]  # ì¤‘ê°„ê°’
    else:
        return np.nan

# íŒ¨ë„ì— ì¶”ê°€
panel['actual_rate_bp'] = panel['meeting_date'].apply(get_actual_rate)
panel['forecast_error'] = panel['exp_rate_bp'] - panel['actual_rate_bp']
```

**ì¥ì :**
- 100% ì •í™•
- ê°„ë‹¨í•˜ê³  ë¹ ë¦„
- ìˆ˜ì • ìš©ì´

**ë‹¨ì :**
- ìˆ˜ë™ ì—…ë°ì´íŠ¸ í•„ìš”

---

### ë°©ë²• 2: FRED API (ìë™í™”)

```python
def fetch_actual_rates_from_fred(fred_api, start_date='2024-01-01'):
    """
    FREDì—ì„œ ì‹¤ì œ Fed Funds Rate ê°€ì ¸ì˜¤ê¸°
    
    FRED ì½”ë“œ:
    - DFF: ì¼ë³„ Effective Federal Funds Rate
    - DFEDTARU: ì—°ì¤€ ëª©í‘œ ê¸ˆë¦¬ ìƒë‹¨
    - DFEDTARL: ì—°ì¤€ ëª©í‘œ ê¸ˆë¦¬ í•˜ë‹¨
    """
    from fredapi import Fred
    
    fred = Fred(api_key=fred_api)
    
    # ëª©í‘œ ê¸ˆë¦¬ (ìƒë‹¨/í•˜ë‹¨)
    upper = fred.get_series('DFEDTARU', observation_start=start_date)
    lower = fred.get_series('DFEDTARL', observation_start=start_date)
    
    # ì¤‘ê°„ê°’ ê³„ì‚°
    target_rate = (upper + lower) / 2
    
    return target_rate

# FOMC íšŒì˜ ë‚ ì§œì— ë§¤í•‘
def map_meeting_to_actual(panel, actual_rates):
    """
    ê° íšŒì˜ì˜ ì‹¤ì œ ê¸ˆë¦¬ ë§¤í•‘
    """
    panel = panel.copy()
    
    def get_rate_at_meeting(meeting_date):
        # íšŒì˜ì¼ ë˜ëŠ” ì§í›„ ì˜ì—…ì¼ì˜ ê¸ˆë¦¬
        try:
            # íšŒì˜ì¼ ì´í›„ 7ì¼ ì´ë‚´ì˜ ê¸ˆë¦¬ (ë°œí‘œ ë°˜ì˜)
            mask = (actual_rates.index >= meeting_date) & \
                   (actual_rates.index <= meeting_date + pd.Timedelta(days=7))
            if mask.any():
                return actual_rates[mask].iloc[0] * 100  # % â†’ bp
        except:
            pass
        return np.nan
    
    panel['actual_rate_bp'] = panel['meeting_date'].apply(get_rate_at_meeting)
    return panel
```

**ì¥ì :**
- ìë™í™” ê°€ëŠ¥
- ì—…ë°ì´íŠ¸ ìš©ì´

**ë‹¨ì :**
- íšŒì˜ì¼ê³¼ ë°œí‘œì¼ ë§¤ì¹­ í•„ìš”
- API ì œí•œ

---

## ğŸ“Š Phase 4: ì‹œì¥ ë°ì´í„° ë¬¸ì œ í•´ê²°

### ë¬¸ì œ: ì¼ë³„ ë°ì´í„°ê°€ ì•„ë‹Œ ê²½ìš° ê²°ì¸¡ì¹˜ ê³¼ë‹¤

#### í•´ê²°ì±… 1: ì¼ë³„ ë³€ìˆ˜ë§Œ ì„ íƒ **[ì¶”ì²œ]**

```python
# ê²°ì¸¡ ë¹„ìœ¨ í™•ì¸
def check_missing_ratio(df, threshold=0.9):
    """
    ê° ë³€ìˆ˜ì˜ ìœ íš¨ ë°ì´í„° ë¹„ìœ¨ í™•ì¸
    
    Args:
        df: DataFrame
        threshold: ìµœì†Œ ìœ íš¨ ë°ì´í„° ë¹„ìœ¨ (0.9 = 90%)
    
    Returns:
        valid_vars: ê¸°ì¤€ í†µê³¼í•œ ë³€ìˆ˜ ë¦¬ìŠ¤íŠ¸
    """
    total = len(df)
    missing_info = []
    
    for col in df.columns:
        if col == 'Date':
            continue
        valid = df[col].notna().sum()
        ratio = valid / total
        missing_info.append({
            'variable': col,
            'valid_count': valid,
            'valid_ratio': ratio,
            'pass': ratio >= threshold
        })
    
    result = pd.DataFrame(missing_info).sort_values('valid_ratio')
    
    print(f"[ê²°ì¸¡ì¹˜ ë¶„ì„] ì´ {len(result)}ê°œ ë³€ìˆ˜")
    print(f"  ê¸°ì¤€: ìœ íš¨ ë°ì´í„° {threshold*100:.0f}% ì´ìƒ\n")
    
    failed = result[~result['pass']]
    passed = result[result['pass']]
    
    if len(failed) > 0:
        print(f"ì œì™¸ ëŒ€ìƒ ({len(failed)}ê°œ):")
        for _, row in failed.iterrows():
            print(f"  âœ— {row['variable']:<30} {row['valid_ratio']:.1%}")
    
    print(f"\nì‚¬ìš© ê°€ëŠ¥ ({len(passed)}ê°œ):")
    for _, row in passed.head(10).iterrows():
        print(f"  âœ“ {row['variable']:<30} {row['valid_ratio']:.1%}")
    
    if len(passed) > 10:
        print(f"  ... (ì™¸ {len(passed)-10}ê°œ)")
    
    return passed['variable'].tolist()

# ì‚¬ìš©
valid_vars = check_missing_ratio(market_data, threshold=0.9)
market_data_clean = market_data[['Date'] + valid_vars]
```

---

#### í•´ê²°ì±… 2: Forward Fill (ì‹ ì¤‘í•˜ê²Œ)

```python
# ê¸ˆë¦¬ ë³€ìˆ˜ëŠ” forward fill í•©ë¦¬ì 
rate_vars = ['US10Y', 'US2Y', 'Baa_Yield', 'SOFR']

for var in rate_vars:
    if var in market_data.columns:
        # ìµœëŒ€ 5ì¼ê¹Œì§€ë§Œ forward fill
        market_data[var] = market_data[var].fillna(method='ffill', limit=5)
```

**ì£¼ì˜:**
- ì´ë²¤íŠ¸ ë³€ìˆ˜ëŠ” ffill í•˜ë©´ ì•ˆë¨! (ë°œí‘œì¼ë§Œ 1)
- ê°€ê²© ë³€ìˆ˜ë„ ffill ìœ„í—˜ (ì¸ìœ„ì  ì—°ì†ì„±)

---

#### í•´ê²°ì±… 3: ì£¼ê°„ ë°ì´í„°ë¡œ ë‹¤ìš´ìƒ˜í”Œë§

```python
# ëª¨ë“  ë°ì´í„°ë¥¼ ì£¼ê°„ìœ¼ë¡œ í†µì¼
market_weekly = market_data.resample('W-FRI').last()

# íŒ¨ë„ë„ ì£¼ê°„ìœ¼ë¡œ
panel_weekly = panel[panel['asof_date'].dt.dayofweek == 4]  # ê¸ˆìš”ì¼ë§Œ
```

**ì¥ì :**
- ê²°ì¸¡ ë¬¸ì œ ì™„í™”
- ë…¸ì´ì¦ˆ ê°ì†Œ

**ë‹¨ì :**
- ê´€ì¸¡ì¹˜ ê°ì†Œ
- ì¼ë³„ ë³€ë™ í¬ì°© ëª»í•¨

---

## ğŸ¯ ìµœì¢… ì¶”ì²œ íŒŒì´í”„ë¼ì¸

```
1. íšŒì˜ë³„ íŒŒì¼ â†’ íŒ¨ë„ ë³€í™˜
   â””â”€ convert_to_panel()
   â””â”€ ê¸°ëŒ€ê¸ˆë¦¬: ê°€ì¤‘í‰ê· 
   â””â”€ ë¶ˆí™•ì‹¤ì„±: í‘œì¤€í¸ì°¨

2. ì‹¤ì œ ê¸ˆë¦¬ ì¶”ê°€
   â””â”€ ìˆ˜ë™ ì…ë ¥ (actual_fed_rates.py)
   â””â”€ ë˜ëŠ” FRED API

3. ì‹œì¥ ë°ì´í„° ì •ì œ
   â””â”€ ê²°ì¸¡ 90% ì´ìƒ ë³€ìˆ˜ë§Œ ì‚¬ìš©
   â””â”€ ê¸ˆë¦¬: forward fill (ìµœëŒ€ 5ì¼)
   â””â”€ ì´ë²¤íŠ¸: 0 ì±„ìš°ê¸°

4. ìµœì¢… ë³‘í•©
   â””â”€ panel + market_data (left join)
   â””â”€ ë‚ ì§œ ê¸°ì¤€ (asof_date)

5. íŒŒìƒë³€ìˆ˜ ìƒì„±
   â””â”€ d_Exp_Rate (ì¼ë³„ ë³€í™”)
   â””â”€ Horizon êµ¬ê°„
   â””â”€ Returns, Diffs
```

---

## ğŸ“ ë‹¤ìŒ ë‹¨ê³„

1. **ë¨¼ì € í™•ì¸:** ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ ê¸°ëŒ€ê¸ˆë¦¬ë¥¼ ê³„ì‚°í• ì§€ ê²°ì •
   - ê°€ì¤‘í‰ê· ? ì¤‘ìœ„ìˆ˜? (ì €ëŠ” ê°€ì¤‘í‰ê·  ì¶”ì²œ)

2. **íŒ¨ë„ ë³€í™˜ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±**
   - ìœ„ì˜ `convert_to_panel()` êµ¬í˜„

3. **ì‹¤ì œ ê¸ˆë¦¬ ë°ì´í„° ì¤€ë¹„**
   - ìˆ˜ë™ ì…ë ¥ìœ¼ë¡œ ì‹œì‘ (ë¹ ë¥´ê³  ì •í™•)

4. **ì‹œì¥ ë°ì´í„° ì ê²€**
   - `collect_macro_finance_v2.py` ì‹¤í–‰
   - ê²°ì¸¡ ë¹„ìœ¨ í™•ì¸

ì¤€ë¹„ ë˜ë©´ ì•Œë ¤ì£¼ì„¸ìš”! ê° ë‹¨ê³„ë³„ ì½”ë“œë¥¼ ì‘ì„±í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ğŸš€

