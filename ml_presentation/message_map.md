# 메시지 슬라이드 맵

> PPT 생성용 세부 슬라이드 맵
> 원칙: 번호 1개 = 슬라이드 1장 = 메시지 1개
> 기존 `slide_outline.md`는 차시 흐름 구조도로 유지
>
> **AI 활용 방법**
> - 이 파일 → "차시 흐름 파악" + AI에게 전체 흐름 전달 (스토리 라인 확인용)
> - `slide_content.md` → 슬라이드 1장씩 상세 생성 (키워드·비주얼 포함 명령어 원고)

---

## 1차시 — 왜 ML인가 (23장)

### [도입] 나는 왜 여기 서 있나

| 번호 | 슬라이드 제목 | 핵심 메시지 |
|------|-------------|------------|
| 1-01 | 야구공 하나에 숨어있는 질문 | "왜 이 타자는 이 구종에만 약한가?" |
| 1-02 | 10년의 여정 | 인터넷 서칭 → R 회귀 → GPT → ML → 에이전틱 AI |
| 1-03 | 도구는 바뀌었고, 목적은 하나 | 결국 '설득'으로 수렴 |

### [배경] 통계의 시대 → 전환점 → ML 탄생

| 번호 | 슬라이드 제목 | 핵심 메시지 |
|------|-------------|------------|
| 1-04 | 오늘 아침 AI가 내린 결정들 | 넷플릭스·신용카드·네비게이션 — 공통점은? |
| 1-05 | 데이터 폭발 | 2025년 하루 생성 데이터 120 제타바이트 |
| 1-06 | 연산력 혁명 | GPU가 가능하게 한 것 |
| 1-07 | 통계학의 시대 | 인간이 규칙을 직접 설계하던 시절 |
| 1-08 | 통계학의 한계 | 변수 100개 → 수식 수천 개, 손이 따라가지 못한다 |
| 1-09 | 전환점 | "기계가 스스로 규칙을 찾을 수 없을까?" |
| 1-10 | ML의 정의 | 데이터에서 패턴을 스스로 추출하는 알고리즘 |

### [개념] 상관관계의 힘

| 번호 | 슬라이드 제목 | 핵심 메시지 |
|------|-------------|------------|
| 1-11 | 무릎이 아프면 비가 온다 | 경험적 패턴 = 상관관계 |
| 1-12 | 기압 → 활막팽창 → 통증 | 상관관계에서 인과관계로 가는 단계 |
| 1-13 | 상관관계는 가설의 문 | 상관 → 가설 → 검증 → 인과 4단계 흐름도 |
| 1-14 | 통계학 vs ML | 인과 추구 vs 예측 우선 — 무엇이 근본적으로 다른가 |

### [개념] ML이 뭘 하는가

| 번호 | 슬라이드 제목 | 핵심 메시지 |
|------|-------------|------------|
| 1-15 | ML이 허용한 것: 블랙박스 | 왜 그렇게 예측하는지 몰라도 된다 |
| 1-16 | ML이 답하는 질문 지도 | 회귀 / 분류 / 군집 / 해석 4분류 |
| 1-17 | 금융에서의 ML | 신용 리스크, 이상거래 탐지 |
| 1-18 | 마케팅·의료·스포츠에서의 ML | 이탈 예측, 암 진단, 타구 분석 |
| 1-19 | LLM 시대에도 ML인가? | 실무 데이터 대부분은 여전히 테이블 형태 |

### [현재] 2026년, 어디까지 왔나

| 번호 | 슬라이드 제목 | 핵심 메시지 |
|------|-------------|------------|
| 1-20 | LLM 내부도 ML이다 | GPT와 XGBoost의 공통점과 차이 |
| 1-21 | 2026 신호: 멀티에이전트 급증 | Gartner — 멀티에이전트 문의 1,445% 급증 (2024→2025) |
| 1-22 | ML이 AI 시스템의 부품이 된다 | 에이전틱 AI 구조도: 에이전트 → ML 예측 모듈 → 도구 |
| 1-23 | 예고: 자유에는 대가가 따른다 | 다음 차시 연결 |

---

## 2차시 — 자유에는 대가가 따른다 (25장)

### [출발] 통계의 딜레마에서 ML로

| 번호 | 슬라이드 제목 | 핵심 메시지 |
|------|-------------|------------|
| 2-01 | 선형회귀가 다중공선성을 두려워하는 이유 | X₁·X₂가 연관되면 계수 해석 불가 |
| 2-02 | 다중공선성의 결과 | "계산 거부" — 수식이 무너질 때 |
| 2-03 | ML의 대답 | "결과만 맞으면 되는 거 아닌가요?" |
| 2-04 | 자유의 이면 | 블랙박스 허용의 대가 |

### [문제] 과적합 — 자유가 만든 함정

| 번호 | 슬라이드 제목 | 핵심 메시지 |
|------|-------------|------------|
| 2-05 | 기출문제를 외운 학생 | 과적합의 직관: 외우는 것 ≠ 이해하는 것 |
| 2-06 | 학습 데이터의 함정 | 훈련 오차 ↓ → 테스트 오차 ↑ |
| 2-07 | 과소적합도 문제다 | 너무 단순한 모델의 실패 |
| 2-08 | Bias-Variance 트레이드오프 예고 | 복잡도를 올릴수록 생기는 갈등 |

### [해결] 규제화

| 번호 | 슬라이드 제목 | 핵심 메시지 |
|------|-------------|------------|
| 2-09 | 규제화의 등장 | 오차 최소화 + 계수 크기 제한 동시 |
| 2-10 | Ridge — 계수를 억제한다 | 0에 가깝지만 0은 아님 → 모든 변수 유지 |
| 2-11 | Lasso — 계수를 제거한다 | 정확히 0이 됨 → 불필요한 변수 탈락 |
| 2-12 | 언제 Ridge, 언제 Lasso? | 변수가 많고 대부분 유의미 → Ridge / 변수 선택 필요 → Lasso |
| 2-13 | Bias 희생으로 Variance를 줄인다 | 규제화의 진짜 의미 — 트레이드오프 곡선 |

### [평가] 데이터 분할과 지표 선택

| 번호 | 슬라이드 제목 | 핵심 메시지 |
|------|-------------|------------|
| 2-14 | 분류 문제 맛보기 | 회귀 → 분류 전환 |
| 2-15 | Confusion Matrix | TP/FP/FN/TN — 2×2 표의 의미 |
| 2-16 | 정확도의 함정 | 암 진단 99% 정확도가 쓸모없을 때 |
| 2-17 | Train / Validation / Test | 왜 세 개로 나누나 — 역할이 다르다 |
| 2-18 | Test는 딱 한 번만 | 이 규칙을 어기면 Data Leakage |
| 2-19 | K-Fold 교차검증 | 데이터를 최대한 활용하는 법 |
| 2-20 | Recall vs Precision vs AUC | 언제 어떤 지표인가 — 상황별 선택 기준 |

### [실무 함정] Data Leakage

| 번호 | 슬라이드 제목 | 핵심 메시지 |
|------|-------------|------------|
| 2-21 | Data Leakage란 무엇인가 | 미래 정보가 과거 학습에 섞이는 위험 |
| 2-22 | Leakage의 실제 패턴 | 타임라인 그래프 — 어디서 오염이 일어나는가 |
| 2-23 | 배포 후 망하는 이유 | 테스트 성능 좋아도 실제 환경에서 실패 |
| 2-24 | 실무 체크리스트 | 모델 만들기 전 확인할 것 4가지 |
| 2-25 | 예고: 직선으로 안 되는 세상 | 다음 차시 연결 |

---

## 3차시 — 나무로 규칙을 만든다 (22장)

### [전환] 비선형 세상

| 번호 | 슬라이드 제목 | 핵심 메시지 |
|------|-------------|------------|
| 3-01 | 직선이 못 잡는 패턴들 | 비선형 곡선 — 회귀직선의 한계 |
| 3-02 | 비선형 문제에 ML이 답하는 방법 | 접근 방식의 갈림길 |

### [개념] 의사결정나무

| 번호 | 슬라이드 제목 | 핵심 메시지 |
|------|-------------|------------|
| 3-03 | 스무고개로 분류한다 | 의사결정나무의 직관 |
| 3-04 | IF-THEN 규칙 구조 | 노드 → 분기 → 리프 시각화 |
| 3-05 | 어떻게 나눌 것인가 | 분기 기준: Gini 불순도 / 정보 이득 |
| 3-06 | 의사결정나무의 강점 | 해석 가능 / 전처리 불필요 / 직관적 규칙 |
| 3-07 | 의사결정나무의 약점 | 데이터 1개 바뀌면 트리 전체 구조 변화 |
| 3-08 | 불안정성 시각화 | 같은 데이터, 다른 트리 |

### [핵심] Bias-Variance Tradeoff

| 번호 | 슬라이드 제목 | 핵심 메시지 |
|------|-------------|------------|
| 3-09 | Bias-Variance Tradeoff | 2×2 매트릭스 — 모든 모델 선택의 나침반 |
| 3-10 | 고편향 모델 | 너무 단순해서 패턴을 못 잡는다 |
| 3-11 | 고분산 모델 | 너무 민감해서 노이즈까지 학습한다 |
| 3-12 | 해결 전략 | 여러 모델을 합치면? |

### [해결] 앙상블 — Bagging

| 번호 | 슬라이드 제목 | 핵심 메시지 |
|------|-------------|------------|
| 3-13 | Bagging의 철학 | 병렬 학습으로 분산을 줄인다 |
| 3-14 | Bootstrap Sampling | 복원 추출로 다양한 학습셋 만들기 |
| 3-15 | 랜덤 포레스트: 나무에서 숲으로 | 나무 N개의 다수결 투표 |
| 3-16 | 랜덤성 두 가지 | 데이터 샘플링 + 변수 랜덤 선택 |
| 3-17 | 변수 중요도 | 어떤 특성이 핵심인가 |

### [실무] 나무가 실제로 하는 일

| 번호 | 슬라이드 제목 | 핵심 메시지 |
|------|-------------|------------|
| 3-18 | 실무 사례 1 — 대출 심사 | Decision Tree: 해석 가능한 승인 규칙 |
| 3-19 | 실무 사례 2 — 이상거래 탐지 | Random Forest: 패턴 감지 |
| 3-20 | 단일 나무 vs 숲 | 무엇이 달라지는가 |
| 3-21 | 랜덤 포레스트의 한계 | 속도 / 해석력 / 순차 패턴 |
| 3-22 | 예고: 나무 하나로도 한계가 있다 | 다음 차시 연결 |

---

## 4차시 — 오답 노트 공부법 (25장)

### [출발] Baseline의 중요성

| 번호 | 슬라이드 제목 | 핵심 메시지 |
|------|-------------|------------|
| 4-01 | 항상 Baseline부터 | 단순한 것이 기준점 — 얼마나 나아졌는가 |
| 4-02 | DummyClassifier 87% vs 복잡 모델 89% | 2% 향상을 위해 쓸 가치가 있는가? |

### [개념] Boosting 철학

| 번호 | 슬라이드 제목 | 핵심 메시지 |
|------|-------------|------------|
| 4-03 | Boosting의 철학 | 틀린 곳을 집중 공략한다 — 오답 노트 비유 |
| 4-04 | AdaBoost | 오답에 가중치를 올려 다음 모델이 집중하게 한다 |
| 4-05 | 순차 학습 구조 | 이전 모델의 실수가 다음 모델의 입력 |
| 4-06 | 약한 학습기들의 합 | 집단 지성의 수직 버전 |

### [핵심] GBM — 잔차를 학습한다

| 번호 | 슬라이드 제목 | 핵심 메시지 |
|------|-------------|------------|
| 4-07 | GBM의 핵심 아이디어 | 잔차를 다음 모델이 배운다 |
| 4-08 | 잔차 학습 3단계 | 예측 → 오차 계산 → 오차를 새 정답으로 |
| 4-09 | 학습률 — 얼마나 크게 배울까 | 보폭의 크기 |
| 4-10 | 학습률이 너무 크면 | 진동, 수렴 실패 |
| 4-11 | 학습률이 너무 작으면 | 느림, 과소적합 위험 |
| 4-12 | Early Stopping — 언제 멈출까 | Validation Loss 꺾이는 지점 |

### [실무 표준] XGBoost

| 번호 | 슬라이드 제목 | 핵심 메시지 |
|------|-------------|------------|
| 4-13 | XGBoost의 탄생 | GBM의 한계: 느리다, 과적합에 취약하다 |
| 4-14 | XGBoost가 빠른 이유 | 병렬 처리 + 희소 데이터 최적화 |
| 4-15 | XGBoost가 정확한 이유 | 규제화 내장 (L1 + L2) |
| 4-16 | Kaggle 우승 공식 | 왜 XGBoost인가 |
| 4-17 | 실무 사례 | 광고 클릭률 예측, 금융 부도 예측 |

### [진단] 학습 곡선 읽기

| 번호 | 슬라이드 제목 | 핵심 메시지 |
|------|-------------|------------|
| 4-18 | 학습 곡선 읽기 | 과적합 / 과소적합 / 수렴 실패 3케이스 |
| 4-19 | 진단 → 파라미터 조정 | n_estimators, max_depth, learning_rate |

### [미래] XGBoost의 도전자

| 번호 | 슬라이드 제목 | 핵심 메시지 |
|------|-------------|------------|
| 4-20 | 테이블 파운데이션 모델의 등장 | Large Tabular Models (TabPFN) — 2025년 등장 |
| 4-21 | TabPFN — 3초 만에 4시간 튜닝을 이긴다 | 소·중규모 데이터셋에서 XGBoost 능가 |
| 4-22 | 언제 XGBoost, 언제 TabPFN? | 데이터 크기가 기준 — 10만 행이 분기점 |

### [정리] 모델 선택 가이드

| 번호 | 슬라이드 제목 | 핵심 메시지 |
|------|-------------|------------|
| 4-23 | Bagging vs Boosting | 병렬(분산↓) vs 직렬(편향↓) |
| 4-24 | 전체 모델 선택 가이드 | 데이터·목표·크기별 의사결정 치트시트 |
| 4-25 | 예고: 잘 맞추면 끝인가? | 다음 차시 연결 |

---

## 5차시 — 설명할 수 있어야 쓸 수 있다 (22장)

### [문제 제기] ML의 세 가지 한계

| 번호 | 슬라이드 제목 | 핵심 메시지 |
|------|-------------|------------|
| 5-01 | 잘 맞추면 끝인가? | 3가지 한계 — 블랙박스 / 편향 / 상관≠인과 |
| 5-02 | 한계 1: 블랙박스 | 왜 이런 예측을 했는지 설명 못 한다 |
| 5-03 | 한계 2: 데이터 편향 | AI가 차별을 학습할 수 있다 |
| 5-04 | 한계 3: 상관 ≠ 인과 | 예측이 정확해도 이유를 모른다 |
| 5-05 | Distribution Shift | 학습 환경과 실제 환경이 달라질 때 |

### [해결] SHAP — 블랙박스를 열다

| 번호 | 슬라이드 제목 | 핵심 메시지 |
|------|-------------|------------|
| 5-06 | 블랙박스를 열어라 | SHAP의 등장 |
| 5-07 | SHAP Value 직관 | 이 예측에 기여한 변수를 지목한다 |
| 5-08 | 워터폴 차트 읽기 | 변수별 기여도 시각화 |
| 5-09 | 전역 해석 vs 국소 해석 | Summary Plot vs Force Plot |

### [공정성] 데이터 편향

| 번호 | 슬라이드 제목 | 핵심 메시지 |
|------|-------------|------------|
| 5-10 | 채용 AI 편향 사례 | 실제 발생한 일 — Amazon 채용 시스템 |
| 5-11 | 편향의 원인 | 편향된 학습 데이터가 그대로 학습된다 |
| 5-12 | 공정성 지표 | 모델이 집단 간 동등하게 오류를 내는가 |

### [인과] 상관은 가설이다 — 1차시 심화

| 번호 | 슬라이드 제목 | 핵심 메시지 |
|------|-------------|------------|
| 5-13 | 아이스크림과 익사 사고 | 상관관계 함정 — 교란변수 |
| 5-14 | 무릎 이야기의 결말 | 진짜 원인 찾기 (1차시 연결) |
| 5-15 | 인과 추론으로 가는 길 | 다음 단계 예고 |

### [설득] 시각화

| 번호 | 슬라이드 제목 | 핵심 메시지 |
|------|-------------|------------|
| 5-16 | 시각화로 설득하기 | 주장 → 근거 → 시각화 3단 구조 |
| 5-17 | 차트 유형 선택법 | 비교 / 추세 / 분포 / 관계 |
| 5-18 | "좋아졌다" 대신 숫자로 | Before/After 정량 표현 습관 |

### [마무리] 사고 흐름 + 다음 단계

| 번호 | 슬라이드 제목 | 핵심 메시지 |
|------|-------------|------------|
| 5-19 | 다음 공부 로드맵 | sklearn → XGBoost → SHAP → 에이전틱 AI |
| 5-20 | 에이전틱 AI 시대의 ML 역할 | 에이전트가 ML 예측 모듈을 호출한다 |
| 5-21 | 전체 사고 흐름 | 목적 → 모델 → 평가 → 설명 → 제안 파이프라인 |
| 5-22 | 여정의 마무리 | 1차시 타임라인과 수미상관 — "도구는 바뀌었고 목적은 하나" |

---

## 6차시 — EDA + 과제 (22장)

### [왜 EDA인가]

| 번호 | 슬라이드 제목 | 핵심 메시지 |
|------|-------------|------------|
| 6-01 | 왜 EDA가 모델보다 먼저인가 | "쓰레기 IN → 쓰레기 OUT" |
| 6-02 | EDA의 목적 | 모델을 돌리기 전에 데이터를 이해한다 |
| 6-03 | 데이터 진단 체크리스트 | 결측 / 이상치 / 중복 / 타입 4항목 |

### [결측치]

| 번호 | 슬라이드 제목 | 핵심 메시지 |
|------|-------------|------------|
| 6-04 | 결측치 탐색 | 얼마나? 어디에? 어떤 패턴으로? |
| 6-05 | 결측 히트맵 읽기 | 열 vs 행 분포 — 구조적 결측인가? |
| 6-06 | 결측 처리 의사결정 | 5% / 30% 임계값 기준 |

### [이상치]

| 번호 | 슬라이드 제목 | 핵심 메시지 |
|------|-------------|------------|
| 6-07 | 이상치 탐색 | 박스플롯으로 먼저 본다 |
| 6-08 | 이상치의 두 얼굴 | 에러인가, 사건인가? |
| 6-09 | 도메인 확인 먼저 | 제거 전에 물어봐야 할 것들 |
| 6-10 | 이상치 처리 의사결정 흐름 | 제거 / 대체 / 유지 |

### [분포·관계 파악]

| 번호 | 슬라이드 제목 | 핵심 메시지 |
|------|-------------|------------|
| 6-11 | 수치형 변수 분포 | 히스토그램 — 정규성, 왜도 확인 |
| 6-12 | 범주형 변수 분포 | 막대 그래프 — 불균형 클래스 경고 |
| 6-13 | 상관 히트맵 읽기 | 강한 상관, 다중공선성 경고 |
| 6-14 | 산점도 매트릭스 | 변수 쌍 관계 한눈에 |

### [파생변수]

| 번호 | 슬라이드 제목 | 핵심 메시지 |
|------|-------------|------------|
| 6-15 | 파생 변수 — 숨겨진 패턴을 만든다 | 도메인 지식을 feature로 변환 |
| 6-16 | 시간 기반 파생 변수 | 시간대 / 요일 / 계절 |
| 6-17 | 비율·차이 기반 파생 변수 | "어제 대비 오늘" 같은 변화량 |

### [Before/After 원칙]

| 번호 | 슬라이드 제목 | 핵심 메시지 |
|------|-------------|------------|
| 6-18 | Before/After 비교가 전부다 | 같은 축 / 같은 단위 / 숫자 증명 |
| 6-19 | 흔한 실수 4가지 | 레드 경고 카드 |
| 6-20 | EDA → ML 연결고리 | 전처리 완료 → 모델 → 의미 있는 결과 |

### [과제]

| 번호 | 슬라이드 제목 | 핵심 메시지 |
|------|-------------|------------|
| 6-21 | 과제 시나리오 | 서울 자전거 수요 분석가 역할 |
| 6-22 | 10문항 흐름 + 제출 기준 | 스키마 → 결측 → 이상치 → 파생변수 → 인사이트 |

---

## 총 슬라이드 수

| 차시 | 장 수 |
|------|-------|
| 1차시 | 23 |
| 2차시 | 25 |
| 3차시 | 22 |
| 4차시 | 25 |
| 5차시 | 22 |
| 6차시 | 22 |
| **합계** | **139** |
