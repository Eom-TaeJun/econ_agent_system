# 슬라이드 콘텐츠 명세

> PPT 직접 생성용 텍스트 명세
> 원칙: 제목 = 결과·인사이트 전달 (주제 나열 X) | 본문 = 명사구 3개 이내 | ~한다/했다 표현 제외

---

## AI 프롬프트 활용법

이 파일의 각 슬라이드 항목은 **AI에게 슬라이드 생성을 요청하는 명령어 원고**입니다.
`**키워드**` → AI가 고를 이미지·개념의 범위 지정
`**비주얼**` → 레이아웃과 그래픽 유형 지정 (흐름도·차트·다이어그램 등)

### 단일 슬라이드 생성

```
다음 내용으로 PPT 슬라이드 1장 만들어줘.

[슬라이드 항목 복사·붙여넣기]

스타일:
- 비율: 16:9
- 배경: 짙은 남색(#1C2833) 또는 흰색
- 제목: 굵게, 40~52pt
- 본문: 명사구, 수치는 강조 색(노랑 또는 주황)
- [비주얼] 태그 기준으로 그래픽 배치
- 언어: 한국어 (영어 용어는 원어 유지)
```

### 차시 흐름 전달 (message_map.md 연계)

```
다음은 1차시 슬라이드 흐름이야. 번호 순서로 스토리가 이어져.

[message_map.md 해당 차시 표 복사·붙여넣기]

이 흐름에 맞게 1-01부터 순서대로 슬라이드를 생성해줘. 각 번호 = 1장.
```

### 연속 슬라이드 (3~5장 묶음) 생성

```
아래 슬라이드 [N]장을 일관된 디자인(같은 색상·폰트·레이아웃)으로 만들어줘.

[슬라이드 항목 N개 복사·붙여넣기]
```

### 비주얼 유형 태그 → AI 지시 대응표

| 태그 | AI에게 전달하는 의미 |
|------|----------------------|
| `[다이어그램]` | 흐름도·개념 연결 구조 (화살표, 노드) |
| `[차트]` | 데이터 시각화 (막대·꺾은선·파이) |
| `[타임라인]` | 시간 순서 수평 배치 |
| `[비교]` | 좌우 대칭 or Before/After 레이아웃 |
| `[이미지]` | 배경·맥락 사진 또는 일러스트 |
| `[아이콘]` | 심플 아이콘 3~4개 격자 배치 |
| `[인포그래픽]` | 수치 강조형 비주얼 (크기·색상으로 값 표현) |
| `[코드]` | 코드 블록 + 라인 하이라이트 |
| `[애니메이션]` | 단계별 등장 (빌드업 효과 필요) |
| `[텍스트 중심]` | 텍스트 레이아웃만, 그래픽 최소 |

---

## 문체 가이드

| 항목 | 규칙 | 예시 |
|------|------|------|
| 제목 | 결과·인사이트 선언 or 질문형 | "3초 만에 4시간 튜닝을 이긴다" |
| 본문 | 명사구 / 짧은 대구 / 수치 강조 | "변수 100개 → 수식 수천 개" |
| 금지 표현 | ~한다, ~했다, ~입니다, ~합니다 | |
| 통계/수치 | 크게, 색상 강조로 배치 | `1,445%` |
| 영어 용어 | 공인 명칭 유지 (XGBoost, SHAP 등) | |
| 비주얼 설명 | `[유형]` 태그로 표기 | `[다이어그램]`, `[차트]`, `[이미지]` |

---

## 1차시 — 왜 ML인가

---

### 1-01
**제목**: "왜 이 타자는 이 구종에만 약한가?"
**본문**:
- 타율 0.310 타자 / 특정 구종에서만 0.180
- 눈으로 보이지 않던 것, 데이터로 보이기 시작
- 데이터가 질문의 방식을 바꾼다

**비주얼**: `[이미지]` 타구 히트맵 (구종별 타율 색상 차이) + 타자 실루엣
**키워드**: `데이터` `패턴` `질문`

---

### 1-02
**제목**: 10년의 여정
**본문**: `[타임라인 비주얼로 전달, 텍스트 최소화]`
- ~10년대: 인터넷 서칭
- 2020년대 초: R 회귀분석
- 2023: GPT 드래그드롭
- 2024: ML 모델링
- 2026: 에이전틱 AI

**비주얼**: `[타임라인]` 수평 타임라인 + 연도별 도구 아이콘
**키워드**: `진화` `도구` `10년`

---

### 1-03
**제목**: 도구는 바뀌었고, 목적은 하나
**본문**:
- 좌: 인터넷 서칭 → R → GPT → ML → Agent
- 우: 모든 화살표가 "설득"으로 수렴
- 도구가 달라져도 목적은 동일

**비주얼**: `[다이어그램]` 좌측 도구 목록 + 우측 "설득" 수렴 화살표
**키워드**: `설득` `목적` `일관성`

---

### 1-04
**제목**: 오늘 아침 AI가 내린 결정들
**본문**:
- 넷플릭스: 당신을 위한 콘텐츠 추천
- 신용카드: 이상 결제 승인·차단
- 네비게이션: 최적 경로 실시간 계산
- 공통점: ?

**비주얼**: `[아이콘]` 앱 3개 아이콘 + 가운데 "공통점은?" 질문
**키워드**: `AI` `일상` `결정`

---

### 1-05
**제목**: 데이터 폭발: 지금 이 순간에도
**본문**:
- 2025년 하루 생성 데이터: **120 제타바이트**
- 10년 전 대비: **60배**
- 스마트폰 1대: 하루 1.5GB 생성

**비주얼**: `[차트]` 지수 성장 곡선 (2000~2025년 데이터량)
**키워드**: `제타바이트` `폭발` `60배`

---

### 1-06
**제목**: GPU가 바꾼 것
**본문**:
- CPU: 복잡한 연산, 소수 코어 순차 처리
- GPU: 단순 연산, 수천 코어 병렬 처리
- 2012, AlexNet: GPU로 이미지 인식 오류 절반으로

**비주얼**: `[비교]` CPU 4코어 vs GPU 수천 코어 시각화
**키워드**: `GPU` `병렬` `2012`

---

### 1-07
**제목**: 인간이 규칙을 설계하던 시대
**본문**:
- 통계학자: 변수 선택 → 수식 설계 → 가정 검정 → 해석
- 강점: 원인-결과 명확
- 한계: 변수가 늘면 수식이 폭발

**비주얼**: `[이미지]` 칠판 가득 수식을 쓰는 연구자 (또는 수식 다이어그램)
**키워드**: `통계` `규칙 설계` `인간`

---

### 1-08
**제목**: 변수 100개 → 수식은 몇 개?
**본문**:
- 변수 10개: 수십 개 수식
- 변수 100개: 수천 개 + 상호작용 항
- "인간의 손이 따라갈 수 없다"

**비주얼**: `[차트]` 변수 수 증가 → 복잡도 지수 폭발 곡선
**키워드**: `복잡도` `한계` `폭발`

---

### 1-09
**제목**: "기계가 스스로 규칙을 찾을 수 없을까?"
**본문**:
- 1950년대: 튜링의 질문
- 1980년대: 신경망 첫 시도
- 2012년: 딥러닝 돌파구
- 전환: 인간이 규칙 설계 → 기계가 규칙 발견

**비주얼**: `[타임라인]` 통계 시대 → 전환점 → ML 시대 화살표
**키워드**: `전환점` `1950` `2012`

---

### 1-10
**제목**: 머신러닝이란
**본문**:
- 데이터를 보여주면
- 패턴을 스스로 찾고
- 새 데이터에 적용

**비주얼**: `[다이어그램]` 데이터 → [ML 모델] → 예측 플로우
**키워드**: `패턴` `학습` `자동`

---

### 1-11
**제목**: 무릎이 아프면 비가 온다
**본문**:
- "할머니가 무릎으로 날씨를 맞힌다"
- 데이터 없이도 패턴 인식
- 인간의 경험 = 비공식 상관관계 모델

**비주얼**: `[이미지]` 어르신 무릎 + 흐린 하늘
**키워드**: `패턴` `경험` `상관관계`

---

### 1-12
**제목**: 기압이 떨어지면 무릎이 아프다
**본문**:
- 상관관계: "비 오는 날 아프다"
- 인과관계: 기압 ↓ → 관절 압력 불균형 → 활막 팽창 → 통증
- 메커니즘을 알면 예방도 가능

**비주얼**: `[다이어그램]` 상관(좌) → 인과 단계(우) 2단 비교
**키워드**: `인과관계` `메커니즘` `기압`

---

### 1-13
**제목**: 상관관계는 가설의 문 ⭐
**본문**:
① 현상 관찰 (무릎이 아프다)
② 상관관계 발견 (비 오는 날)
③ 가설 수립 (기압 변화?)
④ 인과관계 검증 (의학 연구)

**비주얼**: `[다이어그램]` 4단계 흐름도 (화살표 연결, 각 단계 색상 구분)
**키워드**: `상관` `가설` `인과`

---

### 1-14
**제목**: 통계학 vs 머신러닝
**본문**:

|  | 통계학 | 머신러닝 |
|--|--------|----------|
| 목표 | 원인 규명 | 예측 최적화 |
| 블랙박스 | 허용 안 함 | 허용 |
| 강점 | 해석 | 정확도 |

**비주얼**: `[비교표]` 2열 대조 표 (색상 구분)
**키워드**: `해석` `예측` `차이`

---

### 1-15
**제목**: ML이 열어준 것: 블랙박스 허용
**본문**:
- 통계: 계수 하나하나 해석 필수
- ML: 예측만 정확하면 OK
- 새로운 질문: "왜인지 몰라도 맞으면 쓸 수 있는가?"

**비주얼**: `[이미지]` Input → [잠긴 박스] → Output 화살표
**키워드**: `블랙박스` `예측` `허용`

---

### 1-16
**제목**: ML이 답하는 4가지 질문
**본문**:
- 회귀: "얼마나?" → 집값, 매출 예측
- 분류: "어느 쪽?" → 스팸, 이탈 예측
- 군집: "비슷한 것끼리?" → 고객 세분화
- 해석: "왜?" → SHAP, 변수 중요도

**비주얼**: `[다이어그램]` 4분면 (각 사분면에 아이콘)
**키워드**: `회귀` `분류` `군집` `해석`

---

### 1-17
**제목**: 금융: ML이 지키는 것
**본문**:
- 신용 리스크 예측: 대출 부도 확률 → 승인·거절
- 이상거래 탐지: 초당 수천 건 실시간 분류
- 알고리즘 트레이딩: 시장 패턴 실시간 감지

**비주얼**: `[아이콘 카드]` 카드·그래프·방패 3칸
**키워드**: `리스크` `탐지` `실시간`

---

### 1-18
**제목**: ML, 어디에 쓰이나
**본문**:
- 마케팅: 이탈 예측, 개인화 추천
- 의료: 암 조기 진단, 신약 후보 탐색
- 스포츠: 타구 분석, 경기 전략 최적화

**비주얼**: `[카드]` 3개 도메인 카드 (각 아이콘)
**키워드**: `도메인` `응용` `범용`

---

### 1-19
**제목**: GPT가 있는데 왜 ML인가?
**본문**:
- 실무 데이터의 80%: 테이블 형태
- GPT: 비정형 텍스트·이미지에 강함
- XGBoost: 테이블 데이터 예측에 여전히 강함
- 두 가지가 함께 쓰인다

**비주얼**: `[비교]` GPT 아이콘 ↔ 테이블 데이터 대비 다이어그램
**키워드**: `LLM` `테이블` `공존`

---

### 1-20
**제목**: GPT도 결국 ML이다
**본문**:
- GPT: 텍스트 데이터로 다음 단어 예측 학습
- XGBoost: 테이블 데이터로 수치 예측 학습
- 공통점: 데이터 → 패턴 → 예측

**비주얼**: `[다이어그램]` GPT와 XGBoost 공통 구조 (데이터→학습→예측)
**키워드**: `LLM` `공통구조` `패턴`

---

### 1-21
**제목**: 2026 신호
**본문**:
- **1,445%** — Gartner 멀티에이전트 문의 급증
- 기간: 2024 Q1 → 2025 Q2
- 의미: AI가 단독 도구에서 팀으로 진화

**비주얼**: `[인포그래픽]` 1,445% 숫자 대형 강조 + Gartner 출처
**키워드**: `에이전트` `1,445%` `팀`

---

### 1-22
**제목**: ML이 AI 시스템의 부품이 된다
**본문**:
사용자 → 에이전트(LLM) → ML 예측 모듈 → 외부 도구

- 에이전트: 판단·계획·조율
- ML 모듈: 수치 예측, 이상 탐지, 분류
- 결합: LLM이 못하는 정확한 수치 예측을 ML이 담당

**비주얼**: `[구조도]` 4단계 플로우 (사용자→에이전트→ML→도구)
**키워드**: `에이전트` `모듈` `구조`

---

### 1-23
**제목**: 다음 차시: 자유에는 대가가 따른다
**본문**:
- ML이 블랙박스를 허용한 대가
- 과적합: 모델이 외울 때 생기는 일
- 규제화: 학습에 제동을 거는 법

**비주얼**: `[아이콘]` 경고 아이콘 + 다음 차시 키워드 3개
**키워드**: `과적합` `규제화` `대가`

---

## 2차시 — 자유에는 대가가 따른다

---

### 2-01
**제목**: 선형회귀의 딜레마
**본문**:
- Y = a₁X₁ + a₂X₂ + ...
- X₁과 X₂가 서로 연관되면?
- 계수 a₁, a₂의 의미가 무너진다

**비주얼**: `[다이어그램]` X₁·X₂ 상관 산점도 + 수식 무너지는 표현
**키워드**: `다중공선성` `계수` `해석`

---

### 2-02
**제목**: 변수들이 얽히면 수식이 무너진다
**본문**:
- 계수 불안정: 데이터 조금만 바뀌어도 계수 급변
- 표준오차 폭발: 유의성 판단 불가
- 부호 역전: "양수인데 음수로 추정"

**비주얼**: `[차트]` 정상 vs 다중공선성 계수 크기 비교 막대
**키워드**: `불안정` `부호 역전` `표준오차`

---

### 2-03
**제목**: "결과만 맞으면 되는 거 아닌가요?"
**본문**:
- 통계: 계수 하나하나 해석이 목적
- ML: 예측 정확도가 목적
- 블랙박스 허용 = 다중공선성 걱정 없음

**비주얼**: `[다이어그램]` 통계 해석 중심 ↔ ML 예측 중심 전환 화살표
**키워드**: `목적 전환` `예측` `블랙박스`

---

### 2-04
**제목**: 자유의 이면
**본문**:
- 블랙박스를 허용한 대가
- 제약 없이 배우면 → 기출문제 외우기 가능
- 바로 다음: 과적합

**비주얼**: `[이미지]` 저울 — 자유(좌) ↔ 대가(우)
**키워드**: `자유` `대가` `과적합 예고`

---

### 2-05
**제목**: 기출문제를 외운 학생 ⭐
**본문**:
- 기출 시험: **100점**
- 새 문제: **50점**
- 외운 것 ≠ 이해한 것
- ML 과적합과 동일한 구조

**비주얼**: `[이미지]` 기출 더미 앞 자신감 있는 학생 vs 새 시험지 앞 당황한 학생
**키워드**: `외우기` `과적합` `일반화`

---

### 2-06
**제목**: 훈련 오차 ↓ → 테스트 오차 ↑
**본문**:
- 복잡도 ↑ → 훈련 오차 계속 감소
- 그러나 테스트 오차는 어느 순간 반등
- 반등 지점 = 과적합 시작

**비주얼**: `[차트]` 훈련·테스트 오차 곡선 (복잡도 X축, 오차 Y축)
**키워드**: `훈련오차` `테스트오차` `반등`

---

### 2-07
**제목**: 너무 단순해도 실패한다
**본문**:
- 과소적합(Underfitting): 훈련 오차도 높음
- 패턴 자체를 못 잡는 상태
- 해결: 모델 복잡도 증가, 특성 추가

**비주얼**: `[차트]` 과소적합 / 적합 / 과적합 3단 비교 그래프
**키워드**: `과소적합` `단순` `복잡도`

---

### 2-08
**제목**: 복잡할수록 좋은 것이 아니다
**본문**:
- 복잡도 ↑ → Bias ↓, Variance ↑
- 복잡도 ↓ → Bias ↑, Variance ↓
- 최적: 두 오차의 합이 최소인 지점

**비주얼**: `[차트]` Bias·Variance·Total Error 3개 곡선 교차점 강조
**키워드**: `Bias` `Variance` `트레이드오프`

---

### 2-09
**제목**: 규제화: 오차와 복잡도를 동시에 제한
**본문**:
- 기존 목적함수: 오차만 최소화
- 규제화 목적함수: 오차 + λ × 계수 크기
- λ(람다): 규제 강도 조절 파라미터

**비주얼**: `[수식 시각화]` Loss = 오차항 + λ × 규제항 (두 항 색상 구분)
**키워드**: `목적함수` `람다` `규제`

---

### 2-10
**제목**: Ridge: 계수를 0에 가깝게, 0은 아니게
**본문**:
- L2 정규화: 계수² 합 최소화
- 결과: 계수가 작아지지만 0이 되지 않음
- 모든 변수 유지: 중요도 비교 가능

**비주얼**: `[차트]` Ridge 계수 히스토그램 (0 근접하지만 0 아님)
**키워드**: `L2` `Ridge` `억제`

---

### 2-11
**제목**: Lasso: 불필요한 변수를 제거한다
**본문**:
- L1 정규화: 계수 절댓값 합 최소화
- 결과: 일부 계수가 정확히 0
- 변수 선택 효과: 희소 모델 생성

**비주얼**: `[차트]` Lasso 계수 히스토그램 (일부 계수 정확히 0)
**키워드**: `L1` `Lasso` `희소`

---

### 2-12
**제목**: Ridge vs Lasso: 선택 기준
**본문**:
- Ridge: 변수가 많고 대부분 유의미할 때
- Lasso: 변수 선택 필요 + 해석 중요할 때
- ElasticNet: 두 조건 모두 필요할 때

**비주얼**: `[흐름도]` 조건 → 선택 의사결정 흐름도
**키워드**: `선택 기준` `변수` `희소성`

---

### 2-13
**제목**: 규제화의 진짜 의미
**본문**:
- 규제 강도 ↑ → Bias ↑, Variance ↓
- 규제 강도 ↓ → Bias ↓, Variance ↑
- 최적 λ 찾기: Cross-validation

**비주얼**: `[차트]` 규제 강도(λ) vs Bias·Variance 트레이드오프 곡선
**키워드**: `Bias-Variance` `λ` `최적화`

---

### 2-14
**제목**: 회귀에서 분류로
**본문**:
- 회귀: 연속값 예측 (집값: 얼마?)
- 분류: 범주 예측 (이 이메일: 스팸인가?)
- 로지스틱 회귀: 분류를 위한 확률 출력

**비주얼**: `[비교]` 회귀(연속 곡선) vs 분류(결정 경계) 시각화
**키워드**: `분류` `확률` `결정경계`

---

### 2-15
**제목**: 예측 결과의 4가지 경우
**본문**:
- TP: 암 → 암으로 예측 (올바른 탐지)
- FP: 정상 → 암으로 예측 (위양성)
- FN: 암 → 정상으로 예측 (위음성, 치명적)
- TN: 정상 → 정상으로 예측

**비주얼**: `[표]` 2×2 혼동행렬 (색상 강조, TP/FP/FN/TN 라벨)
**키워드**: `TP` `FP` `FN` `TN`

---

### 2-16
**제목**: 99% 정확도가 쓸모없을 때
**본문**:
- 암 발생률 1% → 무조건 "정상"만 예측해도 **99% 정확**
- 그러나 암 환자 100명 전원 놓침
- 불균형 데이터에서 정확도는 의미 없음

**비주얼**: `[비교]` 정확도 99% vs 실제 유용성 0 극단 대비
**키워드**: `정확도` `불균형` `함정`

---

### 2-17
**제목**: 데이터를 세 가지로 나누는 이유
**본문**:
- Train (60~70%): 모델이 패턴 학습
- Validation (15~20%): 하이퍼파라미터 튜닝
- Test (15~20%): 최종 성능 평가 (딱 한 번)

**비주얼**: `[다이어그램]` 3색 막대 분할 + 각 역할 설명
**키워드**: `Train` `Validation` `Test`

---

### 2-18
**제목**: Test 데이터는 딱 한 번만
**본문**:
- Test를 여러 번 보면: 테스트에 맞게 튜닝하는 것
- 시험 전날 정답지 본 학생과 같음
- 규칙: 모든 결정 완료 후 마지막 단 한 번

**비주얼**: `[경고 아이콘]` "ONCE" 강조 + 잘못된 사용 vs 올바른 사용
**키워드**: `Test` `단 한 번` `누출 방지`

---

### 2-19
**제목**: K-Fold: 데이터를 최대한 활용하는 법
**본문**:
- 데이터를 K개 조각으로 분할
- 순환하며 각 조각을 검증셋으로 사용
- K=5: 5회 학습, 평균 성능 = 최종 평가

**비주얼**: `[다이어그램]` 5-Fold 분할 표 (행별 학습·검증 구분)
**키워드**: `K-Fold` `교차검증` `평균`

---

### 2-20
**제목**: 상황마다 다른 지표 선택
**본문**:
- Recall (재현율): 놓치면 안 될 때 → 암 진단, 사기 탐지
- Precision (정밀도): 오탐이 비쌀 때 → 스팸 필터
- AUC-ROC: 전반적 판별력 평가

**비주얼**: `[카드]` 3개 지표 상황별 선택 카드 (조건 → 지표)
**키워드**: `Recall` `Precision` `AUC`

---

### 2-21
**제목**: 미래가 과거를 가르치면 안 된다
**본문**:
- Data Leakage: 테스트·미래 정보가 학습에 유입
- 결과: 훈련 성능 비정상적으로 높음
- 실제 배포 시: 성능 급락

**비주얼**: `[타임라인]` 미래→과거 역방향 오염 화살표 (빨간색 강조)
**키워드**: `Leakage` `오염` `성능 급락`

---

### 2-22
**제목**: Leakage는 어디서 일어나는가
**본문**:
- 패턴 1: 전처리를 Train+Test 전체에 적용 (스케일링)
- 패턴 2: 미래 시점 변수 학습에 포함
- 패턴 3: 목표 변수와 직접 연결된 파생 변수

**비주얼**: `[다이어그램]` 3가지 Leakage 패턴 (타임라인 형식)
**키워드**: `전처리` `시점` `파생변수`

---

### 2-23
**제목**: 테스트 성능 100점 → 배포 후 실패
**본문**:
- 학습 데이터: 2020년 패턴
- 배포 시점: 2024년 패턴 변화
- 모델: 과거를 완벽히 외웠지만 미래는 모름

**비주얼**: `[차트]` 학습 시점 vs 배포 시점 분포 차이 그래프
**키워드**: `배포` `실패` `분포 변화`

---

### 2-24
**제목**: 모델 만들기 전 확인할 4가지
**본문**:
- ① 타깃 변수에 미래 정보 없는가?
- ② 전처리를 Train에만 fit 했는가?
- ③ Test는 마지막까지 보지 않았는가?
- ④ 시계열이면 시간 순서대로 분할했는가?

**비주얼**: `[체크리스트]` 4항목 체크리스트 카드
**키워드**: `체크리스트` `전처리` `시계열`

---

### 2-25
**제목**: 다음 차시: 직선으로 안 되는 세상
**본문**:
- 선형 모델의 한계
- IF-THEN으로 규칙을 만드는 법
- 나무 한 그루가 숲이 되는 과정

**비주얼**: `[차트]` 비선형 scatter plot + 직선이 따라가지 못하는 모습
**키워드**: `비선형` `의사결정나무` `숲`

---

## 3차시 — 나무로 규칙을 만든다

---

### 3-01
**제목**: 직선이 따라갈 수 없는 패턴
**본문**:
- 선형 모델: 직선(또는 평면)으로만 분리
- XOR 문제, 원형 경계: 직선 분리 불가
- 아무리 학습해도 오차 줄지 않음

**비주얼**: `[차트]` XOR 패턴 scatter plot (직선 분리 불가 시각화)
**키워드**: `비선형` `패턴` `한계`

---

### 3-02
**제목**: 비선형 접근 방법들
**본문**:
- ① 의사결정나무: IF-THEN 규칙 (이번 차시)
- ② 신경망: 비선형 활성 함수
- ③ 커널 SVM: 고차원 변환

**비주얼**: `[카드]` 3가지 방법 아이콘 카드 (나무 강조)
**키워드**: `접근법` `나무` `신경망`

---

### 3-03
**제목**: 스무고개: 의사결정나무의 직관
**본문**:
- "동물인가?" → 네
- "다리가 4개인가?" → 아니오
- "날 수 있는가?" → 네 → **새!**

**비주얼**: `[다이어그램]` 스무고개 예시 트리 (동물 분류)
**키워드**: `IF-THEN` `분기` `직관`

---

### 3-04
**제목**: 의사결정나무 구조
**본문**:
- 루트 노드: 첫 번째 질문
- 내부 노드: 중간 질문들
- 리프 노드: 최종 예측값
- 깊이(Depth): 질문의 수

**비주얼**: `[다이어그램]` 나무 구조 (루트·내부·리프 라벨 + 색상 구분)
**키워드**: `루트` `내부 노드` `리프`

---

### 3-05
**제목**: 분기 기준: 어떻게 나누는가
**본문**:
- Gini 불순도: 분기 후 각 그룹의 순도 측정
- 정보 이득: 분기 전후 불확실성 감소량
- 목표: 분기 후 각 그룹이 최대한 순수하게

**비주얼**: `[다이어그램]` 분기 전후 Gini 불순도 변화 계산 예시
**키워드**: `Gini` `불순도` `분기 기준`

---

### 3-06
**제목**: 의사결정나무가 강한 이유
**본문**:
- 해석 가능: IF-THEN 규칙 그대로 설명
- 전처리 불필요: 스케일링, 원핫인코딩 생략
- 직관적 규칙: 비전문가도 이해 가능

**비주얼**: `[카드]` 3개 강점 카드 (아이콘 포함)
**키워드**: `해석` `전처리 불필요` `직관`

---

### 3-07
**제목**: 데이터 하나가 바뀌면 트리 전체가 바뀐다
**본문**:
- 불안정성: 데이터 소폭 변화 → 완전히 다른 트리 구조
- 과적합 취약: 깊이 제한 없으면 완전 암기
- 경계 직각: 대각선 패턴에 취약

**비주얼**: `[비교]` 원본 데이터 트리 vs 데이터 1개 추가 후 트리 (좌우 대비)
**키워드**: `불안정성` `과적합` `민감도`

---

### 3-08
**제목**: 같은 데이터, 데이터 1개 차이
**본문**:
- 좌: 원본 데이터 → 트리 A
- 우: 데이터 1개 추가 → 트리 B
- 두 트리의 구조가 완전히 다름

**비주얼**: `[비교]` 트리 A vs 트리 B 구조 나란히 (분기점 차이 강조)
**키워드**: `민감도` `불안정` `구조 변화`

---

### 3-09
**제목**: Bias-Variance Tradeoff ⭐
**본문**:
- 고Bias·저Variance: 단순 모델, 과소적합
- 저Bias·고Variance: 복잡 모델, 과적합
- 목표: 두 오차의 합이 최소인 지점

**비주얼**: `[다이어그램]` 2×2 매트릭스 + 과녁 이미지 4칸 비유
**키워드**: `Bias` `Variance` `최적 균형`

---

### 3-10
**제목**: 고Bias: 너무 단순해서 놓친다
**본문**:
- 선형 회귀로 비선형 데이터 학습
- 결과: 훈련·테스트 모두 오차 높음
- 현상: 과소적합(Underfitting)

**비주얼**: `[차트]` 비선형 데이터에 직선 하나만 그어진 그래프
**키워드**: `고Bias` `과소적합` `단순 모델`

---

### 3-11
**제목**: 고Variance: 너무 민감해서 흔들린다
**본문**:
- 훈련 오차: 0에 수렴
- 테스트 오차: 매우 높음
- 노이즈까지 외운 상태

**비주얼**: `[차트]` 구불구불한 곡선이 모든 점을 통과하는 그래프
**키워드**: `고Variance` `과적합` `노이즈`

---

### 3-12
**제목**: 여러 모델을 합치면 분산이 줄어든다
**본문**:
- 단일 나무: 고Variance
- 여러 나무의 평균: Variance 감소
- 원리: 독립 추정치의 평균은 더 안정적

**비주얼**: `[다이어그램]` "단일 vs 여러 개 평균" 분산 감소 비교
**키워드**: `앙상블` `평균` `분산 감소`

---

### 3-13
**제목**: Bagging: 병렬 학습으로 분산을 줄인다
**본문**:
- **B**ootstrap + **Agg**regat**ing** = Bagging
- 각 모델: 서로 다른 데이터 샘플로 학습
- 최종 예측: 다수결(분류) 또는 평균(회귀)

**비주얼**: `[플로우]` 데이터 → N개 병렬 모델 → 집계 다이어그램
**키워드**: `Bootstrap` `Aggregating` `병렬`

---

### 3-14
**제목**: 복원 추출: 같은 데이터로 다양성 만들기
**본문**:
- 원본 N개에서 N번 복원 추출 (같은 데이터 포함 가능)
- 결과: 서로 조금씩 다른 학습셋
- Out-of-Bag: 약 37%는 학습에 미포함 → 검증에 활용

**비주얼**: `[다이어그램]` 항아리에서 꺼내고 다시 넣는 복원 추출 개념
**키워드**: `복원 추출` `Bootstrap` `다양성`

---

### 3-15
**제목**: 나무 N개가 숲이 된다
**본문**:
- 각 나무: 다른 Bootstrap 샘플로 학습
- 각 분기마다: 무작위 변수 선택
- 최종 예측: 모든 나무의 다수결 투표

**비주얼**: `[이미지]` 나무 한 그루 → 숲 + 투표 아이콘
**키워드**: `랜덤포레스트` `투표` `앙상블`

---

### 3-16
**제목**: 랜덤 포레스트의 무작위성 두 가지
**본문**:
- ① 데이터 무작위: Bootstrap Sampling (행)
- ② 변수 무작위: 분기마다 √p개 변수만 선택 (열)
- 두 무작위성이 나무들의 다양성을 만든다

**비주얼**: `[표]` 행·열 무작위 선택 데이터 표 시각화
**키워드**: `행 무작위` `열 무작위` `다양성`

---

### 3-17
**제목**: 어떤 변수가 가장 중요한가
**본문**:
- Gini 중요도: 각 변수가 불순도 감소에 기여한 양
- Permutation 중요도: 변수를 섞었을 때 성능 변화
- 출력: 변수별 중요도 순위 차트

**비주얼**: `[차트]` 변수 중요도 수평 막대 차트 (상위 10개)
**키워드**: `중요도` `Gini` `순위`

---

### 3-18
**제목**: 대출 심사: 해석 가능한 규칙
**본문**:
- Decision Tree 사용 이유: 규제 기관에 규칙 제출 필요
- 실제 규칙 예시: "연소득 5천만 이상 AND 부채비율 30% 미만 → 승인"
- 장점: 심사위원, 고객 모두 이해 가능

**비주얼**: `[다이어그램]` 대출 심사 의사결정나무 예시 (간소화)
**키워드**: `대출` `규칙` `해석`

---

### 3-19
**제목**: 이상거래: 초당 수천 건 감지
**본문**:
- 변수: 금액, 위치, 시간, 가맹점 등 수십 개
- Random Forest: 복잡한 패턴 조합 탐지
- 정확도보다 Recall 중요 (놓치면 안 됨)

**비주얼**: `[플로우]` 이상거래 탐지 플로우 다이어그램
**키워드**: `이상거래` `RF` `Recall`

---

### 3-20
**제목**: 단일 나무 vs 랜덤 포레스트
**본문**:
|  | Decision Tree | Random Forest |
|--|---------------|---------------|
| 속도 | 빠름 | 느림 |
| 해석 | 쉬움 | 어려움 |
| 안정성 | 낮음 | 높음 |
| 선택 기준 | 해석 필요 | 정확도 우선 |

**비주얼**: `[비교표]` 장단점 대조 표
**키워드**: `비교` `해석` `안정성`

---

### 3-21
**제목**: 랜덤 포레스트가 못 하는 것
**본문**:
- 느림: 나무 100개 이상 학습 시 시간 소요
- 블랙박스화: 개별 나무 해석 불가
- 시계열 패턴 취약: 순서 정보 무시

**비주얼**: `[카드]` 한계 3가지 경고 카드 (빨간 테두리)
**키워드**: `속도` `블랙박스` `시계열`

---

### 3-22
**제목**: 다음 차시: 오답 노트 공부법
**본문**:
- 틀린 곳에 집중하는 알고리즘
- Boosting: 직렬 학습의 힘
- AdaBoost → GBM → XGBoost 진화

**비주얼**: `[이미지]` 오답 표시된 문제지 + 다음 차시 연결 화살표
**키워드**: `Boosting` `순차` `오답노트`

---

## 4차시 — 오답 노트 공부법

---

### 4-01
**제목**: Baseline: 단순한 것이 기준점
**본문**:
- DummyClassifier: 가장 많은 클래스만 예측
- 성능 기준: "이것보다 나아야 의미 있다"
- 복잡한 모델이 Baseline보다 나쁘면 → 문제 있음

**비주얼**: `[차트]` Baseline vs 복잡 모델 성능 비교 막대 차트
**키워드**: `Baseline` `기준점` `DummyClassifier`

---

### 4-02
**제목**: 2% 향상에 얼마를 투자할 것인가
**본문**:
- Dummy: **87%** (가장 많은 클래스만 예측)
- XGBoost: **89%**
- 질문: 2%를 위해 복잡도·비용·유지보수 감당할 가치?

**비주얼**: `[비교]` 두 모델 성능 막대 + "Trade-off" 화살표
**키워드**: `비용-편익` `2%` `의사결정`

---

### 4-03
**제목**: 틀린 곳을 집중 공략한다
**본문**:
- 1라운드: 전체 학습 → 틀린 데이터 파악
- 2라운드: 틀린 데이터에 집중
- 3라운드: 여전히 틀린 데이터에 더 집중

**비주얼**: `[플로우]` 순차 학습 다이어그램 (1→2→3 라운드, 강조 데이터 변화)
**키워드**: `집중` `순차` `약점 극복`

---

### 4-04
**제목**: AdaBoost: 오답 데이터에 가중치를 올린다
**본문**:
- 1단계: 균등 가중치로 첫 번째 분류기 학습
- 2단계: 틀린 샘플 가중치 ↑, 맞춘 샘플 가중치 ↓
- 3단계: 높아진 가중치로 다음 분류기 학습

**비주얼**: `[다이어그램]` 가중치 변화 시각화 (틀린 데이터 크기 커지는 과정)
**키워드**: `AdaBoost` `가중치` `약한 분류기`

---

### 4-05
**제목**: 이전 모델의 실수가 다음 모델의 입력
**본문**:
- Bagging: 독립적 병렬 학습
- Boosting: 의존적 순차 학습
- 순서가 중요: 앞 모델 없이 뒤 모델 시작 불가

**비주얼**: `[다이어그램]` 모델1 → 모델2 → 모델3 순차 의존성 플로우
**키워드**: `순차` `의존성` `직렬`

---

### 4-06
**제목**: 약한 것들이 모여 강해진다
**본문**:
- 약한 학습기(Weak Learner): 랜덤보다 조금만 나은 모델
- 각각은 불완전
- 가중 합: 강력한 예측 생성

**비주얼**: `[플로우]` 약한 분류기 여러 개 → 가중 합 → 강한 분류기
**키워드**: `약한 학습기` `가중 합` `앙상블`

---

### 4-07
**제목**: GBM: 잔차를 다음 모델이 배운다
**본문**:
- AdaBoost: 가중치로 집중
- GBM: 잔차(오차)를 직접 다음 모델의 정답으로
- 핵심: "틀린 만큼을 학습하라"

**비주얼**: `[플로우]` 예측 → 오차 → 새 정답 → 반복 순환
**키워드**: `잔차` `GBM` `경사하강`

---

### 4-08
**제목**: 잔차 학습: 3단계
**본문**:
① 첫 번째 모델로 예측
② 실제값 − 예측값 = 잔차
③ 잔차를 다음 모델의 정답으로

반복할수록 잔차 감소 → 정확도 향상

**비주얼**: `[순서도]` 3단계 루프 다이어그램 (수치 예시 포함)
**키워드**: `잔차` `반복` `수렴`

---

### 4-09
**제목**: 학습률: 보폭의 크기
**본문**:
- 학습률(η): 각 모델의 기여 비율
- η = 1.0: 잔차 전부 반영 (빠르지만 불안정)
- η = 0.01: 잔차 1%만 반영 (느리지만 안정)
- 권장: η = 0.05 ~ 0.3

**비주얼**: `[비유]` 보폭 크기 다이어그램 (크면 도약·진동, 작으면 조심스럽게)
**키워드**: `학습률` `η` `보폭`

---

### 4-10
**제목**: 학습률 너무 크면 → 진동, 수렴 실패
**본문**:
- 손실 함수: 진동·발산 가능
- 최적점을 지나쳐 건너뜀
- 학습 곡선: 불규칙, 불안정

**비주얼**: `[차트]` 큰 학습률의 진동하는 학습 곡선
**키워드**: `진동` `발산` `불안정`

---

### 4-11
**제목**: 학습률 너무 작으면 → 느리고 과소적합 위험
**본문**:
- 수렴 속도 매우 느림
- n_estimators를 크게 해야 보완
- 극단적으로 작으면: 과소적합

**비주얼**: `[차트]` 작은 학습률의 느리게 수렴하는 학습 곡선
**키워드**: `과소적합` `느림` `보상`

---

### 4-12
**제목**: Early Stopping: Validation Loss가 꺾이는 순간 멈춘다
**본문**:
- 트리 수 ↑ → 훈련 Loss 계속 감소
- Validation Loss: 어느 지점에서 반등
- 반등 직전 모델 = 최적

**비주얼**: `[차트]` 훈련/검증 Loss 곡선 (꺾이는 지점 빨간 선 강조)
**키워드**: `Early Stopping` `Validation` `최적 지점`

---

### 4-13
**제목**: XGBoost: GBM의 한계를 넘다
**본문**:
- GBM 문제: 느리다 / 과적합 취약 / 규제 없음
- XGBoost (2016, Chen & Guestrin): 규제 내장 + 병렬화
- Kaggle 우승 솔루션에 등장 시작

**비주얼**: `[비교 카드]` GBM 문제점 → XGBoost 개선점 대조
**키워드**: `XGBoost` `2016` `개선`

---

### 4-14
**제목**: XGBoost가 빠른 이유
**본문**:
- Column Block: 데이터를 열 단위로 정렬·캐시
- 병렬 트리 구성: CPU 코어 전체 활용
- 희소 데이터: 결측값 자동 처리 최적화

**비주얼**: `[차트]` GBM vs XGBoost 학습 시간 비교 막대
**키워드**: `병렬` `캐시` `희소 데이터`

---

### 4-15
**제목**: XGBoost가 정확한 이유
**본문**:
- L1 규제(α): 불필요한 변수 계수를 0으로
- L2 규제(λ): 계수 크기 억제
- 트리 복잡도 규제: 리프 수 제한

**비주얼**: `[수식 시각화]` 목적함수 = 오차 + L1 + L2 + 복잡도 (항별 색상)
**키워드**: `L1` `L2` `규제 내장`

---

### 4-16
**제목**: Kaggle이 XGBoost를 선택한 이유
**본문**:
- 2014~2020년: 상위권 절반 이상이 XGBoost 사용
- 테이블 데이터 대회: 사실상 표준
- 이유: 빠름 + 정확 + 튜닝 용이

**비주얼**: `[인포그래픽]` Kaggle 로고 + XGBoost 우승 비율 원형 차트
**키워드**: `Kaggle` `우승` `표준`

---

### 4-17
**제목**: XGBoost가 쓰이는 곳
**본문**:
- 광고 클릭률(CTR) 예측: Facebook, Criteo
- 금융 부도 예측: 대출, 채권 리스크
- 의료: 환자 리스크 스코어링

**비주얼**: `[카드]` 3개 도메인 카드 (광고·금융·의료 아이콘)
**키워드**: `CTR` `부도 예측` `스코어링`

---

### 4-18
**제목**: 학습 곡선으로 모델 진단하기
**본문**:
- 케이스 1 — 과적합: Train↓↓, Validation↑
- 케이스 2 — 과소적합: Train·Validation 모두 높음
- 케이스 3 — 수렴 실패: 진동, 불안정

**비주얼**: `[차트×3]` 3케이스 학습 곡선 나란히 비교
**키워드**: `과적합` `과소적합` `수렴`

---

### 4-19
**제목**: 진단 결과에 따른 파라미터 조정
**본문**:
- 과적합 → max_depth ↓, 규제 ↑, η ↓
- 과소적합 → max_depth ↑, n_estimators ↑, η ↑
- 수렴 실패 → η ↓↓, n_estimators 대폭 ↑

**비주얼**: `[흐름도]` 진단 → 처방 의사결정 흐름도
**키워드**: `max_depth` `n_estimators` `튜닝`

---

### 4-20
**제목**: XGBoost의 도전자: 테이블 파운데이션 모델
**본문**:
- 2025년: TabPFN (Prior-data Fitted Networks) 등장
- 사전 학습된 거대 모델을 테이블 데이터에 적용
- "테이블 데이터에도 GPT 같은 파운데이션 모델이 가능한가?"

**비주얼**: `[다이어그램]` LLM 파운데이션 → 테이블 데이터 적용 흐름
**키워드**: `TabPFN` `파운데이션` `2025`

---

### 4-21
**제목**: 3초 vs 4시간: TabPFN의 도전
**본문**:
- TabPFN-2.5: 소·중 데이터셋(10만 행 이하)에서 XGBoost 능가
- 하이퍼파라미터 튜닝 없이 바로 사용
- **3초** 만에 **4시간** 튜닝 XGBoost 결과 초과

**비주얼**: `[인포그래픽]` "3초 vs 4시간" 대비 강조 타이머 시각화
**키워드**: `TabPFN` `3초` `자동화`

---

### 4-22
**제목**: 데이터 크기가 기준점
**본문**:
- 10만 행 이하: TabPFN 고려 (빠른 프로토타이핑)
- 10만 행 이상: XGBoost 우세
- 운영 환경 배포: XGBoost (더 검증됨)

**비주얼**: `[흐름도]` 데이터 크기 기준 선택 분기 (10만 행 분기점 강조)
**키워드**: `10만 행` `선택 기준` `프로토타이핑`

---

### 4-23
**제목**: Bagging vs Boosting 한눈에
**본문**:
|  | Bagging | Boosting |
|--|---------|----------|
| 학습 방식 | 병렬 | 순차 |
| 효과 | Variance ↓ | Bias ↓ |
| 대표 | Random Forest | XGBoost |

**비주얼**: `[비교표]` 특성별 아이콘 포함 2열 대조
**키워드**: `병렬` `순차` `Bias vs Variance`

---

### 4-24
**제목**: 어떤 모델을 선택할 것인가 ⭐
**본문**:
- 해석 중요 + 규모 작음 → Decision Tree
- 안정성 필요 → Random Forest
- 정확도 우선 → XGBoost
- 빠른 시작 + 소규모 → TabPFN

**비주얼**: `[치트시트]` 조건별 모델 선택 의사결정 흐름도
**키워드**: `선택 가이드` `데이터 크기` `해석`

---

### 4-25
**제목**: 다음 차시: 잘 맞추면 끝인가?
**본문**:
- 모델 정확도 95% → 현장에서 신뢰받지 못함
- 블랙박스 문제
- 데이터 편향
- 상관 ≠ 인과

**비주얼**: `[이미지]` 95% 숫자 크게 + 물음표 오버레이
**키워드**: `블랙박스` `신뢰` `설명`

---

## 5차시 — 설명할 수 있어야 쓸 수 있다

---

### 5-01
**제목**: 정확도 95%, 하지만 아무도 안 쓴다
**본문**:
- "왜 이 예측을 했는가?" 설명 불가
- 데이터에 편향이 있으면 모델도 편향
- 예측은 맞지만 원인은 모름

**비주얼**: `[이미지]` 95% 성능 숫자 강조 + "왜?" 물음표
**키워드**: `정확도` `신뢰` `한계`

---

### 5-02
**제목**: 블랙박스: 왜 이 예측인가
**본문**:
- XGBoost 100개 나무: 사람이 해석 불가
- 의료: "이 환자에게 왜 고위험 판정인가?"
- 금융: "왜 대출이 거절됐는가?"
- 설명 없는 AI: 규제 통과 불가

**비주얼**: `[이미지]` 잠긴 블랙박스 + 입출력 화살표
**키워드**: `블랙박스` `설명 불가` `규제`

---

### 5-03
**제목**: AI는 편향된 데이터를 그대로 배운다
**본문**:
- 학습 데이터에 편향 → 모델도 편향
- 과거 채용 패턴 학습 → 특정 집단 불이익
- 역사적 차별이 데이터에 남아있으면 AI가 재현

**비주얼**: `[플로우]` 편향 데이터 → 편향 모델 → 편향 결정 다이어그램
**키워드**: `편향` `차별` `역사 데이터`

---

### 5-04
**제목**: 예측이 정확해도 원인은 모른다
**본문**:
- 높은 예측력 ≠ 인과관계 이해
- "아이스크림 판매량으로 익사 사고 예측" → 예측은 맞음
- 하지만 아이스크림이 익사를 일으키지는 않음

**비주얼**: `[차트]` 상관 높은 두 변수 산점도 + "원인이 아님" 경고 표시
**키워드**: `상관` `인과` `예측의 한계`

---

### 5-05
**제목**: 학습 환경과 실제 환경이 달라질 때
**본문**:
- 학습: 2020~2022년 데이터 패턴
- 배포 후: 2024년 패턴 변화
- 코로나·금리·사용자 행동 변화
- 주기적 모델 업데이트 필수

**비주얼**: `[차트]` 학습 분포 vs 배포 분포 불일치 그래프
**키워드**: `Distribution Shift` `패턴 변화` `모니터링`

---

### 5-06
**제목**: SHAP: 블랙박스를 여는 열쇠
**본문**:
- 기존: 모델 내부 불투명
- SHAP (Shapley Additive Explanations): 각 예측에 대한 변수 기여도
- 2017년 등장, 현재 설명 가능 AI의 표준

**비주얼**: `[이미지]` 잠긴 박스 → SHAP 열쇠 → 열린 박스
**키워드**: `SHAP` `설명 가능` `2017`

---

### 5-07
**제목**: 이 예측에 각 변수가 얼마나 기여했나
**본문**:
- 대출 거절 예측 예시
- 부채비율: +0.5 (거절 강화)
- 연소득: −0.3 (거절 완화)
- 각 변수의 기여를 수치로 표현

**비주얼**: `[SHAP 차트]` 변수별 기여도 워터폴 차트 예시
**키워드**: `기여도` `양수·음수` `변수`

---

### 5-08
**제목**: 워터폴 차트 읽는 법
**본문**:
- 기준값(Base value): 전체 평균 예측
- 빨간 바: 예측값 증가에 기여
- 파란 바: 예측값 감소에 기여
- 최종 예측값 = 기준 + 모든 기여의 합

**비주얼**: `[SHAP 차트]` 워터폴 차트 (색상·방향·라벨 설명 포함)
**키워드**: `워터폴` `기준값` `기여`

---

### 5-09
**제목**: 전체 vs 개별: 두 가지 해석 수준
**본문**:
- 국소(Local): 특정 샘플 1개 예측 이유 → Force Plot
- 전역(Global): 모델 전체 변수 중요도 → Summary Plot
- 실무: 개별 케이스 설명 + 전체 경향 동시 필요

**비주얼**: `[나란히]` Summary Plot (좌) + Force Plot (우)
**키워드**: `국소` `전역` `Summary` `Force Plot`

---

### 5-10
**제목**: Amazon 채용 AI: 편향의 교훈
**본문**:
- 2018년: Amazon AI 채용 툴 폐기
- 10년 이력서 학습 → 남성 편향 학습
- "여성", "여대" 단어 포함 이력서 감점
- 교훈: 과거 데이터에 역사적 편견 내재

**비주얼**: `[다이어그램]` 편향 발생 메커니즘 + Amazon 2018 표기
**키워드**: `Amazon` `채용` `편향 사례`

---

### 5-11
**제목**: 편향은 데이터에서 온다
**본문**:
- 역사적 차별 → 편향 학습 데이터 → 편향 모델 → 편향 결정
- 알고리즘은 잘못 없음
- 세계에 편견이 있으면 AI도 편견

**비주얼**: `[사이클]` 편향 전파 사이클 다이어그램 (데이터→모델→결정→데이터)
**키워드**: `역사적 편향` `사이클` `데이터 품질`

---

### 5-12
**제목**: 모델이 공정한가 측정하기
**본문**:
- Equal Opportunity: 집단 간 True Positive Rate 동일
- Demographic Parity: 집단 간 예측 비율 동일
- 현실: 두 가지 동시 만족 불가능 → 트레이드오프
- 도메인에 따라 기준 선택

**비주얼**: `[차트]` 집단 A vs 집단 B 예측 비율 비교 막대 차트
**키워드**: `Equal Opportunity` `공정성` `트레이드오프`

---

### 5-13
**제목**: 아이스크림이 익사를 유발하는가?
**본문**:
- 아이스크림 판매량 ↑ → 익사 사고 ↑ 강한 상관
- 진짜 원인: 여름 = 두 현상의 공통 원인
- 교란변수(Confounding Variable): 제3의 변수

**비주얼**: `[삼각형]` 아이스크림 ↔ 익사 (점선) / 여름 → 둘 다 (실선)
**키워드**: `교란변수` `허위 상관` `여름`

---

### 5-14
**제목**: 무릎 이야기 결말 (1차시 연결)
**본문**:
- 1차시: "비 오는 날 무릎이 아프다" = 상관관계
- 오늘: 기압 변화가 공통 원인 확인
- 상관관계 → 가설 → 메커니즘 → 인과관계 확인

**비주얼**: `[이미지 재사용]` 1차시 무릎 이미지 + "결말" 강조 표시
**키워드**: `인과 확인` `교란` `분석 사이클`

---

### 5-15
**제목**: 상관을 넘어 인과로
**본문**:
- A/B 테스트: 무작위 배정으로 인과 확인
- DoWhy, CausalML: 관측 데이터에서 인과 추론
- 다음 공부 단계: 통계 → ML → 인과 추론

**비주얼**: `[로드맵]` 상관관계 → 인과 추론 단계 화살표
**키워드**: `A/B 테스트` `DoWhy` `인과 추론`

---

### 5-16
**제목**: 주장 → 근거 → 시각화
**본문**:
- 주장: "이 모델이 더 좋다"
- 근거: AUC 0.92 vs 0.87
- 시각화: ROC 커브 비교
- "좋아졌다" 대신 "0.05 향상됐다"

**비주얼**: `[다이어그램]` 주장-근거-시각화 3단계 플로우
**키워드**: `주장` `근거` `정량화`

---

### 5-17
**제목**: 목적에 맞는 차트 선택
**본문**:
- 비교: 막대 차트
- 추세: 선 차트
- 분포: 히스토그램, 박스플롯
- 관계: 산점도, 히트맵

**비주얼**: `[매트릭스]` 2×2 차트 유형 선택 매트릭스 (각 셀에 차트 썸네일)
**키워드**: `비교` `추세` `분포` `관계`

---

### 5-18
**제목**: "개선" 대신 수치로 말하라
**본문**:
- 나쁜 예: "성능이 크게 개선됐습니다"
- 좋은 예: "AUC 0.87 → 0.92, 재현율 +12%p"
- Before/After: 같은 축, 같은 단위
- 숫자가 없으면 주장이 아니다

**비주얼**: `[나란히]` 나쁜 표현(좌) vs 좋은 표현(우) 슬라이드 예시 대비
**키워드**: `정량화` `Before/After` `수치`

---

### 5-19
**제목**: 다음에 뭘 공부하나?
**본문**:
① sklearn (기초 모델)
② XGBoost (실무 표준)
③ SHAP (설명 가능)
④ 에이전틱 AI 연동

Kaggle: 각 단계 실전 연습장

**비주얼**: `[로드맵]` 4단계 화살표 다이어그램 + Kaggle 아이콘
**키워드**: `sklearn` `XGBoost` `SHAP` `에이전틱`

---

### 5-20
**제목**: 에이전트가 ML을 호출한다
**본문**:
- 2026 패러다임: AI 에이전트 + ML 예측 모듈 조합
- 에이전트(LLM): 판단·계획·조율
- ML 모듈: 수치 예측, 이상 탐지, 분류
- ML 엔지니어: API처럼 모듈화하는 역할

**비주얼**: `[구조도]` 에이전트 → ML 모듈 호출 다이어그램
**키워드**: `에이전트` `모듈화` `역할 진화`

---

### 5-21
**제목**: 분석가의 사고 흐름
**본문**:
목적 정의 → 데이터·EDA → 모델 학습 → 평가 → 설명·시각화 → 제안

- 이 흐름이 반복
- 각 단계: 판단이 필요

**비주얼**: `[순환 다이어그램]` 6단계 파이프라인 순환 플로우
**키워드**: `파이프라인` `사고 흐름` `반복`

---

### 5-22
**제목**: 도구는 바뀌었고, 목적은 하나였다 ⭐
**본문**:
- 1차시: 야구 데이터 → 2026: 에이전틱 AI
- 통계학 → ML → XGBoost → 에이전트
- 도구 진화, 목적: 데이터로 설득

**비주얼**: `[타임라인 재사용]` 1차시 여정 타임라인 + "현재 위치" 강조
**키워드**: `수미상관` `목적` `여정`

---

## 6차시 — EDA + 과제

---

### 6-01
**제목**: 쓰레기 IN → 쓰레기 OUT
**본문**:
- 완벽한 모델 + 나쁜 데이터 = 나쁜 결과
- EDA: 데이터를 모델에 넣기 전 이해하는 과정
- 분석 시간의 **80%**: 데이터 이해·정제

**비주얼**: `[이미지]` 쓰레기통 입력 → 모델 → 쓰레기 출력 일러스트
**키워드**: `EDA` `데이터 품질` `80%`

---

### 6-02
**제목**: EDA: 모델 전에 데이터를 이해한다
**본문**:
- 데이터 구조 파악: 행/열/타입
- 이상 탐지: 결측, 이상치, 중복
- 변수 관계 파악: 상관, 분포
- 파생 변수 아이디어 발굴

**비주얼**: `[아이콘 카드]` EDA 4가지 목적 카드
**키워드**: `구조` `이상` `관계` `파생`

---

### 6-03
**제목**: 데이터 4대 진단 항목
**본문**:
- ① 결측치: `df.isnull().sum()`
- ② 이상치: 박스플롯, IQR
- ③ 중복: `df.duplicated()`
- ④ 데이터 타입: `df.dtypes`

**비주얼**: `[체크리스트]` 4항목 표 (코드 스니펫 포함)
**키워드**: `결측` `이상치` `중복` `타입`

---

### 6-04
**제목**: 결측치: 얼마나, 어디에, 왜
**본문**:
- 결측 비율: 열별 결측 %
- 결측 위치: 특정 행·열에 집중?
- 결측 패턴: 랜덤 vs 구조적
- MCAR·MAR·MNAR: 결측 메커니즘 3종

**비주얼**: `[차트+히트맵]` 결측 비율 막대 + 결측 패턴 히트맵 나란히
**키워드**: `결측 비율` `패턴` `MCAR`

---

### 6-05
**제목**: 결측 히트맵: 구조적 결측을 찾아라
**본문**:
- 특정 열 전체 결측: 데이터 수집 문제
- 열 간 동시 결측: 관련 변수 셋
- 구조적 결측 ≠ 랜덤 결측 → 처리 방법 다름

**비주얼**: `[히트맵]` missingno 결측 히트맵 예시 (패턴 강조)
**키워드**: `히트맵` `구조적 결측` `패턴`

---

### 6-06
**제목**: 결측 비율에 따른 처리 기준
**본문**:
- **5% 미만**: 행 제거 or 단순 대체 가능
- **5~30%**: 평균·중앙값·KNN 대체
- **30% 초과**: 해당 변수 제거 고려
- 단, 도메인상 중요 변수는 예외

**비주얼**: `[흐름도]` 결측 비율 범주별 처리 의사결정 흐름도
**키워드**: `5%` `30%` `대체` `제거`

---

### 6-07
**제목**: 박스플롯으로 이상치를 먼저 본다
**본문**:
- IQR = Q3 − Q1
- 이상치 기준: Q1 − 1.5×IQR 미만 or Q3 + 1.5×IQR 초과
- 박스플롯: 분포 + 이상치 한눈에

**비주얼**: `[다이어그램]` 박스플롯 구조 (Q1, Q3, IQR, 이상치 라벨 포함)
**키워드**: `IQR` `박스플롯` `이상치 기준`

---

### 6-08
**제목**: 에러인가, 사건인가?
**본문**:
- 에러: 입력 실수, 센서 오류 → 제거 또는 대체
- 사건: 진짜 이상 패턴 (이상거래, 희귀 질환) → 반드시 유지
- 판단 기준: 도메인 전문가 확인 필수

**비주얼**: `[비교]` 에러(빨간) vs 사건(노란) 이상치 예시 대비
**키워드**: `에러` `사건` `도메인 확인`

---

### 6-09
**제목**: 데이터 제거 전에 물어봐야 할 것
**본문**:
- "이 값이 실제로 가능한 값인가?"
- "이 패턴은 비즈니스적으로 의미가 있는가?"
- 연령 150세: 에러
- 거래 금액 0원: 에러일 수도, 프로모션일 수도

**비주얼**: `[흐름도]` 이상치 발견 → 질문 체크리스트 플로우
**키워드**: `도메인 지식` `판단 전` `질문`

---

### 6-10
**제목**: 이상치: 제거·대체·유지 선택
**본문**:
- 입력 오류 확인 → 에러면 제거·대체
- 극단값이지만 실제 → 유지
- 모델에 민감 → Winsorizing (상한·하한 캡핑)
- 분포 왜도 심함 → 로그 변환

**비주얼**: `[흐름도]` 이상치 처리 의사결정 흐름도
**키워드**: `제거` `대체` `Winsorizing`

---

### 6-11
**제목**: 히스토그램: 수치형 변수의 분포 확인
**본문**:
- 정규분포: 대칭, 종 모양 → 많은 모델이 가정
- 오른쪽 꼬리: 로그 변환 고려
- 이중봉: 두 집단 혼재 가능성

**비주얼**: `[차트×3]` 정규분포 / 오른쪽 꼬리 / 이중봉 히스토그램 비교
**키워드**: `정규분포` `왜도` `이중봉`

---

### 6-12
**제목**: 막대 그래프: 범주형 변수의 불균형 확인
**본문**:
- 클래스 불균형: 분류 모델에 치명적
- 예: 이상거래 0.1% vs 정상 99.9%
- 처리: Oversampling(SMOTE), Undersampling, 가중치

**비주얼**: `[차트]` 극단적 불균형 막대 차트 예시
**키워드**: `불균형` `SMOTE` `가중치`

---

### 6-13
**제목**: 상관 히트맵: 관계와 다중공선성 경고
**본문**:
- 강한 양의 상관(0.8↑): 빨간색 강조
- 강한 음의 상관(−0.8↓): 파란색 강조
- 독립 변수 간 강한 상관 → 다중공선성 위험
- 목표 변수 상관: 중요 변수 후보

**비주얼**: `[히트맵]` 상관 히트맵 (색상 스케일 포함)
**키워드**: `상관계수` `히트맵` `다중공선성`

---

### 6-14
**제목**: 변수 쌍의 관계를 한눈에
**본문**:
- 주대각선: 각 변수 분포 (히스토그램 or KDE)
- 비대각선: 변수 쌍 산점도
- 패턴 발견: 선형·비선형 관계, 군집, 이상치

**비주얼**: `[매트릭스]` 4×4 산점도 매트릭스 예시 (seaborn pairplot)
**키워드**: `pairplot` `쌍 관계` `패턴 탐색`

---

### 6-15
**제목**: 파생 변수: 도메인 지식을 feature로
**본문**:
- 원본 변수만으로는 패턴 안 보일 때
- 체중·신장 → BMI
- 가입일·오늘 → 가입 기간 (일수)
- 도메인 지식이 파생 변수의 원천

**비주얼**: `[플로우]` 원본 변수 → 변환 → 파생 변수 플로우
**키워드**: `파생 변수` `도메인 지식` `Feature Engineering`

---

### 6-16
**제목**: 시간에서 패턴을 추출한다
**본문**:
- 시간대: 새벽·아침·오후·저녁 (행동 패턴)
- 요일: 평일·주말 (수요 차이)
- 계절·월: 계절성 패턴
- 공휴일 여부: 비즈니스 특수 효과

**비주얼**: `[차트]` 시간대별 자전거 수요 선 차트 (시간대 구간 색상 구분)
**키워드**: `시간대` `요일` `계절성`

---

### 6-17
**제목**: 변화량과 비율이 핵심 신호
**본문**:
- 전일 대비 변화율: 이상 감지
- 평균 대비 비율: 상대적 위치
- 7일 이동평균: 노이즈 제거
- 누적합: 트렌드 방향

**비주얼**: `[차트]` 원본 시계열 vs 파생 변수(변화율·이동평균) 비교 그래프
**키워드**: `변화율` `이동평균` `이상 감지`

---

### 6-18
**제목**: Before/After: 같은 축, 같은 단위, 숫자 증명 ⭐
**본문**:
- 같은 Y축 범위 유지
- 같은 단위 (% vs 절댓값 혼용 금지)
- 변화량 숫자 직접 표시
- "개선됨"이 아닌 "결측 18% → 2%"

**비주얼**: `[나란히]` 잘못된 Before/After(축 다름) vs 올바른 Before/After 대비
**키워드**: `같은 축` `단위` `정량화`

---

### 6-19
**제목**: EDA에서 흔히 하는 실수
**본문**:
- ① Y축 0에서 시작 안 함 → 변화 과장
- ② Train+Test 같이 전처리 → Data Leakage
- ③ 이상치 확인 없이 평균 사용 → 왜곡
- ④ 결측치 확인 건너뜀 → 모델 오류

**비주얼**: `[경고 카드]` 4개 항목 빨간 테두리 카드
**키워드**: `Y축` `Leakage` `평균 왜곡` `결측`

---

### 6-20
**제목**: EDA 완료 → 모델 시작
**본문**:
- 결측 처리 완료 → 학습 준비
- 파생 변수 생성 → 변수 후보 풍부
- 이상치 처리 완료 → 안정적 학습 가능
- EDA 결과물 → 전처리 계획

**비주얼**: `[플로우]` EDA → 전처리 → 모델 → 결과 파이프라인
**키워드**: `전처리` `준비` `파이프라인`

---

### 6-21
**제목**: 오늘의 역할: 서울 자전거 수요 분석가
**본문**:
- 데이터: 서울 공공자전거 대여 기록 (오염 버전)
- 변수: 시간, 날씨, 온도, 습도, 대여 수
- 역할: 데이터 정제 → 패턴 발견 → 인사이트 도출

**비주얼**: `[이미지+표]` 서울 자전거 이미지 + 데이터 스키마 표
**키워드**: `자전거` `시나리오` `raw_dirty.csv`

---

### 6-22
**제목**: 10문항: EDA 전체 여정
**본문**:
- Q1~2: 스키마 확인·결측 탐색
- Q3~4: 이상치 탐지·처리
- Q5~6: 분포·관계 시각화
- Q7~8: 파생 변수·시각화
- Q9~10: 인사이트 도출
- 제출: 노트북 1개 + 필수 시각화 6개

**비주얼**: `[흐름도]` 10문항 EDA 단계 매핑
**키워드**: `10문항` `체험` `시각화 6개`

---

## 비주얼 유형 범례

| 태그 | 설명 |
|------|------|
| `[이미지]` | 사진·일러스트·아이콘 |
| `[차트]` | 데이터 시각화 (막대·선·산점도 등) |
| `[다이어그램]` | 개념 플로우·구조 설명 |
| `[타임라인]` | 시간 순서 나열 |
| `[비교표]` | 2열 이상 대조 표 |
| `[카드]` | 항목별 카드 레이아웃 |
| `[인포그래픽]` | 숫자·통계 강조 시각화 |
| `[플로우]` | 순서·과정 플로우 다이어그램 |
| `[흐름도]` | 조건 분기 의사결정 흐름 |
| `[체크리스트]` | 항목 체크 형식 |
| `[히트맵]` | 행렬 색상 시각화 |
| `[SHAP 차트]` | SHAP 전용 시각화 |
| `[순환 다이어그램]` | 순환·반복 프로세스 |
