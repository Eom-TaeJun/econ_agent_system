# 차시별 진행 흐름 & 대본 구조

> 세미나형 운영 기준 | 각 차시 55~60분
> 형식: [강사 멘트 예시] + [전환 포인트] + [예상 질문 대응]

---

## 1차시 — ML이 왜 등장했고, 어디에 쓰이는가

### 오프닝 훅 (5분)
```
"오늘 아침에 유튜브 켰을 때 첫 영상, 왜 그게 나왔는지 알아요?
 카드 결제할 때 이상거래 감지는 어떻게 0.1초 만에 되는 걸까요?
 이것들의 공통점이 오늘의 핵심입니다."
```
→ 슬라이드 1: 일상 속 ML 결정들 (넷플릭스 / 신용점수 / 이상거래)

### 시대적 배경 (10분)
```
"왜 지금인가? 두 가지가 바뀌었습니다.
 첫째, 데이터가 폭발적으로 늘었습니다.
 둘째, 컴퓨터가 계산을 감당할 수 있게 됐습니다."
```
→ 슬라이드 2: 데이터 폭증 + 연산력 성장 그래프
→ 슬라이드 3: 통계학 vs ML 비교표 (원인 규명 vs 결과 예측)

**[전환 포인트]**
```
"그러면 ML은 어떤 종류의 질문에 답하는 도구일까요?
 크게 4가지로 나눌 수 있습니다."
```

### 핵심 다이어그램: ML 질문 유형 지도 (8분)
→ 슬라이드 4: 2×2 다이어그램
```
  얼마나? (숫자 예측)  →  회귀 Regression
  어떤 종류? (선택 예측)  →  분류 Classification
  어떤 그룹? (패턴 발견)  →  군집 Clustering
  왜? (근거 설명)  →  해석 SHAP / Feature Importance
```

### 분야별 실제 사례 (8분)
→ 슬라이드 5
```
금융: 대출 심사, 사기 탐지, 주가 방향 (예측이지 정답이 아님!)
마케팅: 이탈 고객 예측, 구매 확률 순위
의료: 진단 보조, 재입원 위험도
스포츠: 선수 성과 예측, 전술 분석
```
**[예상 질문]** "주가 예측이 되면 다 부자 아닌가요?"
→ "방향성 확률을 높이는 것이지 확정 예측이 아닙니다. 그래서 리스크 관리랑 같이 씁니다."

### 설명력 vs 예측력 (5분)
→ 슬라이드 6
```
"통계학은 '왜'를 정확히 알고 싶어합니다.
 ML은 '결과'를 잘 맞추고 싶어합니다.
 둘 중 하나가 더 좋은 게 아니라, 질문이 다른 겁니다."
```

### [추가] LLM 시대에도 ML인가? (5분)
→ 슬라이드 7
```
"그런데 요즘 GPT 같은 LLM이 있으면 ML 배울 필요 없지 않냐는 질문을 많이 받습니다.
 세 가지 이유로 ML은 여전히 필수입니다.

 첫째, LLM은 테이블 데이터(엑셀 형태)에 약합니다.
   실무 데이터의 80% 이상은 여전히 CSV·DB 테이블 형태입니다.

 둘째, LLM 내부도 ML입니다.
   트랜스포머 역시 데이터로 학습하고, 과적합을 막는 방법을 씁니다.
   ML 개념을 모르면 LLM의 한계도 이해할 수 없어요.

 셋째, 비용과 설명 의무.
   금융·의료·법무에서는 '왜 그 결론이 나왔는지' 설명해야 합니다.
   XGBoost + SHAP 조합이 GPT보다 훨씬 저렴하고 설명 가능합니다."
```
**[예상 질문]** "그럼 나중엔 ML을 AI가 다 해주지 않나요?"
→ "AutoML·AI 코딩 도구가 코드를 써줘도, 어떤 모델을 왜 선택하는지 판단은 사람이 합니다. 그 판단 능력이 오늘 배우는 것입니다."

### [추가] 2026년: ML이 AI 시스템의 부품이 된다 (3분)
→ 슬라이드 7-1
```
"그러면 앞으로 ML은 어디로 가는 걸까요?

 2026년에는 '에이전틱 AI' 시대가 본격화되고 있습니다.
 AI가 지시를 기다리는 도구가 아니라, 스스로 판단해서 일을 처리하는 거죠.

 그런데 그 에이전트 안을 열어보면 이런 구조입니다:

   사용자 요청
       ↓
   에이전트 (계획·실행 담당)
       ↓
   [ML 예측 모듈] ← 오늘 배우는 것
       ↓
   도구 호출 → 결과 반환

 에이전트가 '이 고객 이탈할 것 같으니 할인 쿠폰 발송'을
 결정할 때, 그 이탈 확률을 만드는 게 XGBoost + SHAP입니다.

 2026년 시장에서 승패를 가르는 건
 '누가 더 좋은 모델을 가졌는가'가 아니라
 '누가 ML을 시스템 안에서 제대로 운영하는가'로 바뀌고 있습니다.

 ML을 모르면 에이전트도 설계할 수 없어요.
 그래서 지금 이걸 배우는 겁니다."
```
**[예상 질문]** "에이전트는 어떻게 공부하나요?"
→ "에이전트는 나중 단계입니다. 지금은 ML 예측 모듈을 잘 만드는 것이 먼저예요.
   집을 짓기 전에 재료부터 다뤄야 합니다."

### 마무리 + 예고 (2분)
```
"다음 시간엔 ML이 어떻게 진화했는지,
 그리고 왜 변수를 많이 넣으면 오히려 망하는지 보겠습니다."
```

---

## 2차시 — ML 기초 도구: 선형에서 규제까지

### 오프닝 연결 (3분)
```
"지난 시간에 ML이 왜 나왔는지 봤습니다.
 이번엔 가장 기초적인 도구부터 시작해서
 왜 더 복잡한 도구가 필요해졌는지 따라가 보겠습니다."
```

### 선형회귀 → 다중공선성 문제 (10분)
→ 슬라이드 1~2
```
"y = Xβ + ε, 이게 ML의 출발점입니다.
 그런데 변수를 많이 넣으면 통계학은 계산을 거부합니다.
 왜냐면 어떤 변수가 영향을 미치는지 구분할 수 없기 때문입니다."
```

### [선택] 최소제곱법(OLS): 선형회귀가 직선을 찾는 방법
```
왜 등장했나:
  데이터를 가장 잘 요약하는 직선 하나를 구하고 싶었음.
  계수(β)가 각 변수의 영향력을 직접 나타내므로 해석이 쉬움.

핵심 원리 — 잔차 제곱합 최소화:
  잔차 = 실제값 - 예측값 (직선과의 수직 거리)
  잔차를 그냥 합하면 +/-가 상쇄 → 제곱해서 합산
  이 합이 가장 작아지는 β를 수학적으로 유일하게 구할 수 있음
  (행렬 미분: β = (XᵀX)⁻¹ Xᵀy)

왜 제곱을 쓰나:
  절댓값 |잔차| 합도 가능하지만 미분이 불가 → 최적화 어려움
  제곱은 연속 미분 가능 → 닫힌 해(closed-form solution) 존재

어떤 상황에서 이점:
  - 변수 영향력을 숫자로 보고 싶을 때 (β 해석)
  - 데이터가 선형 관계에 가까울 때
  - 빠른 기준선(baseline) 모델이 필요할 때
  단점: 변수 간 다중공선성 있으면 (XᵀX) 역행렬 불안정
        → Ridge/Lasso로 해결
```
→ 슬라이드 3
```
"ML은 다르게 생각합니다.
 beta1이 1이든 2이든 결국 예측값이 같으면 됩니다.
 이것이 블랙박스를 허용하는 출발점입니다."
```

### 과적합: 자유의 대가 (8분)
→ 슬라이드 4
```
"그런데 변수를 너무 많이 넣으면 문제가 생깁니다.
 기출문제 답을 통째로 외운 학생처럼,
 새로운 문제는 못 푸는 거죠. 이걸 과적합이라고 합니다."
```

### Ridge vs Lasso: 언제 뭘 쓰나 (10분)
→ 슬라이드 5
```
두 방법 모두 손실함수에 '계수 크기에 대한 벌칙'을 추가합니다.
  Ridge: 벌칙 = β² 합 (L2)  → 계수를 작게 만들지만 0은 안 됨
  Lasso: 벌칙 = |β| 합 (L1) → 계수를 아예 0으로 만들 수 있음

왜 L1은 0이 되고 L2는 안 되나? (기하 직관)
  최솟값을 찾는 과정을 그래프로 보면:
  - L2 벌칙 영역은 원(circle) → 등고선이 원과 접하는 지점이 축 위에 잘 안 걸림
  - L1 벌칙 영역은 다이아몬드(◇) → 뾰족한 꼭짓점이 축 위에 있어서
    최솟값이 거기 걸리면 해당 변수가 정확히 0이 됨

Ridge: 변수를 모두 살리되 영향력을 줄임 → 다중공선성 있을 때
Lasso: 덜 중요한 변수를 0으로 날림 → 진짜 중요한 변수만 남기고 싶을 때

실무 기준: 변수 해석이 필요하면 Lasso
          안정적 예측이 목적이면 Ridge
```
**[예상 질문]** "그럼 항상 Lasso 쓰면 되지 않나요?"
→ "변수들끼리 비슷한 정보를 갖고 있을 때 Lasso는 하나만 선택해서 나머지를 버려요. 그게 손실일 수 있어요. 그래서 둘을 섞은 ElasticNet도 있습니다."

### [추가] Confusion Matrix: 지표의 출발점 (5분)
→ 슬라이드 6-1

```
"Precision, Recall, F1 — 이름이 나오기 전에 기반이 되는 표 하나를 보겠습니다."

|              | 예측 Positive | 예측 Negative |
|--------------|--------------|--------------|
| 실제 Positive | TP (맞게 양성) | FN (놓침) ← 암 진단에서 치명적 |
| 실제 Negative | FP (오탐)     | TN (맞게 음성) |

Recall    = TP / (TP + FN)  → "실제 양성 중 몇 개를 잡았나"
Precision = TP / (TP + FP)  → "양성으로 예측한 것 중 실제로 맞은 비율"
Accuracy  = (TP + TN) / 전체

"이 표를 머릿속에 갖고 있으면 어떤 지표든 직접 계산할 수 있습니다."
```

### 로지스틱 회귀 → 평가지표 (15분)
→ 슬라이드 6~7
```
"숫자가 아니라 '이탈한다/안 한다'를 예측하려면?
 로지스틱 회귀는 결과를 0~1 확률로 변환합니다."

"그런데 정확도 99%인데 쓸모없는 모델이 있습니다.
 암 환자가 1%인 데이터에서 '다 정상'이라고 해도 99%가 나오거든요."
 → Recall(재현율)과 Precision(정밀도)이 왜 필요한지
```

### [추가] 어떤 지표로 모델을 평가하나 (10분)
→ 슬라이드 7-1

```
"Accuracy가 99%여도 쓸모없는 모델이 있다는 건 알았습니다.
 그러면 어떤 상황에서 어떤 지표를 써야 하는지 기준이 필요합니다."

| 상황 | 선택 지표 | 이유 |
|------|-----------|------|
| 클래스 균형, 비용 대칭 | Accuracy | 오탐·미탐 비용이 같을 때 |
| 놓치면 치명적 (암 진단, 사기 탐지) | Recall | FN(놓침) 비용이 압도적으로 큼 |
| 틀리면 신뢰 손상 (스팸 필터) | Precision | FP(오탐) 비용이 큼 |
| 둘 다 중요한 균형 | F1 | Precision·Recall 조화 평균 |
| 임계값 미정, 불균형 데이터 | AUC-ROC | 모든 임계값에서 전반적 성능 비교 |
| 회귀: 큰 오차에 엄격 | RMSE | 이상치·큰 오차에 가중 패널티 |
| 회귀: 이상치 영향 최소화 | MAE | 안정적, 해석 쉬움 |

핵심 질문: "이 모델이 틀렸을 때, 어느 쪽 실수가 더 나쁜가?"
→ 그 답이 지표를 결정한다.

[예상 질문] "항상 AUC 쓰면 안 되나요?"
→ "AUC는 임계값을 아직 정하지 않은 모델 선택 단계에 씁니다.
   실제 배포 후에는 비즈니스 상황에 맞는 임계값을 정하고
   그 시점의 Precision 또는 Recall을 봐야 합니다."
```

### [선택] 로지스틱 회귀: 왜 시그모이드를 쓰는가
```
왜 등장했나:
  분류 문제에 선형회귀를 그대로 쓰면 예측값이 0~1을 벗어남.
  "이탈 확률 = 1.7" 같은 말이 안 되는 결과가 나옴.
  어떤 실수라도 0~1 사이로 압축하는 함수가 필요했음.

핵심 원리 — 시그모이드 함수:
  σ(z) = 1 / (1 + e^{-z})
  z = 선형 점수 (Xβ, -∞~+∞)

  z → -∞ 이면 σ → 0 (완전히 음성)
  z = 0     이면 σ = 0.5 (경계)
  z → +∞ 이면 σ → 1 (완전히 양성)

  결정 경계: σ ≥ 0.5 → z ≥ 0 → Xβ ≥ 0인 초평면
  → 데이터 공간을 직선(2D) or 평면(3D)으로 이분

왜 이 함수인가:
  ① 미분이 쉬움: σ'(z) = σ(z)(1-σ(z)) → 역전파 계산 가능
  ② 로그 오즈(log-odds)가 선형: log(p/1-p) = Xβ
     → 계수 해석: β₁ = 1이면 x₁이 1 증가 시 오즈가 e배

어떤 상황에서 이점:
  - 결과가 이진(예/아니오, 이탈/유지)일 때
  - 확률값 자체가 필요할 때 (0 or 1이 아니라 "이탈 확률 73%")
  - 해석 가능한 선형 결정 경계가 충분할 때
  단점: 비선형 경계는 표현 못함 → 나무 계열로 이동
```

### [선택] AUC-ROC: 임계값에 독립적인 성능 측정
```
왜 등장했나:
  F1 스코어는 결정 임계값 0.5를 고정해서 계산.
  하지만 실무에서는 상황마다 임계값이 다름.
    - 암 진단: 놓치면 치명적 → 임계값 낮게 → Recall 우선
    - 스팸 필터: 오탐지가 짜증 → 임계값 높게 → Precision 우선
  임계값 0.5 하나만으로 모델을 평가하는 건 불완전함.

핵심 원리:
  임계값을 0에서 1까지 전부 바꿔가며
  각 시점에서 TPR(재현율)과 FPR(위양성률)을 기록 → 곡선을 그림

  AUC = ROC 곡선 아래 면적
  - AUC = 0.5: 무작위 분류 (대각선)
  - AUC = 1.0: 완벽한 분류

직관적 해석:
  "무작위로 양성 1명, 음성 1명을 뽑았을 때
   양성을 더 높은 확률로 예측할 확률" = AUC

어떤 상황에서 이점:
  - 불균형 데이터 (암 환자 1%, 정상 99%)
  - 임계값을 아직 정하지 않은 모델 선택 단계
  - 두 모델의 전반적 식별력을 비교할 때
  단점: AUC가 높아도 실제 쓸 임계값에서 성능이 낮을 수 있음
        → 최종 배포 전 Precision-Recall 곡선도 함께 확인 필요
```

### 교차검증 (K-Fold): 과적합 측정을 믿을 수 있나 (5분)
→ 슬라이드 7 (분류 맛보기 슬라이드 내 삽입)
```
"train/test를 한 번만 나누면, 그 나눔 자체가 운일 수 있습니다.
 내가 운 좋게 쉬운 테스트를 뽑은 건지 모델이 정말 잘하는 건지 모릅니다."

K-Fold 교차검증:
  1) 데이터를 K개 묶음으로 나눔 (보통 K=5)
  2) 묶음 1개를 테스트, 나머지 4개로 학습 → 성능 측정
  3) 이걸 K번 반복, 모든 묶음이 한 번씩 테스트가 됨
  4) K개 성능 점수의 평균 = 더 신뢰할 수 있는 진짜 성능

"어느 한 번 나눔에 결과가 좌우되는 게 아니라,
 다섯 번 시험을 보고 평균을 내는 것과 같습니다."

주의: 시계열 데이터에서는 미래 데이터가 학습에 들어가면 안 되므로
     K-Fold 대신 TimeSeriesSplit을 써야 합니다.
```

### [추가] Train / Validation / Test: 왜 세 개로 나누나 (5분)
→ 슬라이드 6-2

```
"K-Fold로 성능을 믿을 수 있게 됐습니다.
 그런데 하이퍼파라미터를 튜닝하는 순간 문제가 생깁니다."

Train      → 모델 파라미터 학습 (가중치, 분할 기준)
Validation → 하이퍼파라미터 튜닝 (학습률, max_depth, n_estimators)
Test       → 최종 성능 측정 — 딱 한 번만, 맨 마지막에

핵심:
  "Validation 결과를 보고 파라미터를 바꾸는 행위 자체가
   Test를 Validation으로 만든다.
   Test는 모든 결정이 끝난 후, 단 한 번 확인하는 용도다."

흔한 실수: 테스트 성능을 보고 모델을 다시 고름
→ 이 순간 테스트 세트가 오염됨
→ 실제 배포 성능과 보고된 성능이 다른 이유

K-Fold와 삼분할의 관계:
  실무: Train+Validation 합쳐서 K-Fold, Test는 완전히 분리 보관
  Kaggle: Public LB(Validation 역할) + Private LB(Test 역할)
```

### [추가] 실무 함정: Data Leakage (7분)
→ 슬라이드 8
```
"모델 성능이 너무 좋게 나오면 오히려 의심해야 할 때가 있습니다.
 Data Leakage — 미래 정보가 학습 데이터에 섞여드는 문제입니다.

 예시: 내일 주가를 예측하는 모델에
       오늘 장 마감 이후의 데이터가 학습에 들어가면
       테스트 성능은 완벽하지만 실제 배포하면 바로 망합니다.

 왜 생기나?
 - 전처리(정규화, 결측 처리)를 전체 데이터에 먼저 적용할 때
 - 타임스탬프를 무시하고 무작위로 데이터를 나눌 때

 핵심 규칙: 테스트 세트는 모델이 학습 시점에 절대 보면 안 된다."
```
**[예상 질문]** "그럼 어떻게 막나요?"
→ "전처리 파이프라인을 train 세트로만 fit하고, test 세트에는 transform만 적용하면 됩니다.
   sklearn의 Pipeline 클래스가 이걸 자동으로 처리해줍니다.

   ```python
   from sklearn.pipeline import Pipeline
   pipe = Pipeline([('scaler', StandardScaler()), ('model', XGBClassifier())])
   pipe.fit(X_train, y_train)   # scaler도 train으로만 fit
   pipe.predict(X_test)         # test엔 transform만 자동 적용
   ```
   Pipeline을 쓰면 실수로 test를 fit에 넣는 일이 구조적으로 불가능합니다."

---

## 3차시 — Tree 계열

### 오프닝 연결 (3분)
```
"지금까지 직선으로 데이터를 설명했습니다.
 그런데 현실 데이터는 직선이 아닌 경우가 훨씬 많습니다.
 '소득이 오를수록 행복도 계속 오르나요?'"
```

### 의사결정나무: 스무고개 비유 (8분)
→ 슬라이드 2
```
"스무고개 아시죠? 질문을 던져서 범위를 좁혀가는 놀이.
 의사결정나무가 정확히 이겁니다.
 '변수 A가 5보다 큰가?' → 예/아니오 → 또 질문..."

그런데 질문을 어떤 기준으로 고르나? — 분할 기준
  목표: 나눠진 그룹이 '최대한 순수하게(한 종류로만)' 구성되도록

  Gini 불순도 직관:
    "이 그룹에서 무작위로 뽑은 두 개체가 서로 다른 종류일 확률"
    → 섞인 그룹일수록 Gini가 높음, 순수한 그룹일수록 0에 가까움
    → 나무는 Gini를 가장 많이 낮추는 질문을 먼저 선택

  예시: 10명 중 5명 이탈·5명 유지 → Gini = 0.5 (최악, 완전히 섞임)
        10명 전원 이탈 → Gini = 0 (완벽, 순수)

"나무가 '어떤 변수를 몇으로 자르면 가장 순수하게 나뉘나'를
 모든 변수·모든 구간에 대해 계산해서 가장 좋은 걸 고르는 것입니다."
```

### [선택] 엔트로피와 정보 이득 — 시간·분위기 보고 추가
```
Gini와 함께 쓰이는 또 다른 분할 기준.

엔트로피 직관:
  "이 그룹이 얼마나 불확실한가(섞여 있는가)"를 측정.
  전원 한 종류 → 엔트로피 = 0 (확실함)
  반반 섞임   → 엔트로피 = 1 (최대 불확실)

정보 이득 = 분할 전 엔트로피 − 분할 후 엔트로피 (가중 평균)
  → 분할 후 불확실성이 가장 많이 줄어드는 질문을 선택.

Gini와 차이:
  계산 결과는 거의 동일. sklearn 기본값은 Gini.
  엔트로피는 Shannon 정보이론(통신·압축)과 같은 개념에서 출발.
  "정보"라는 단어가 익숙한 청중이면 엔트로피가 더 와닿을 수 있음.
```

### 나무의 장점과 한계 (15분)
→ 슬라이드 3~4
```
장점:
- 결과를 사람이 읽을 수 있는 규칙으로 설명 가능
- 범주형·연속형 변수 섞여도 OK
- 데이터 분포 가정 없음

한계:
- 데이터 조금만 바뀌면 나무 구조가 완전히 달라짐
- 너무 깊게 자라면 학습 데이터 노이즈까지 외워버림
```

### Bias-Variance: 핵심 다이어그램 (8분)
→ 슬라이드 5
```
"모델이 틀리는 이유는 딱 두 가지입니다.
 너무 단순해서(Bias) vs 너무 예민해서(Variance)
 나무는 깊을수록 Variance가 높아집니다."
```

### [선택] Bias-Variance Tradeoff: 수식 분해
```
왜 이 개념이 중요한가:
  모델을 개선하려 할 때 '어디가 문제인지' 진단이 먼저.
  Bias가 문제인지 Variance가 문제인지에 따라 해결책이 반대임.

총 오차 분해:
  E[오차²] = Bias² + Variance + 줄일 수 없는 노이즈(ε)

  Bias (편향):
    - 여러 데이터셋으로 모델을 반복 학습했을 때 평균 예측값과 정답의 차이
    - 모델이 구조적으로 단순해서 패턴 자체를 못 잡는 것
    - 예: 비선형 데이터에 직선 하나 → 아무리 데이터 많아도 틀림

  Variance (분산):
    - 데이터가 바뀌면 모델이 얼마나 출렁이나
    - 훈련 데이터의 노이즈까지 외워서 민감하게 반응
    - 예: 깊은 나무 → 샘플 하나 빠져도 나무 구조가 완전히 달라짐

  트레이드오프:
    complexity ↑ → Bias ↓, Variance ↑
    complexity ↓ → Bias ↑, Variance ↓
    최적은 그 사이 어딘가

진단 방법:
  훈련 오차 높음 + 테스트 오차 높음 → Bias 문제 → 모델 복잡도 ↑
  훈련 오차 낮음 + 테스트 오차 높음 → Variance 문제 → 정규화·데이터 추가
```

### 랜덤 포레스트: 집단지성 (10분)
→ 슬라이드 6
```
"한 나무가 불안정하다면, 수백 그루를 심어서 평균 내면 어떨까요?
 게다가 각 나무가 보는 변수도 조금씩 다르게 하면
 서로 다른 관점이 만들어져서 훨씬 안정적이 됩니다."
```

### [선택] Bagging이 분산을 줄이는 이유 + RF의 feature subsampling
```
왜 Bagging이 등장했나:
  단일 나무는 Variance가 높음 → 데이터 조금 달라지면 결과가 확 바뀜.
  같은 데이터로 여러 모델을 만들 수는 없을까? → Bootstrap + Aggregating

Bagging 원리:
  1) 원본 데이터에서 중복 허용 랜덤 샘플링 (bootstrap) → 여러 개 데이터셋
  2) 각 데이터셋으로 나무를 따로 학습
  3) 예측: 모든 나무의 평균(회귀) or 다수결(분류)

왜 평균이 분산을 줄이나:
  독립인 확률변수 n개의 평균 분산 = σ²/n
  → 이론상 나무 100개를 평균 내면 분산이 1/100

  하지만 같은 데이터에서 나온 나무들은 서로 상관이 있음
  → 실제 감소는 σ²/n보다 작음
  → 이 상관을 줄이는 게 랜덤 포레스트의 핵심

랜덤 포레스트의 feature subsampling:
  각 분할마다 전체 변수 중 랜덤으로 sqrt(p)개만 후보로 사용
  → 나무마다 다른 변수를 보게 됨 → 나무 간 상관 감소
  → 평균 효과가 더 강해짐 (진짜 σ²/n에 가깝게)

어떤 상황에서 이점:
  - 데이터 노이즈가 많고 과적합이 걱정될 때
  - 변수가 많고 어떤 변수가 중요한지 모를 때 (변수 중요도 제공)
  - 빠른 훈련과 안정적 성능이 동시에 필요할 때
  단점: 나무가 많아질수록 느려지고 메모리 사용 ↑
        개별 나무의 해석은 불가 → SHAP 필요
```

### [추가] 실사례: 나무가 실무에서 하는 일 (5분)
→ 슬라이드 7
```
의사결정나무 — 대출 심사 규칙
  "연소득 < 3000만 AND 연체 이력 있음 → 거절"
  규칙이 투명하게 보이기 때문에 금융 규제 환경에서 선호.
  심사 담당자가 규칙을 읽고 설명할 수 있어야 함.

랜덤 포레스트 — 신용카드 이상거래 감지
  수백 개 나무의 투표 → "이상거래 확률 87%"
  한 나무가 노이즈에 흔들려도 숲 전체의 결론은 안정적.

  질병 위험도 예측에도 사용:
  여러 임상 변수(나이·혈압·혈당 등)로 각 환자의 재입원 위험 점수 산출.
```

---

## 4차시 — 부스팅

### [추가] 항상 Baseline부터 (3분)

```
"XGBoost를 돌렸더니 정확도 87%가 나왔습니다. 좋은 건가요?"

→ "무조건 다수 클래스 예측"만 해도 몇 %가 나오는지 먼저 확인해야 합니다.

DummyClassifier (항상 다수 클래스 예측):
  클래스 비율이 85:15면 → 아무것도 안 해도 정확도 85%
  XGBoost 87% → 실제 개선은 2%

Baseline 없이 성능 숫자를 보고하면 의미가 없습니다.

실무 순서:
  1단계: Dummy/단순 규칙으로 Baseline 측정
  2단계: 로지스틱 회귀 or Random Forest로 빠른 검증
  3단계: XGBoost로 최적화

"복잡한 모델로 바로 가지 않는 이유 — 단순한 것이 잘 되면 굳이 복잡하게 할 필요가 없습니다."
```

### AdaBoost → GBM → XGBoost 흐름 (25분)
```
"두 번째 전략은 반대입니다.
 틀린 문제를 다음 모델에게 집중적으로 물어봅니다.
 오답 노트를 계속 업데이트하는 거죠."

AdaBoost: 틀린 데이터에 가중치 → 다음 모델이 집중 학습
GBM: 잔차(오차) 자체를 새로운 정답으로 → 더 정교
XGBoost: GBM + 병렬처리 + 정규화 → 실무 표준
```

GBM 단계별 메커니즘 (핵심 설명)
```
[1라운드]
  - 단순한 모델 f₁(x)로 첫 예측을 함
  - 예: 실제값이 100인데 f₁이 80을 예측 → 잔차(오차) = 20

[2라운드]
  - 2번째 모델 f₂(x)의 학습 목표는 원래 y(=100)가 아님
  - 목표 = 1라운드가 틀린 양, 즉 잔차 20
  - f₂는 "얼마나 틀렸는지"를 배움

[3라운드, 4라운드... 반복]
  - 전 라운드가 남긴 잔차를 다음 모델이 학습
  - 최종 예측 = f₁ + f₂ + f₃ + ... (모든 모델의 합)

왜 이게 좋나?
  각 모델이 앞 모델이 못한 부분만 집중해서 보완.
  작고 단순한 모델을 순서대로 쌓아서 전체가 정밀해지는 구조.

학습률(Learning Rate)의 역할:
  최종 예측 = f₁ + lr×f₂ + lr×f₃ + ...
  lr을 낮게 설정 → 한 번에 많이 보정하지 않음 → 과적합 방지
  대신 모델이 더 많이 필요해짐 → Early Stopping으로 언제 멈출지 결정
```

### [선택] AdaBoost 가중치 업데이트 원리
```
왜 등장했나:
  "약한 학습기(weak learner) 여러 개를 조합하면 강한 학습기가 된다"
  (Boosting 이론, Schapire 1990) — 이론적 증명에서 시작.

핵심 원리:
  [라운드 t]
  1) 현재 가중치로 약한 학습기(얕은 나무) 학습
  2) 틀린 샘플 비율로 이 학습기의 신뢰도 α_t 계산
     α_t = 0.5 × log((1-오류율) / 오류율)
     → 잘 맞출수록 α 크고, 무작위 수준(오류율=0.5)이면 α=0
  3) 가중치 업데이트:
     - 틀린 샘플: w × exp(+α_t) → 가중치 증가
     - 맞춘 샘플: w × exp(-α_t) → 가중치 감소
  4) 최종 예측 = Σ α_t × 각 학습기 예측 (신뢰도 가중 합산)

약점 — 왜 GBM에 자리를 내줬나:
  이상치(outlier)가 있으면 계속 틀리므로 가중치가 폭발적으로 증가.
  → 이상치 하나가 전체 모델을 망침.
  GBM은 잔차를 직접 맞추므로 이 문제를 우회.

어떤 상황에서 이점:
  - 이상치가 없고 깨끗한 데이터
  - 해석 가능한 앙상블이 필요할 때
  - 빠른 학습이 필요한 비교적 단순한 분류 문제
```

### [선택] XGBoost vs GBM: 왜 실무 표준이 됐나
```
왜 등장했나:
  GBM은 느리고 (순차적 탐색), 정규화가 약하고, 결측치를 못 다룸.
  Chen & Guestrin (2016)이 이 세 가지를 동시에 해결.

핵심 차이 — GBM vs XGBoost:

  GBM: 1차 미분(기울기)만으로 다음 트리 학습
       → "어느 방향으로 가야 하나"만 앎

  XGBoost: 2차 미분(곡률)까지 사용 (Taylor 2차 근사)
       → "얼마나 가야 하나"까지 계산 → 최적 leaf 값을 수식으로 결정
       → 더 적은 트리로 더 정확한 수렴

  정규화 추가:
       트리 구조 자체에 L1/L2 페널티 → 리프 수·리프 값 크기 제약
       → 과적합 방지를 모델 구조 수준에서 처리

  결측치 자동 처리:
       각 노드에서 결측치를 왼쪽/오른쪽 중 어디로 보낼지 학습
       → 별도 결측 처리 없이 바로 학습 가능

  병렬화:
       각 트리의 분할 탐색을 CPU 멀티코어로 병렬 처리
       → GBM 대비 10배 이상 빠름

LightGBM (추가 발전):
  histogram 기반 분할: 연속값을 bin으로 묶어 탐색 공간 축소
  leaf-wise 성장: 오차를 가장 많이 줄이는 leaf만 우선 확장
  → 대규모 데이터에서 XGBoost보다 빠름, 메모리 효율적

어떤 상황에서 이점:
  - 테이블 데이터 + 최고 성능이 목표
  - 결측치가 많은 실무 데이터
  - 빠른 실험 반복이 필요한 Kaggle·프로덕션
  단점: 하이퍼파라미터가 많아 튜닝 필요, 트리 해석 불가
```

**[추가] XGBoost 실사례**
→ 슬라이드 5
```
Kaggle 우승 사례:
  2014~2022년 Kaggle 테이블 데이터 경쟁 우승 솔루션의 절반 이상이
  XGBoost 또는 LightGBM 계열.

광고 클릭률 예측 (CTR):
  수억 건의 광고 노출 로그 → "이 사용자가 클릭할 확률?"
  실시간 입찰(RTB) 시스템에서 ms 단위로 XGBoost 추론.

금융 부도 예측:
  수백 개 재무 변수 → 기업 부도 확률
  연속 학습(오차 보정)으로 경기 변화에 빠르게 적응.
```

**[예상 질문]** "딥러닝이 더 강한 거 아닌가요?"
→ "테이블 데이터(엑셀 형태)에서는 XGBoost가 여전히 강합니다.
   Kaggle 우승 솔루션 상당수가 XGBoost 계열이에요.
   딥러닝은 이미지, 텍스트, 음성처럼 구조가 다른 데이터에서 강합니다."

### [추가] 학습 곡선 읽기: 진단 → 조정 (10분)
→ 슬라이드 5-1

```
"XGBoost를 돌렸더니 결과가 나왔습니다.
 근데 이 결과가 좋은 건지 나쁜 건지, 뭘 바꿔야 하는지 어떻게 알까요?
 학습 곡선을 읽을 수 있어야 합니다."

학습 곡선 = 훈련 오차 vs 검증 오차를 epoch(또는 트리 수)에 따라 그린 그래프

케이스 1: 과적합 (Variance 문제)
  증상: 훈련 오차 ↓↓, 검증 오차 ↑ 또는 정체, gap이 계속 벌어짐
  의미: 모델이 훈련 데이터 노이즈까지 외움
  조치:
    - 규제 강화 (XGBoost: lambda ↑, alpha ↑)
    - max_depth ↓ (나무 얕게)
    - 학습률 ↓ + n_estimators ↑ (천천히 더 많이)
    - Early Stopping 더 일찍 적용
    - 훈련 데이터 추가 or 변수 줄이기

케이스 2: 과소적합 (Bias 문제)
  증상: 훈련 오차도 높음, 검증 오차와 비슷하게 높음, gap 없음
  의미: 모델이 데이터 패턴 자체를 못 잡음
  조치:
    - max_depth ↑ (나무 깊게)
    - n_estimators ↑
    - 학습률 ↑
    - 규제 완화 (lambda ↓)
    - 변수 추가 / 피처 엔지니어링

케이스 3: 수렴 불안정
  증상: 오차가 진동하며 내려가지 않음
  조치: 학습률 10배 낮춰보기

핵심: 하이퍼파라미터 조정 방향은 학습 곡선 케이스 진단이 먼저.
      케이스 확인 없이 파라미터 바꾸는 건 눈 감고 운전하는 것.

[예상 질문] "학습률은 얼마로 설정해야 하나요?"
→ "0.1로 시작해서 학습 곡선 보고 수렴 불안정하면 낮추고,
   과소적합이면 높이는 게 실무 관행입니다.
   XGBoost는 학습률 낮게 + n_estimators 높게 + Early Stopping 조합이 가장 안정적입니다."
```

### Bagging vs Boosting 최종 정리 (10분)
→ 슬라이드 6~7
```
Bagging(랜덤 포레스트): 분산 감소 → 노이즈 많고 과적합 걱정될 때
Boosting(XGBoost):    편향 감소 → 최고 성능이 목표일 때, 세심한 튜닝 필요

데이터 특성별 모델 선택 기준:

| 상황 | 선택 모델 | 이유 |
|------|-----------|------|
| 선형 관계 + 변수 해석 필요 | Ridge / Lasso | 계수로 영향력 직접 확인 |
| 비선형 + 결과 설명 必 (금융·법무) | Decision Tree | 규칙이 사람이 읽을 수 있는 형태 |
| 비선형 + 안정성 + 변수 많음 | Random Forest | 튜닝 덜 민감, 빠른 baseline |
| 비선형 + 최고 성능 목표 | XGBoost | 튜닝 필요하지만 성능 최상 |
| 결측치 많은 실무 데이터 | XGBoost | 결측치 자동 처리 내장 |
| 데이터 100만 건 이상 | LightGBM | 속도·메모리 효율 우월 |

빠른 기준: "설명이 필요하면 나무, 성능이 필요하면 XGBoost, 둘 다면 RF로 시작"
```

---

## 5차시 — 한계와 극복, 설명하고 설득하기

### ML의 네 가지 한계 (8분)
```
1. 블랙박스: 왜 그렇게 예측했는지 설명 불가
   → 금융·의료처럼 설명 의무가 있는 분야에서 치명적

2. 데이터 편향: 편향된 데이터로 학습하면 편향된 예측
   → 채용 AI 차별 사례, 신용 심사 공정성 이슈

3. 인과관계 없음: 상관관계를 인과관계로 착각하는 함정
   → "아이스크림 판매 ↑ = 익사 사고 ↑" (둘 다 여름이 원인)

4. Distribution Shift: 학습 시점과 배포 시점의 데이터 분포가 다를 때
   → 모델은 과거 데이터로 학습했는데, 세상이 바뀌면 성능이 떨어짐
   → 예: 코로나 이전 소비 패턴으로 학습한 모델을 2020년에 그대로 사용
   → 해결: 정기적 모델 재학습, 성능 모니터링, 데이터 분포 변화 감지
```

### SHAP으로 블랙박스 열기 (16분)
→ 슬라이드 2~3
```
"이 고객의 이탈 확률이 80%인 이유가 뭔가요?
 SHAP은 각 변수가 최종 예측에 얼마나 기여했는지 게임이론으로 계산합니다."

기존 Feature Importance: 전교 회장 뽑기 (전체 영향력)
SHAP: 이번 시험 네 수학 점수에 학원이 몇 점 기여했나 (개별 기여)
```

### [선택] SHAP Shapley Value: 계산 원리
```
왜 등장했나:
  기존 Feature Importance (불순도 기반):
    - 전체 데이터에서 어떤 변수가 분할에 많이 쓰였는지
    - 개별 예측 설명 불가, 변수 간 상관 있으면 왜곡

  LIME (이전 방법):
    - 예측 주변을 국소적으로 선형 근사 → 근사 오차 있음
    - 반복마다 결과가 달라지는 불안정성

  Shapley Value (Lundberg & Lee, 2017):
    - 게임이론에서 공정한 이익 배분 방식을 ML에 적용
    - 수학적으로 유일하게 공정한 기여도 분배

핵심 원리 — 협력 게임 직관:
  "5명이 팀 프로젝트를 해서 100점을 받았다.
   각 팀원의 기여도를 어떻게 공정하게 나누나?"

  Shapley 방식:
  - 가능한 모든 팀원 조합을 만들어봄 (2^5 = 32가지)
  - 각 조합에서 A가 추가될 때 점수가 얼마나 오르는지 측정
  - 그 평균값 = A의 Shapley Value

  ML에 적용:
  - 팀원 = 변수 (feature)
  - 프로젝트 점수 = 모델 예측값
  - 변수 A의 SHAP = 모든 변수 조합에서 A를 추가할 때 예측 변화의 평균

보장되는 4가지 공정성 조건:
  ① 효율성: 모든 변수의 SHAP 합 = 예측값 - 기준값(전체 평균)
  ② 대칭성: 같은 기여를 한 변수는 같은 SHAP
  ③ 더미: 아무 영향 없는 변수의 SHAP = 0
  ④ 선형성: 두 모델 합의 SHAP = 각 모델 SHAP의 합

TreeSHAP의 효율화:
  모든 조합 수 = 2^p (변수 수가 100개면 2¹⁰⁰ → 계산 불가)
  트리 구조를 활용해 O(TLD²) 다항 시간으로 정확히 계산
  (T=트리수, L=리프수, D=깊이)

어떤 상황에서 이점:
  - 개별 예측에 대한 설명이 필요할 때 (왜 이 고객이 이탈 위험?)
  - 금융·의료·법무 등 설명 의무가 있는 도메인
  - 모델 편향 감사 (특정 변수가 불공정하게 작용하는지 확인)
  단점: 변수 간 상관이 높으면 SHAP도 오해를 줄 수 있음
        전체 변수 중요도는 mean(|SHAP|)로 집계
```

### [추가] 시각화로 설득하기 (8분)
→ 슬라이드 6
```
설득의 3단 구조:
  1) 주장: "고객 이탈률이 증가했습니다"
  2) 근거: "3월 이탈률 12% → 4월 18%, +50% 증가"
  3) 시각화: 꺾은선 그래프로 추세와 변화 시점을 동시에 보여줌

차트 선택 원칙:
- 비교하려면     → 막대 (동일 범주 간) or 꺾은선 (시간 흐름)
- 관계 보려면    → 산점도 (두 변수의 패턴)
- 구성 보려면    → 누적 막대 (파이는 3개 이상이면 오히려 헷갈림)
- 분포 보려면    → 히스토그램, 박스플롯

좋아졌다 → 금지 표현:
  X: "전처리 후 데이터 품질이 좋아졌습니다."
  O: "결측치 비율이 8.3% → 0%로, 이상치 제거 후 평균이 42 → 38로 줄었습니다."

숫자로 증명하지 않으면 주장이 아니라 의견입니다.
```

### [추가] 다음에 뭘 공부하나? (5분)
→ 슬라이드 8
```
학습 로드맵 (입문 → 실전):

  1단계 — sklearn으로 모델 직접 돌리기
    → titanic, iris 데이터로 LinearRegression·DecisionTree 실습
    → train_test_split, cross_val_score 체득

  2단계 — XGBoost + 하이퍼파라미터 튜닝
    → Kaggle 입문 대회 (Home Credit, Titanic)
    → GridSearchCV, Optuna로 튜닝 경험

  3단계 — SHAP으로 모델 해석
    → shap.TreeExplainer, waterfall_plot
    → "모델이 왜 이 예측을 했는가" 설명 가능해지기

  4단계 (선택) — 에이전틱 AI 시대의 ML 엔지니어
    → 만든 모델을 API로 서빙 (FastAPI + sklearn/XGBoost)
    → 에이전트가 예측 API를 호출하는 구조 체험
    → MLOps 기초: 모델 버전 관리, 성능 모니터링
    → "좋은 모델 하나"에서 "시스템 안에서 작동하는 모듈"로 사고 전환

  핵심 메시지:
  2026년 시장의 승패는 '누가 더 좋은 모델'이 아니라
  'ML을 얼마나 안정적으로 운영하느냐'로 갈립니다.
  3단계까지 익히면 그 운영의 핵심 능력을 갖춘 겁니다.

Kaggle 시작 방법:
  - 계정 생성 → Getting Started 대회 참여
  - 노트북 공유 문화 → 남의 코드 읽는 것도 공부
  - 순위보다 '왜 이 접근이 효과적인가' 이해가 목적
```

---

## 6차시 — EDA 실습 + 과제 안내

### EDA 강의 (30분)
```
오프닝:
"모델보다 데이터가 먼저입니다.
 오늘 배울 건 분석의 첫 단계, 탐색적 데이터 분석입니다."

핵심 메시지:
- 모든 분석은 데이터 진단부터
- Before/After 비교가 핵심 증명 방식
- '좋아졌다' 대신 '평균이 X에서 Y로 바뀌었다'

결측치 처리 의사결정 기준:
  비율 < 5% + 무작위 결측 → 행 삭제 (정보 손실 최소)
  비율 5~30% + 그룹 패턴 있음 → 그룹별 평균/중앙값 대체
  비율 > 30% → 변수 삭제 검토 or "결측" 자체를 범주로 추가
  시계열 데이터 → 앞뒤 값 보간 (forward fill)

  처리 후 반드시 기록: "변수 X: 결측 12% → 그룹 중앙값 대체, 이유: 요일별 패턴 확인됨"

이상치 처리 의사결정 기준:
  도메인상 불가능한 값 (음수 대여량, 나이 200세) → 즉시 제거 (에러)
  IQR 1.5배 초과 → 도메인 확인 먼저
    → 실제 이벤트 (계절 피크, 경제 충격) → 유지 (정보가 있는 이상치)
    → 측정 오류 → 제거 or 상한값 클리핑
  트리 계열 모델 → 이상치 영향 작음 (분할 기준 기반)
  선형 모델 → 이상치 영향 큼 → 적극 처리 필요

  핵심: "이상치를 제거한 이유"를 숫자로 기록해야 분석이 설득력을 가진다.
```

### 과제 안내 (15분)
```
시나리오 소개:
"여러분은 서울시 자전거 공유 수요를 분석하는 데이터 분석가입니다.
 데이터에는 결측치, 이상치, 중복이 섞여 있습니다.
 전처리 전/후를 비교해서 신뢰할 수 있는 인사이트를 도출해보세요."

강조 포인트:
- 순위 없음, 채점 없음 — 직접 해보는 게 목적
- 코드보다 '왜 이 방법을 선택했나'가 더 중요
- 분석 결과는 반드시 숫자로 증명
- random_state 고정 필수: 모든 모델·분할에 random_state=42 (또는 임의 고정값) 설정 — 같은 코드가 매번 다른 결과를 내면 분석을 신뢰할 수 없음
```

### 자주 나올 질문 대응
| 질문 | 답변 |
|---|---|
| "결측치 어떻게 처리해야 해요?" | "일단 비율이랑 패턴 먼저 보세요. 비율이 낮으면 삭제, 패턴이 있으면 그룹 대체" |
| "이상치 기준이 뭐예요?" | "IQR이 가장 실용적. 근데 도메인 맥락 먼저 봐야 해요 — 자전거 대여량 음수가 나오면 그냥 에러" |
| "시각화 어떤 라이브러리?" | "matplotlib, seaborn으로 충분. 화려한 거보다 축·단위 일관성이 더 중요" |
