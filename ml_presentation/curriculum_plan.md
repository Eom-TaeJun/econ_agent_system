# ML 학회 세션 커리큘럼 계획 (확정)

> 대상: 데이터 분석·AI 동아리 학회원 (ML 입문)
> 형식: 세미나형 | 차시당 약 1시간 | 총 6차시
> 중심 메시지: "도구를 알고, 골라서, 설명할 수 있어야 분석이다"
> → 각 선택(모델·지표·전처리)에 '왜'가 있어야 한다. 판단의 흐름을 가진 사람이 AI를 제대로 활용할 수 있다.

---

## 전체 흐름

```
1차시        2차시            3차시          4차시         5차시         6차시
"왜 ML"  →  "쓰면 생기는  →  "직선 한계  →  "나무 한계  →  "설명까지   →  EDA
              문제"             극복"           극복"          해야 완성"     실습
```

---

## 차시별 키워드 맵

### 1차시 — 왜 ML인가

| 키워드 묶음 | 내용 |
|---|---|
| 시대 배경 | 데이터 폭증, 연산력 발전, AI 시대 |
| 기존과 다른 점 | 통계학(원인 규명) vs ML(결과 예측), 블랙박스 허용 |
| ML이 답하는 질문 | 회귀 / 분류 / 군집 / 해석 |
| 어디에 쓰이나 | 금융·마케팅·의료·스포츠 실제 사례 |
| **[추가] LLM 시대에도 ML인가?** | GPT가 있는데 왜 ML인가 → 테이블 데이터 한계, LLM 내부도 ML, 실무 데이터 대부분 테이블 |

→ 연결: "그런데 막상 쓰면 문제가 생긴다"

---

### 2차시 — 자유에는 대가가 따른다

| 키워드 묶음 | 내용 |
|---|---|
| 출발점 | 선형회귀, 다중공선성, 변수가 많으면? |
| 핵심 문제 | 과적합(Overfitting), 외우는 모델, Underfitting |
| 해결책 | 규제화, Ridge vs Lasso, 언제 뭘 선택하나 |
| 분류 맛보기 + 지표 선택 | 로지스틱 회귀, 정확도의 함정, **상황별 지표 선택 기준** (Recall vs Precision vs AUC — 언제 어떤 지표인가) |
| **[추가] 실무 함정** | Data Leakage — 미래 정보가 학습에 섞이는 위험, 테스트 성능 좋아도 실제 배포하면 망하는 이유 |

→ 연결: "직선으로도 한계가 있다"

---

### 3차시 — 나무로 규칙을 만든다

| 키워드 묶음 | 내용 |
|---|---|
| 비선형성 | 직선의 한계, IF-THEN 규칙 |
| 의사결정나무 | 스무고개 비유, 해석 가능, 재귀적 분할 |
| 핵심 개념 | **Bias-Variance Tradeoff** ← 3·4차시 연결 허브 |
| 집단지성 | Bagging, 랜덤 포레스트, 분산 감소 |
| **[추가] 실사례** | Decision Tree: 대출 심사 규칙 / Random Forest: 신용카드 이상거래 감지·질병 위험도 |

→ 연결: "나무 하나로도 한계가 있다"

---

### 4차시 — 오답 노트 공부법

| 키워드 묶음 | 내용 |
|---|---|
| Boosting 철학 | 순차 학습, 틀린 곳 집중, 오답 노트 비유 |
| 기법 진화 | AdaBoost(가중치) → GBM(잔차 학습) → XGBoost |
| 실무 튜닝 + 진단 | 학습률 개념 → **학습 곡선 읽기** (과적합/과소적합 진단 → 파라미터 조정 방향) |
| **[추가] 실사례** | XGBoost: Kaggle 우승 솔루션 다수, 광고 클릭률 예측, 금융 부도 예측 |
| 총정리 | Bagging vs Boosting 비교, **전체 모델 선택 가이드** |

→ 연결: "잘 맞추면 끝인가?"

---

### 5차시 — 설명할 수 있어야 쓸 수 있다

| 키워드 묶음 | 내용 |
|---|---|
| ML의 한계 | 블랙박스, 데이터 편향, 인과 ≠ 상관, **Distribution Shift** |
| 극복 | SHAP, 왜 그렇게 예측했나, 변수 기여도 |
| **[추가] 시각화 설득 원칙** | 주장→근거→시각화 3단 구조, 차트 유형별 선택 기준, "좋아졌다" 대신 정량 표현 습관 |
| 마무리 | 데이터 사이언티스트 사고 흐름 (목적→모델→평가→설명→제안) |
| **[추가] 다음 공부 방향** | Kaggle 실습, sklearn → XGBoost → SHAP 순서, 추천 학습 경로 |

---

### 6차시 — EDA + 과제 (보강 세션)

| 키워드 묶음 | 내용 |
|---|---|
| 왜 EDA가 먼저인가 | 쓰레기 IN·OUT, 모델보다 데이터 품질 |
| 데이터 진단 | 결측 / 이상치 / 중복 / 타입 |
| Before/After | 같은 축 비교, 숫자로 증명 |
| 과제 안내 | 서울 자전거 수요 데이터, 10문항, 체험 목적 |

---

## 원본 슬라이드 → 차시 배치표

| 원본 슬라이드 | 제목 요약 | 배치 차시 | 처리 |
|---|---|---|---|
| 슬라이드 5 앞부분 | 왜 지금인가 (시대 배경) | 1차시 ① | 훅으로 앞으로 이동 |
| 슬라이드 1 | Inference vs Prediction | 1차시 ② | 유지 |
| 슬라이드 4 | ML의 전환점 (블랙박스) | 1차시 ③ | 유지 |
| [신규] | ML 질문 유형 지도 | 1차시 ④ | 신규 추가 |
| 슬라이드 5 뒷부분 | 기법 진화 예고 | 1차시 ⑤ | 예고로 활용 |
| 슬라이드 2+3 압축 | 선형회귀 + 다중공선성 | 2차시 ① | 1장으로 압축 |
| 슬라이드 6 | 과적합 | 2차시 ② | 유지 (2차시 메인) |
| 슬라이드 7, 8, 9, 10 | 규제화, Ridge, Lasso | 2차시 ③~⑤ | 유지 |
| 슬라이드 10-1 | PCA | **부록** | 흐름 분리됨 |
| 슬라이드 11~12-2 | 로지스틱, 평가지표, 교차검증 | 2차시 (압축) | 맛보기 수준으로 압축 |
| 슬라이드 13~16 | 의사결정나무, 장단점 | 3차시 ①~③ | 유지 |
| 슬라이드 17 | Bias-Variance Tradeoff | 3차시 ④ | 확대 (핵심 슬라이드) |
| 슬라이드 18~19 | Bagging, 랜덤 포레스트 | 3차시 ⑤ | 유지 |
| 슬라이드 20~22 | Boosting, AdaBoost, GBM | 4차시 ①~③ | 유지 |
| 슬라이드 23~23-2 압축 | 학습률, Early Stopping | 4차시 ④ | 1~2장으로 압축 |
| 슬라이드 24~25 | 비교 정리, 모델 선택 가이드 | 4차시 ⑤~⑥ | 4차시 클라이맥스 |
| [신규] | ML 한계 3가지 | 5차시 ① | 신규 추가 |
| 슬라이드 27~28 | SHAP | 5차시 ②~③ | 유지 |
| [신규/보강] | 시각화로 설득하기 | 5차시 ④ | 신규 추가 |
| 슬라이드 29 | 데이터 사이언티스트 사고 과정 | 5차시 ⑤ | 마무리로 이동 |
| 슬라이드 26 | 결론 | 5차시 ⑥ | 맨 마지막으로 이동 |
| 슬라이드 30~30-1 | 군집화, 엘보우 | **부록** | 선택 사항 |
| AIC/BIC | 모형 선택 기준 | **부록** | 우선순위 최하 |

---

## 과제 운영 원칙

- 채점: 순위 없음, 완료 여부 + 피드백 코멘트 중심
- 데이터: `eda_teaching_pack/data/raw_dirty.csv` 배포
- 제출물: 분석 노트북 1개 + 보고서 2~4페이지
- 정답 코드: 비공개 (함수 인터페이스만 제공)
- 참고: `eda_teaching_pack/starter.ipynb` 배포

---

## 슬라이드 설계 원칙

```
각 슬라이드 = 제목(질문형/선언형 1줄)
            + 핵심 다이어그램 or 비유 (화면 60%)
            + 키워드 2~3개
            + 하단: "→ 실무에서는 ___에 쓴다"
```

- 수식은 슬라이드 제거 → 별도 배포 자료
- 각 차시 마지막은 반드시 다음 차시 연결 슬라이드
- 선택·결정 슬라이드는 반드시 "어떤 상황 → 어떤 선택 → 왜" 3단 구조로 작성
