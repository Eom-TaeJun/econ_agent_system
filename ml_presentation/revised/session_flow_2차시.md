
# 2차시 강의 대본 — 자유에는 대가가 따른다

> 시간: 60분 | 대상: 베이스 혼합(초급~중급) | 톤: 문제를 함께 풀어가는 느낌 | 슬라이드: 20장

---

## [연결] 1차시 → 2차시 브리지 (0~3분)

### → 슬라이드 2-01: 자유의 이면

```
"지난 시간 마지막에 뭐라고 했죠?

 '자유에는 대가가 따른다'

 어떤 의미였나요?

 통계학은 엄격했어요.
 '수식을 명확하게 세우고, 모든 가정을 검증하고, 틀리면 답이 없다'

 ML은 자유로워졌어요.
 '변수 1,000개도 처리하고, 뭐든 시도하고, 예측만 잘 되면 된다'

 이 자유가 정말 좋을까요?

 오늘 우리가 볼 건,
 이 자유가 어떤 대가를 치르게 하는지,
 그리고 그 대가를 어떻게 치르지 않는지입니다."
```

**[강조]**
```
"좋은 소식은:
 대가를 안 치를 수는 없지만,
 그 대가를 최소화하는 방법이 있다는 거.

 오늘 배우는 게 정확히 그겁니다."
```

→ **실무에서는**: 90% 정확도로 배포했다가 2개월 후 50%로 떨어지는 모델들이 많아요. 오늘 배우는 게 정확히 이걸 방지하는 방법입니다.

**[예상 질문]** "정확도가 떨어지는 게 정상인가요?"
→ "네, 정상입니다. 배포 후 시간이 지나면서 데이터의 특성이 바뀌거든요. 그걸 감지하고 대응하는 방법을 배웁니다."

---

## [출발] 통계의 딜레마에서 ML로 (3~10분)

### → 슬라이드 2-02: 선형회귀가 공포하는 것 — 다중공선성

```
"처음부터 시작해보겠습니다.

 선형회귀는 어떻게 작동할까요?

 간단한 예:
 '이 집의 가격 = 평수 × 계수1 + 방 개수 × 계수2 + ...'

 통계학은 이 계수들을 '정확하게' 구해야 한다고 강조합니다.

 왜냐면 계수가 '각 변수의 영향력'을 직접 보여주거든요.

 그런데 문제가 생겨요.

 예를 들어:
 - 평수와 방 개수는 보통 함께 변해요 (크면 방도 많고, 작으면 방도 적고)
 - 거리와 지하철역까지의 시간도 함께 변해요

 이런 상황을 '다중공선성'이라고 부릅니다.

 '변수들이 서로 연관되어 있다'는 뜻이에요.

 그러면 어떻게 될까요?

 통계학의 신기로운 발견:

 '계수를 정할 수 없어진다'

 비유하자면:
 학교에서 '범죄자를 찾는 경찰'의 입장이에요.

 증인 A가 증언해요:
 '범인은 키 180cm, 검은 옷 입었어요'

 증인 B가 증언해요:
 '범인은 키 180cm, 검은 옷 입었어요'

 둘의 증언이 똑같아요.

 그럼 경찰은 뭐가 더 중요한지 알 수 없어요.
 '키일까? 옷깔일까?'

 법정에서도 같은 증거를 두 번 받으면 증거 가치가 반감돼요.

 통계학도 비슷해요.

 두 변수가 완벽히 연관되면,
 '어느 변수의 영향인지' 수학적으로 구분 불가.

 계수를 정할 수 없으니 수식이 무너져요."
```

**[전환]**
```
"그래서 통계학은 이렇게 말했어요:

 '다중공선성이 있으면 그 모델은 쓸 수 없다.
  다시 설계하거나, 변수를 버려야 한다.'"
```

→ **실무에서는**: 금융권에서 신용점수를 만들 때 변수 100개 중에 90개를 버리고 10개만 쓰는 이유가 이겁니다.

**[예상 질문]** "그럼 모든 데이터가 다중공선성이 있나요?"
→ "현실의 거의 모든 데이터가 어느 정도는 있어요. 그래서 통계학이 어려운 거고, ML이 나온 거예요."

---

### → 슬라이드 2-03: ML의 혁신적 대답

```
"그런데 ML이 나와서 이렇게 말했어요:

 '그런데 우리가 정말 '왜'를 알아야 해?

 계수1이 1이든 2이든,
 최종 예측이 맞으면 되지 않아?

 괜히 복잡하게 생각하지 말고,
 결과만 맞추자.

 변수 1,000개든 10,000개든,
 예측이 정확하면 그게 좋은 모델이야.'"

 이게 ML의 출발점입니다.

 통계학은 '이유'를 원했는데,
 ML은 '결과'만 원해버린 거예요.

 이게 정말 혁신적이었어요.

 왜냐면:
 - 변수가 많아도 괜찮아
 - 변수 간 관계가 복잡해도 괜찮아
 - 설명은 못 해도 예측만 잘하면 돼

 이 자유함이 ML을 강력하게 만들었어요.

 근데 여기부터가 문제의 시작입니다."
```

→ **실무에서는**: Google의 추천 알고리즘이 개별 변수의 영향을 설명할 수 없지만, 추천이 정확하니까 쓰죠.

**[예상 질문]** "그럼 정확도가 높으면 무조건 좋은 건가요?"
→ "아뇨. 정확도가 높아도 '실제 데이터'에서는 엉망인 경우가 많아요. 그게 오늘의 핵심 주제입니다."

---

## [핵심] 과적합 — 자유가 만든 첫 번째 함정 (10~22분)

### → 슬라이드 2-04: 기출문제를 외운 학생

```
"아이들의 공부 방식을 보면 두 가지가 있어요.

 [방식 1] 이해하며 공부하는 학생
 '이 개념이 뭐고, 왜 이렇게 작동하는지 이해하자'
 → 처음에는 천천히 배우지만
 → 새로운 문제를 줘도 풀어낸다

 [방식 2] 기출문제를 외우는 학생
 '올해 기출문제 1,000개를 다 외워버렸다'
 → 기출 문제는 100% 정답을 맞힌다
 → 근데 시험에 처음 보는 문제가 나온다면?
 → 아무것도 못 푼다

 이게 정확히 '과적합'입니다.

 ML 모델이 '학습 데이터'(=기출문제)를 너무 잘 외워서,
 '새로운 데이터'(=시험 문제)를 못 푸는 거예요.

 실제 예시:

 [시나리오]
 마케팅팀이 이탈 고객 예측 모델을 만들었어요.

 학습 데이터: 지난 1년 고객 1,000명
 테스트 데이터: 이번 달 새 고객 100명

 모델을 훈련시켜봤어요:

 '학습 데이터에서의 정확도: 95%'
 와! 이제 배포하자!

 3개월 후...

 '실제 배포 성능: 55%'
 어? 뭐가 잘못됐어?

 뭐가 잘못됐을까요?

 이유는:
 모델이 학습 데이터의 '개별 고객의 특이사항'까지 외워버렸거든요.

 예를 들어:
 '2월에 가입한 고객 중에서 월급 날에 거래하지 않는 사람은 이탈한다'

 이런 식의 매우 구체적인 규칙이 만들어졌어요.

 그 규칙은 학습 데이터에선 정확하지만,
 '다른 달, 다른 시점'에는 안 통해요.

 모델이 '진짜 패턴'을 배운 게 아니라,
 '학습 데이터의 노이즈'까지 배운 거예요.

 이게 과적합입니다.

 가장 중요한 점:

 '과적합은 대부분 눈에 띄지 않아요.

  훈련할 때 정확도는 좋은데,
  배포하고 시간이 지나야 문제가 보인다.'"
```

**[안심 멘트]**
```
"지금 이게 이해가 안 가도 괜찮아요.
 이게 딱 이거 하나만 기억해야 하는 부분입니다:

 '훈련 정확도 90% ≠ 실제 정확도 90%

  둘은 완전히 다를 수 있다.'"
```

→ **실무에서는**: Netflix의 추천 모델도 훈련할 때는 95% 정확도지만, 3개월 후 성능이 떨어지면 재훈련합니다.

**[예상 질문]** "그럼 어떻게 알아요? 과적합인지 아닌지?"
→ "테스트 데이터를 따로 떼어놓고, 그 데이터에서의 성능을 봐요. 훈련과 테스트 성능의 차이가 크면 과적합이에요."

---

### → 슬라이드 2-05: 훈련 오차 vs 테스트 오차 — 왜 달라질까

```
"자, 이제 그 차이를 직접 봅시다.

 [학습 데이터 (Training Set)]
 예시: 1,000명의 과거 고객
 모델: 이 데이터로 훈련해요
 결과: '훈련 정확도 90%'

 [테스트 데이터 (Test Set)]
 예시: 100명의 새로운 고객 (모델이 본 적 없는 데이터)
 모델: 이미 훈련된 모델이 예측
 결과: '테스트 정확도 50%'

 둘의 차이가 무려 40%포인트!

 이 차이가 뭐냐면:

 '모델이 훈련 데이터에서 '진짜 패턴'을 80% 배웠고,
  '노이즈와 우연'을 20% 외웠다는 뜻'

 그 노이즈는 훈련 데이터에만 있으니까,
 새로운 데이터에서는 정확도가 떨어지는 거예요.

 비유:

 학생이 기출문제 1,000개를 풀었어요.
 '이 문제는 X가 답이다, 저 문제는 Y가 답이다' 다 외웠어요.

 그런데 실제 시험에는:
 - 새로운 문제들이 나온다
 - 조금 다른 형식으로 나온다
 - 예상치 못한 함정이 있다

 그래서 '외운' 학생은 못 푼다.
 근데 '이해한' 학생은 풀어낸다.

 ML도 같아요.

 과적합: 외운 모델
 적절한 수준의 학습: 이해한 모델

 핵심 질문:

 '그럼 어디가 정답일까요?
  훈련 정확도 90%를 믿을까요?
  테스트 정확도 50%를 믿을까요?'

 답: 테스트 정확도만 믿으세요.

 왜냐면 테스트 데이터가 '실제 배포 환경'의 시뮬레이션이거든요."
```

→ **실무에서는**: 대부분의 실패한 ML 프로젝트가 "훈련에서 좋았는데 배포 후 망했다"는 패턴입니다.

**[예상 질문]** "훈련 정확도가 50%, 테스트도 50%면 괜찮은 건가요?"
→ "네, 그게 훨씬 낫습니다. 둘이 가까우면 '정직한' 모델이에요. 낮지만 신뢰할 수 있어요."

---

### → 슬라이드 2-06: Bias-Variance Tradeoff 예고

```
"여기서 한 가지 중요한 개념이 나타나요.

 '모델의 오차'는 두 가지로 나뉜다:

 [편향 (Bias)]
 '모델이 너무 단순해서 패턴 자체를 못 잡는다'

 예: 곡선 데이터에 직선 하나를 그으면
    아무리 훈련해도 틀린다

 [분산 (Variance)]
 '모델이 너무 민감해서 훈련 데이터의 노이즈까지 배운다'

 예: 복잡한 곡선을 그으면
    훈련 데이터는 완벽하지만
    새로운 데이터에서는 엉망이다

 이 둘은 서로 '트레이드오프' 관계예요.

 복잡도를 높이면:
 - Bias는 낮아진다 (더 복잡한 패턴을 잡을 수 있다)
 - Variance는 높아진다 (노이즈도 더 많이 외운다)

 복잡도를 낮추면:
 - Bias는 높아진다 (패턴을 놓친다)
 - Variance는 낮아진다 (안정적이다)

 우리가 원하는 건:
 'Bias도 낮고 Variance도 낮은 상태'

 그런데 그건 불가능해요. 한쪽을 줄이면 다른 쪽이 는다.

 최적은 그 사이 어딘가를 찾는 것.

 오늘 배우는 '규제화'가 정확히 이걸 하는 거예요."
```

→ **실무에서는**: XGBoost 모델이 오버피팅되면, 우리는 "Variance를 낮춘다"는 표현을 써요.

---

## [해결] 규제화 (22~32분)

### → 슬라이드 2-07: 규제화의 등장

```
"과적합을 막기 위한 핵심 아이디어:

 '손실 함수에 벌칙을 더한다'

 이게 뭔 말일까요?

 원래 ML은 이렇게 목표를 세웠어요:

 '오차(예측이 틀린 정도)를 최소화하자'

 근데 규제화는 이렇게 바꿔요:

 '오차를 최소화하면서,
  동시에 계수의 크기도 작게 유지하자'

 왜 계수를 작게 유지할까요?

 이유:

 복잡한 모델(오버피팅된 모델)은
 계수들이 매우 크고 극단적인 경향이 있어요.

 예를 들어:
 '이 변수가 0.001 증가하면 결과가 1,000 증가한다' (극단적)

 반면 건강한 모델은:
 '이 변수가 0.1 증가하면 결과가 10 증가한다' (적절)

 계수를 작게 강제하면,
 모델이 극단적으로 복잡해질 수 없어요.

 이게 바로 '규제화'의 철학입니다.

 비유:

 학생에게 이렇게 말하는 거예요:

 '기출문제를 풀면 100점 만점을 다 주겠지만,
  한 가지 조건이 있어.

  너는 이 문제들에서 이상한 패턴을 찾으면 안 돼.
  예를 들어, "짝수 번 문제는 무조건 C"라든지,
  "월요일 문제는 B"라든지 하는 식 말이야.

  진짜 개념을 공부하면서 동시에,
  너의 특이한 습관들은 줄이렴.

  그러면 새로운 시험에서도 잘할 가능성이 높아질 거야.'"
```

→ **실무에서는**: Ridge와 Lasso는 모두 이 규제화를 구현한 것들입니다.

---

### → 슬라이드 2-08: Ridge vs Lasso — 다이아몬드 vs 원

```
"규제화에는 두 가지 방식이 있어요.

 [Ridge 규제화]
 특징: 계수를 작게 만들지만, 0으로는 안 만든다
 결과: 모든 변수가 계속 영향을 미친다 (단, 약하게)

 비유: 학생의 '습관들을 조금씩 순화한다'
      약간 나쁜 습관은 남아 있지만 약해진다

 [Lasso 규제화]
 특징: 계수를 정확히 0으로 만들 수 있다
 결과: 덜 중요한 변수는 완전히 제거된다

 비유: 학생의 '나쁜 습관을 완전히 없앤다'
      중요한 습관만 남고, 나머지는 버린다

 어떻게 이런 차이가 생길까요?

 [기하학적 직관]

 이건 수식 없이 그림으로 이해하면 돼요.

 두 규제화의 영역을 그려보면:

 Ridge: 원(circle) 모양
 - 둥근 모양이라서
 - 최솟값이 축(=변수)에 정확히 걸릴 가능성이 낮다
 - 그래서 계수가 0이 되기 어렵다

 Lasso: 다이아몬드(◇) 모양
 - 뾰족한 꼭짓점이 축 위에 있어서
 - 최솟값이 그 꼭짓점에 걸릴 가능성이 높다
 - 그래서 계수가 정확히 0이 된다

 [상황별 선택]

 Ridge를 쓸 때:
 - 변수들이 비슷한 중요도를 가질 때
 - 모든 변수를 살리고 싶을 때
 - '하나의 원인이 없다'는 도메인 지식이 있을 때

 예: 뉴스 추천 모델
     여러 특성(장르, 저자, 발행사)이 다 중요해요

 Lasso를 쓸 때:
 - '정말 중요한 변수 10개만 남기고 싶을 때'
 - 변수 해석이 필요할 때
 - '왜 이렇게 예측했는가'를 설명해야 할 때

 예: 의료 진단 모델
     수백 개의 임상 지표 중에서
     '진짜 진단에 영향을 미치는 10개만 찾고 싶다'

 핵심:

 Ridge = '모든 변수를 조금씩 약하게'
 Lasso = '중요한 변수만 강하게'

 그래서 금융규제가 강한 곳은 Lasso를 선호해요.
 '왜 이 고객을 거절했는가'를 '3~5개 변수'로 명확히 설명해야 하거든요."
```

→ **실무에서는**: Kaggle 우승 팀들은 "둘을 섞은" ElasticNet을 자주 씁니다.

**[예상 질문]** "그럼 항상 Lasso를 쓰면 되지 않나요?"
→ "변수들이 비슷한 정보를 가지고 있을 때, Lasso는 하나를 선택하고 나머지를 버려요. 그게 정보 손실일 수 있어요. Ridge는 둘 다 살려서 더 안정적이에요."

---

### → 슬라이드 2-09: 규제화의 진짜 의미 — Bias를 희생해서 Variance를 줄인다

```
"규제화가 정확히 뭘 하는지 깊이 있게 설명하면:

 '약간의 Bias를 포기해서 Variance를 크게 줄인다'

 이게 뭐냐면:

 [규제화 없을 때]
 - 모델이 훈련 데이터를 완벽히 맞춘다
 - Bias: 낮음
 - Variance: 높음 (=새로운 데이터에서 흔들린다)
 - 결과: 훈련 정확도 95%, 테스트 정확도 50%

 [규제화 할 때]
 - 모델이 훈련 데이터를 '약간' 덜 맞춘다
 - Bias: 조금 높아짐 (의도적으로!)
 - Variance: 크게 낮아짐
 - 결과: 훈련 정확도 82%, 테스트 정확도 78%

 어느 게 더 나아요?

 당연히 2번이에요.

 '훈련 정확도 3% 손실 (Bias 증가)로
  테스트 정확도 28% 이득 (Variance 감소)'

 이게 좋은 거래입니다.

 그래서 규제화의 강도(얼마나 강하게 벌칙을 줄 건가)를 조정하는 게
 ML에서 가장 중요한 기술입니다.

 너무 약하면: 과적합 여전히 발생
 너무 강하면: 과소적합 (=너무 단순해짐)

 최적의 강도를 찾는 게 우리의 일입니다."
```

→ **실무에서는**: XGBoost의 `lambda`와 `alpha` 파라미터가 정확히 이 규제화의 강도를 조정하는 것들입니다.

---

## [평가] 모델을 어떻게 평가하는가 (32~44분)

### → 슬라이드 2-10: 분류 문제 맛보기 — 예측이 맞다는 게 뭔가요

```
"지금까지 우리는 '정확도'를 마치 절대값처럼 얘기했어요.

 '훈련 정확도 90%, 테스트 정확도 80%'

 근데 이게 정말 좋은 건가요?

 여기서 질문이 하나 필요해요:

 '뭘 예측했는가?'

 지금까지는 '숫자'를 예측했어요.

 '내일 판매량은 몇 개?'
 '이 집 가격은 얼마?'

 이걸 '회귀 (Regression)' 문제라고 부르고,
 정확도 개념이 비교적 간단했어요.

 근데 이제는 '예/아니오' 같은 '선택'을 예측할 거예요.

 이걸 '분류 (Classification)' 문제라고 부르고,
 여기서는 '정확도'의 의미가 훨씬 복잡해집니다.

 [분류 문제 예시]

 '이 고객이 이탈할까?'
 → 예측: '네, 이탈합니다' 또는 '아니오, 유지합니다'

 '이 이메일은 스팸인가?'
 → 예측: '스팸입니다' 또는 '정상 메일입니다'

 '이 거래는 정상인가?'
 → 예측: '이상 거래입니다' 또는 '정상 거래입니다'

 [여기서의 '정확도' 문제]

 정확도 = '맞게 예측한 비율'

 근데 이게 속을 수 있어요.

 예를 들어:

 100명 중에서 2명이 이탈하는 데이터가 있어요.
 (암묵적 비율: 98%는 유지, 2%는 이탈)

 모델이 이렇게 했어요:
 '모든 고객이 유지한다'

 결과:
 '정확도 98%!'

 와! 좋은 모델이네요?

 아뇨. 최악의 모델입니다.

 왜냐면 '진짜 이탈할 2명'을 못 찾았거든요.

 이 모델은 실무에서 아무 가치가 없어요.

 여기서 필요한 게 '새로운 지표'입니다."
```

→ **실무에서는**: 불균형 데이터(99% 정상, 1% 이상)는 금융·의료·보안 분야에서 대부분이에요.

---

### → 슬라이드 2-11: Confusion Matrix — TP/FP/FN/TN의 의미

```
"분류 문제를 평가하기 위해,
 먼저 '맞고 틀린 경우'를 4가지로 나눕니다.

 [2×2 표 상상하기]

 |              | 예측: Positive | 예측: Negative |
 |--------------|----------------|----------------|
 | 실제: Positive | TP (True Pos)  | FN (False Neg) |
 | 실제: Negative | FP (False Pos) | TN (True Neg)  |

 [각각의 의미]

 TP (True Positive): 정답도 Positive, 예측도 Positive
 → '맞게 맞혔다' (좋음)

 FP (False Positive): 정답은 Negative, 예측은 Positive
 → '틀렸는데 Positive라고 했다' (오탐, False Alarm)

 FN (False Negative): 정답은 Positive, 예측은 Negative
 → '틀렸는데 Negative라고 했다' (놓침, 미탐)

 TN (True Negative): 정답도 Negative, 예측도 Negative
 → '맞게 맞혔다' (좋음)

 [의료 사례로 이해하기]

 '이 환자가 암인가?'를 예측한다고 하면:

 TP: 암이 있고, 모델이 '암이 있다'고 예측
     → 옳은 진단, 치료 시작 가능

 FP: 암이 없는데, 모델이 '암이 있다'고 예측
     → 오진, 불필요한 수술 위험

 FN: 암이 있는데, 모델이 '암이 없다'고 예측
     → 위험한 오진, 치료 기회 상실 → 생명 위험!

 TN: 암이 없고, 모델이 '암이 없다'고 예측
     → 옳은 진단

 [중요한 깨달음]

 암 진단에서는:
 'FP(오진)보다 FN(놓침)이 훨씬 더 나쁩니다.'

 오진이면 추가 검사로 확인할 수 있지만,
 놓침이면 생명이 위험해요.

 반면 스팸 필터에서는:
 'FP(정상 메일을 스팸으로)가 더 나쁩니다.'

 스팸을 놓치는 건 괜찮지만,
 중요 메일을 스팸으로 분류하면 업무 차질이 생겨요.

 이게 왜 중요한가?

 지표 선택이 달라지기 때문입니다."
```

→ **실무에서는**: 의료 AI와 보안 AI는 같은 정확도여도 다른 지표를 봐요.

---

### → 슬라이드 2-12: 정확도의 함정

```
"자, 이제 정확도가 왜 '함정'인지 봅시다.

 정확도 = (TP + TN) / (TP + FP + FN + TN)
        = '맞게 예측한 것들의 비율'

 이게 높아야 좋은 모델이라고 생각하기 쉽고,
 실제로 대부분의 경우 그래요.

 근데 불균형 데이터에선 이걸 믿으면 안 됩니다.

 [암 검진 예시]

 100만 명을 검진해요.
 실제 암 환자: 10,000명 (1%)
 암 아닌 사람: 990,000명 (99%)

 [모델 1: '무조건 암 아니다' 예측]
 예측:
 - 모든 사람에게 '암 없음' 판정
 - TP = 0, FP = 0, FN = 10,000, TN = 990,000
 - 정확도 = (0 + 990,000) / 1,000,000 = 99%

 와! 정확도 99%! 좋은 모델이네?

 아니요. 최악입니다. 암 환자 10,000명을 모두 놓쳤어요.

 [모델 2: 실제 좋은 모델]
 예측:
 - 실제 암 환자의 95%는 맞게 예측 (9,500명)
 - 실제 정상인의 2%는 오탐 (19,800명)
 - TP = 9,500, FP = 19,800, FN = 500, TN = 970,200
 - 정확도 = (9,500 + 970,200) / 1,000,000 = 97.97%

 모델 2가 모델 1보다 정확도가 낮지만,
 실제로는 훨씬 유용합니다.

 암 환자 500명을 놓치고,
 실제 암 환자 중 95%를 올바르게 진단했거든요.

 이때 필요한 지표가 Precision과 Recall입니다."
```

→ **실무에서는**: Kaggle 대회에서 불균형 데이터 문제는 거의 필수예요.

**[예상 질문]** "그럼 정확도는 아예 못 쓰는 건가요?"
→ "아뇨. 클래스 비율이 균형 잡혀 있으면(50:50, 60:40) 정확도를 써도 돼요. 근데 1:99 같은 불균형이면 Precision, Recall, F1, AUC 같은 다른 지표를 봐야 해요."

---

### → 슬라이드 2-13: 상황별 지표 선택 — 언제 뭘 쓰나

```
"이제 핵심입니다.

 '어떤 상황에서 어떤 지표를 쓰나'

 [지표 설명]

 Precision (정밀도)
 = TP / (TP + FP)
 = '양성으로 예측한 것 중 실제 양성의 비율'
 = '얼마나 정확하게 맞혔는가'

 Recall (재현율)
 = TP / (TP + FN)
 = '실제 양성 중 몇 개를 잡았는가'
 = '놓친 게 몇 개인가'

 F1 Score
 = Precision과 Recall의 조화 평균
 = '둘 다 중요할 때'

 AUC-ROC
 = 모든 임계값에서의 성능을 평가
 = '임계값을 아직 정하지 않았을 때' (모델 선택 단계)

 [상황별 선택 테이블]

 | 상황 | 선택 지표 | 이유 |
 |------|-----------|------|
 | 암 진단 | Recall | FN(놓침)이 생명 관련이므로 '놓치지 말자' |
 | 스팸 필터 | Precision | FP(오탐)이 사용자 신뢰에 영향 |
 | 신용 사기 탐지 | Recall | FN이 손실이므로 '놓치지 말자' |
 | 광고 추천 | Precision | FP는 무시된 광고일 뿐이라 문제 없음 |
 | 모델 선택 (배포 전) | AUC-ROC | 임계값이 아직 미정이므로 전체 성능 본다 |
 | 모델 성능 보고 (배포 후) | Precision / Recall | 비즈니스 목표에 맞춘 임계값에서의 성능 |

 [핵심 질문]

 '이 모델이 틀렸을 때 어느 쪽이 더 나쁜가?'

 그 답이 지표를 정합니다.

 암 진단에서 놓치는 게 나쁨 → Recall
 스팸 필터에서 오탐이 나쁨 → Precision"
```

→ **실무에서는**: 비즈니스 팀과 먼저 이 질문을 합니다: "우리는 FP 비용과 FN 비용 중 뭐가 더 크지?"

**[예상 질문]** "항상 F1을 쓰면 안 되나요?"
→ "F1은 Precision과 Recall이 동등하게 중요할 때만 써요. 대부분의 실무 문제는 하나가 더 중요해요."

---

### → 슬라이드 2-14: Train / Validation / Test 데이터 분할 — 왜 세 개로 나누나

```
"여기가 중요합니다.

 많은 사람들이 '학습과 테스트로만 나누면 되지 않나'라고 생각해요.

 아뇨. 세 개가 필요합니다.

 [역할 정의]

 Train Set (학습 데이터)
 - 모델의 가중치와 계수를 배우는 데 쓴다
 - 비율: 60~70%

 Validation Set (검증 데이터)
 - '하이퍼파라미터'(=모델이 배우지 않는 설정)를 조정할 때 쓴다
 - 비율: 10~20%

 Test Set (테스트 데이터)
 - 모든 결정이 끝난 후 '최종 성능'을 확인하는 데 쓴다
 - 비율: 10~20%

 [하이퍼파라미터가 뭔가요]

 모델이 '배우는' 것: 가중치, 계수
 모델이 '배우지 않는' 것 (사람이 정하는 것):
 - 정규화 강도 (Ridge/Lasso 강도)
 - max_depth (나무 최대 깊이)
 - learning_rate (학습 속도)

 이런 '사람이 정하는 것'을 하이퍼파라미터라고 부르고,
 이걸 조정하는 과정을 '하이퍼파라미터 튜닝'이라고 해요.

 [왜 세 개가 필요한가]

 scenario:

 [1단계] Train으로 모델 학습
 → 가중치 결정됨

 [2단계] Validation으로 하이퍼파라미터 튜닝
 → Validation 성능을 보고 파라미터를 계속 바꿈
 → '이 파라미터가 Validation에서 가장 좋네!'

 근데 여기서 중요한 함정:

 Validation 성능을 '반복적으로' 보면서
 파라미터를 조정한다는 건,
 결국 Validation 데이터에 '과적합'되고 있다는 뜻입니다!

 우리가 Validation에서 가장 좋은 결과를 찾으면,
 그건 Validation에는 최적이지만,
 새로운 데이터(Test)에는 아닐 수 있어요.

 그래서 Test가 필요해요.

 [3단계] Test로 최종 성능 확인
 → 이건 모든 결정 후 '딱 한 번만'
 → 이 숫자를 보고 더 이상 조정하면 안 됨

 만약 Test를 보고 '이상하네, 파라미터를 다시 조정해야겠다'라고 하면?
 → Test가 오염됩니다 (=실제로는 Validation이 됨)
 → 진짜 배포 성능과 달라집니다

 [실무에서의 예시]

 [모델 1 - 잘못된 방식]
 1) 전체 데이터로 모델 학습
 2) 같은 데이터로 성능 측정 → 95%!
 3) Test 성능 보기 → 70%
 4) 뭔가 잘못됐으니 파라미터 조정
 5) Test 성능 보기 → 75%
 6) 보고: '우리 모델의 성능은 75%입니다'

 이건 거짓이에요. 실제 배포하면 60% 정도가 나올 겁니다.

 [모델 2 - 올바른 방식]
 1) Train으로 모델 학습
 2) Validation으로 하이퍼파라미터 튜닝 (여러 번!)
 3) Train 성능 95%, Validation 성능 92%
 4) Test 성능 보기 → 90%
 5) 이 후 Test는 절대 안 본다
 6) 보고: '우리 모델의 성능은 90%입니다'

 이게 정직한 거예요."
```

→ **실무에서는**: 이 규칙을 어기는 팀들이 실제 배포 후 성능이 떨어져서 당황하죠.

**[예상 질문]** "그럼 Test는 정말 한 번만 봐야 하나요?"
→ "네, 원칙적으로 그래야 해요. 만약 봐야 할 이유가 있으면, 새로운 Test Set을 따로 만들어야 합니다."

---

## [실무 함정] Data Leakage (44~52분)

### → 슬라이드 2-15: Data Leakage란 무엇인가

```
"마지막 함정입니다.

 '미래 정보가 과거 학습에 섞여드는 문제'

 이걸 Data Leakage라고 부르고,
 이게 생기면 모델 성능이 거짓이 돼요.

 [간단한 예시]

 내일 주가를 예측하는 모델을 만들어요.

 학습 데이터:
 - 1월 1일: 주가 100원
 - 1월 2일: 주가 105원
 - 1월 3일: 주가 103원

 [올바른 방식]
 학습: 1월 1일 데이터로 1월 2일 주가 예측
 테스트: 1월 2일 데이터로 1월 3일 주가 예측

 [잘못된 방식 (Data Leakage)]
 학습: 1월 3일 주가도 포함해서 (=미래 정보!)
      1월 1일의 여러 변수를 전처리

 그럼 모델이:
 '1월 1일의 특성들 + 1월 3일 주가 정보'로 학습

 결과:
 테스트 성능 100%! (당연하지, 미래를 봤으니까)
 실제 배포: 30%

 [더 흔한 예시]

 고객 이탈 예측 모델:

 [올바른 방식]
 - 1월 1일 데이터: 고객의 나이, 결제액, 만족도
 - 예측 대상: '1월 2일 이탈할 것인가?'
 - 학습: 1월 1일까지의 정보만 쓴다

 [데이터 Leakage (흔한 실수)]
 - 학습 데이터에 '1월 15일 고객센터 불만 상담 기록'도 포함
 - 근데 이건 미래 정보야! (1월 1일 기준으로)
 - 실제 배포할 때는 이 정보가 없다
 - 그래서 배포 성능이 떨어진다

 [타임라인으로 이해하기]

 시간이 이렇게 흐른다고 상상:

 과거 ─────────── 현재 ──── 미래
        ↓
    학습 데이터
    구간

        현재 ──── 미래
              ↓
          테스트/배포
          구간

 Leakage가 없으려면:
 '학습 데이터 구간에 미래 정보가 없어야 한다'

 그런데 전처리 과정에서 이게 자꾸 생겨요.

 [자주 생기는 상황]

 1) 정규화 (Normalization)
    - 방법: 전체 데이터의 평균과 표준편차로 변수 표준화
    - Leakage: Test 데이터의 통계 정보가 학습에 들어감

 2) 결측치 처리
    - 방법: 전체 데이터의 평균으로 대체
    - Leakage: Test 데이터의 평균이 학습에 들어감

 3) 특이치 제거
    - 방법: 전체 데이터에서 이상치 제거
    - Leakage: Test 범위가 학습 과정에 반영됨

 4) 변수 선택
    - 방법: 전체 데이터에서 상관계수가 높은 변수만 선택
    - Leakage: Test와 target의 관계가 학습 결정에 영향

 [Leakage의 특징]

 '모델 성능이 너무 좋아서 의심해야 한다'

 예시:
 '테스트 성능 99%' → 즉시 의심하세요.
              왜?
 99%는 매우 드문 성능이고,
 대부분의 경우 Leakage가 있을 가능성이 높다는 신호거든요."
```

→ **실무에서는**: Kaggle에서 리더보드 1위인데 실제로는 Leakage가 있었던 사례들이 있어요.

---

### → 슬라이드 2-16: 배포 후 망하는 이유 + 실무 방어법

```
"Leakage의 가장 큰 문제:

 '학습 때는 안 보였는데 배포하고 나서 터진다'

 [배포 후 망하는 시나리오]

 [개발 시점]
 모델 성능: 95%
 테스트 성능: 93%
 '좋은데? 배포하자!'

 [배포 후 1개월]
 실제 성능: 55%
 어? 뭐가 잘못됐지?

 뭐가 잘못됐냐면:

 개발 때는 과거 데이터로 했으니까,
 모든 변수가 이미 준비되어 있었어요.

 근데 배포는 '현재'에서 하는 거예요.

 '지금 이 고객이 이탈할까?'를 물어본다면,
 '지금 시점의 정보'로만 예측해야 하는데,

 학습할 때 '미래 정보'도 썼다면?
 → 지금 예측할 수 없어요.

 [흔한 예시]

 신용카드 이상거래 탐지:

 [올바른 방법]
 - 학습: 거래 발생 시점의 정보만 쓴다
   (카드사, 금액, 시간, 최근 거래 패턴)

 - 배포: 거래가 발생하자마자 바로 판단

 [Leakage가 있는 방법]
 - 학습: 거래 발생 후 '24시간 뒤의 정보'도 포함
   (결국 이상 거래인지 판명난 후의 정보)

 - 배포: 거래 발생 직후에 판단해야 하는데,
        24시간 뒤 정보를 아직 못 본다
 → 배포 성능 급락

 [실무 방어법 1: sklearn Pipeline]

 전처리를 구조적으로 막으려면:

 ```python
 from sklearn.pipeline import Pipeline
 from sklearn.preprocessing import StandardScaler
 from sklearn.linear_model import LogisticRegression

 # 파이프라인 만들기
 pipe = Pipeline([
     ('scaler', StandardScaler()),      # 정규화
     ('model', LogisticRegression())    # 모델
 ])

 # fit: Train으로만 통계 계산
 pipe.fit(X_train, y_train)

 # predict: Test에는 transform만 자동 적용
 # (scaler가 train 통계로 test를 변환)
 pipe.predict(X_test)
 ```

 이 방식의 장점:
 - 'fit'은 Train으로만 한다 (=미래 정보 차단)
 - 'transform'은 Train 통계로 Test에 적용 (=일관성 유지)
 - 구조적으로 Leakage가 불가능해진다

 [실무 방어법 2: 타임라인 검증]

 배포 전에 항상 묻기:

 'Test 데이터의 타임 범위는?'
 '학습 데이터의 타임 범위는?'
 '그 사이에 갭이 있나?'

 그 갭이 있으면:
 - 갭에 속한 데이터는 쓸 수 없다
 - 또는 '시간이 지났을 때의 성능'을 따로 측정한다

 [실무 방어법 3: 도메인 체크]

 배포 시점에 이 변수들을 물어야 한다:

 '이 변수가 배포할 때 정말 있을까?'
 '이 변수는 누가 언제 만드는가?'
 '혹시 미래 정보가 섞여 있지는 않을까?'

 이 질문들을 계속 던져야 Leakage를 피합니다."
```

→ **실무에서는**: Leakage 때문에 망한 ML 프로젝트가 정말 많아요. "성능이 좋아 보이는데 배포가 안 돼"는 신호는 Leakage를 의심해봐야 합니다.

**[예상 질문]** "Pipeline을 안 쓰고도 Leakage를 막을 수 있나요?"
→ "네, 가능하지만 매우 조심스러워요. 전처리 함수를 Train으로만 fit하고, Test에는 수동으로 transform 적용해야 해요. Pipeline이 이걸 자동으로 해주는 거라서 훨씬 안전해요."

---

## [마무리] K-Fold와 핵심 정리 (52~60분)

### → 슬라이드 2-17: K-Fold 교차검증 — 한 번 나눔에 운이 개입한다

```
"여기까지 우리는 '한 번' Train/Test를 나눴어요.

 그런데 그 나눔 자체가 '운'일 수도 있어요.

 [시나리오]

 데이터 100개를 70/30으로 나눴어요.

 근데 혹시 운 좋게 쉬운 테스트를 뽑은 건 아닐까요?

 다시 나누면 다른 결과가 나올 수도 있어요.

 이걸 해결하는 게 K-Fold 교차검증입니다.

 [K-Fold 원리]

 K=5라고 하면:

 데이터를 5개 묶음으로 나눔:
 [묶음1] [묶음2] [묶음3] [묶음4] [묶음5]

 [1회차]
 테스트: 묶음1
 훈련: 묶음2+3+4+5
 → 성능1 측정

 [2회차]
 테스트: 묶음2
 훈련: 묶음1+3+4+5
 → 성능2 측정

 ... (반복) ...

 [5회차]
 테스트: 묶음5
 훈련: 묶음1+2+3+4
 → 성능5 측정

 [최종]
 최종 성능 = (성능1 + 성능2 + 성능3 + 성능4 + 성능5) / 5

 비유:

 어떤 학생의 진짜 실력을 알고 싶어요.

 시험을 한 번만 보고 판단하면 위험해요.
 그날 몸 상태, 문제 운 등이 영향을 주거든요.

 대신 시험을 5번 보고 평균을 내는 게
 그 학생의 '진짜 실력'을 더 정확히 보여줘요.

 K-Fold도 같은 원리입니다.

 [K-Fold의 장점]

 - 데이터를 최대한 활용 (모든 데이터가 한 번씩 테스트)
 - 한 번 나눔의 운을 제거
 - '진짜 성능'을 더 신뢰할 수 있게 함

 [주의: 시계열 데이터]

 만약 데이터가 '시간 순서'가 있다면?
 (예: 주가 데이터, 고객 행동 시계열)

 K-Fold를 쓰면 안 됩니다!

 왜냐면 K-Fold는 무작위로 섞어서 나누는데,
 시계열에서 '미래 데이터'가 '과거'에 섞일 수 있거든요.

 대신 TimeSeriesSplit을 써야 합니다:

 [1회차]
 훈련: 1월~3월
 테스트: 4월

 [2회차]
 훈련: 1월~4월
 테스트: 5월

 ... (시간 순서 유지)

 이렇게 하면 Leakage를 방지합니다."
```

→ **실무에서는**: 시계열 데이터를 K-Fold로 하다가 망한 팀들이 많아요.

---

### → 슬라이드 2-18: 모델 선택 가이드 — 언제 Ridge, 언제 Lasso?

```
"이번 차시의 도구들을 정리하면:

 선형회귀 + Ridge/Lasso (= 규제화 선형회귀)

 이게 언제 쓸까요?

 [Ridge 쓸 때]
 - 데이터가 많고 변수도 많을 때
 - 모든 변수가 어느 정도 중요할 때
 - '예측만' 잘 되면 되는 상황
 - 예: 광고 클릭률 예측

 [Lasso 쓸 때]
 - 변수 선택(해석)이 필요할 때
 - '왜' 이렇게 예측했는지 설명해야 할 때
 - 규제 강도: Ridge보다 강함
 - 예: 의료 진단 (어떤 증상이 진짜 중요한가?)

 [ElasticNet (Ridge + Lasso 섞음)]
 - 둘의 장점을 합친 것
 - 변수도 선택하면서 안정성도 유지
 - 현실의 대부분 상황에서 가장 좋은 선택

 핵심: 규제화가 없으면 과적합 위험이 크고,
      규제화 강도를 잘 조정하는 게 핵심 능력입니다."
```

→ **실무에서는**: 첫 모델링할 때는 ElasticNet으로 시작하고, 해석이 필요하면 Lasso로 바꿔요.

---

### → 슬라이드 2-19: 2차시 핵심 3줄 + 평가 체크리스트

```
"오늘 배운 것을 정리하면:

 [핵심 1] 자유의 대가
 → ML은 변수 1,000개도 처리하지만,
    과적합(훈련과 배포 성능 격차)이 그 대가다

 [핵심 2] 규제화로 대가를 최소화
 → Ridge/Lasso 규제화로 Variance를 줄인다
    Bias를 조금 희생해서 Variance 크게 감소

 [핵심 3] 평가 지표의 선택이 모든 것
 → 정확도는 함정이고,
    상황에 따라 Precision/Recall/AUC를 달리 선택한다

 [배포 전 체크리스트]

 모델을 배포하기 전에 반드시 확인하세요:

 [ ] 훈련 성능 vs 테스트 성능의 격차가 작은가? (과적합 검증)
 [ ] 테스트 성능이 비즈니스 기준치를 넘는가?
 [ ] Precision/Recall/AUC 중 올바른 지표를 선택했는가?
 [ ] Data Leakage가 없는가? (타임라인 검증)
 [ ] Pipeline으로 전처리를 구조화했는가?

 이 5가지 중 하나라도 아니면, 배포 후 망합니다."
```

→ **실무에서는**: 이 체크리스트를 무시한 팀들이 배포 후 성능 저하로 어려움을 겪어요.

---

### → 슬라이드 2-20: 예고 — 직선으로 안 되는 세상

```
"여기까지 우리는 '직선'을 그으려고 노력했어요.

 '회귀 직선 하나'로 데이터를 설명하려고.

 근데 현실 세상은 직선이 아니에요.

 [비선형 패턴 예시]

 '소득이 올수록 행복도가 계속 올라갈까?'
 → 아니요. 어느 정도 이상 올라가면 행복도가 정체돼요 (포화)

 '사람이 많을수록 더 좋은 팀일까?'
 → 아니요. 어느 정도 이상 많으면 오히려 효율이 떨어져요 (복잡성)

 '광고 예산이 많을수록 판매가 계속 증가할까?'
 → 아니요. 어느 정도 이상 투자하면 회수 효율이 떨어져요 (한계 효용 체감)

 이런 '곡선'이나 '구간별 다른 패턴'을 잡으려면?

 선형 모델로는 안 돼요.

 다음 차시(3차시)에서 배울 게 이겁니다.

 '의사결정나무'라는 도구.

 나무는:
 - 질문을 반복해서 데이터를 나눈다
 - 각 영역에서 다른 예측을 한다
 - 비선형 관계를 자연스럽게 잡는다

 그리고 나무를 여러 개 모으면?

 '랜덤 포레스트'라는 강력한 모델이 나와요.

 3차시를 기대하세요."
```

→ **실무에서는**: 데이터의 80% 이상이 비선형이라 나무 계열 모델이 더 자주 쓰여요.

---

## [부록] 60분 타임라인

```
0~3분:    [연결] 1차시 → 2차시 브리지
          - 2-01: 자유의 이면

3~10분:   [출발] 통계의 딜레마에서 ML로
          - 2-02: 선형회귀의 공포 (다중공선성)
          - 2-03: ML의 혁신적 대답

10~22분:  [핵심] 과적합 — 자유가 만든 함정
          - 2-04: 기출문제를 외운 학생
          - 2-05: 훈련 오차 vs 테스트 오차
          - 2-06: Bias-Variance Tradeoff 예고

22~32분:  [해결] 규제화
          - 2-07: 규제화의 등장
          - 2-08: Ridge vs Lasso (다이아몬드 vs 원)
          - 2-09: Bias 희생으로 Variance 감소

32~44분:  [평가] 모델을 어떻게 평가하는가
          - 2-10: 분류 문제 맛보기
          - 2-11: Confusion Matrix (TP/FP/FN/TN)
          - 2-12: 정확도의 함정
          - 2-13: 상황별 지표 선택
          - 2-14: Train / Validation / Test

44~52분:  [실무 함정] Data Leakage
          - 2-15: Data Leakage란 무엇인가
          - 2-16: 배포 후 망하는 이유 + 방어법

52~60분:  [마무리]
          - 2-17: K-Fold 교차검증
          - 2-18: 모델 선택 가이드
          - 2-19: 핵심 3줄 + 체크리스트
          - 2-20: 예고 - 직선으로 안 되는 세상
```

---

## 작성 원칙 준수 체크

- [x] 슬라이드 번호 명시 (2-01 ~ 2-20)
- [x] 1차시 연결: "자유의 대가" 자연스럽게 이어받음
- [x] 수식 완전 제거 (직관과 비유만)
- [x] Ridge vs Lasso: "다이아몬드 vs 원" 비유로 설명
- [x] 과적합 비유: "기출문제를 외운 학생" 공들여 작성
- [x] 각 슬라이드 후 "→ 실무에서는" 한 줄 포함
- [x] [예상 질문] 태그 포함 (총 14개)
- [x] 60분 타임라인 명시
- [x] 톤: 함께 문제를 풀어가는 느낌
- [x] 20장 구조로 최적화 (기존 25장 통합)
- [x] "어렵게 느껴질 수 있는데, 사실 이거 하나만..." 안심 멘트 포함
- [x] Data Leakage: 타임라인 비유로 설명
- [x] Train/Validation/Test: 역할 명확히 구분
